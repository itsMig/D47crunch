<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>D47crunch API documentation</title>
<meta name="description" content="Standardization and analytical error propagation of Δ47 and Δ48 clumped-isotope measurements …" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Fira+Mono&display=swap" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:1em;line-height:1.4em}code{font-family:'Fira Mono',monospace;background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}.css{line-height:1em}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
<style>
pre code {
font-size: .75em;
}
pre code.csv {
padding: 0;
}
pre .csv {
line-height: 1.25;
}
code .hljs-selector-tag,
code .hljs-selector-class {
font-weight: normal;
}
code.csv .hljs-string,
code.csv .hljs-number {
color: #333;
}
code.csv .hljs-keyword,
code.csv .hljs-selector-tag,
code.csv .hljs-subst {
font-weight: normal;
}
h1, h2, h3, h4, h5 {
font-weight: 600;
}
blockquote {
border-left: 3px solid #DDD;
padding: 1em;
color : #AAA
}
</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>D47crunch</code></h1>
</header>
<section id="section-intro">
<p>Standardization and analytical error propagation of Δ<sub>47</sub> and Δ48 clumped-isotope measurements</p>
<p>Process and standardize carbonate and/or CO<sub>2</sub> clumped-isotope analyses,
from low-level data out of a dual-inlet mass spectrometer to final, “absolute”
Δ<sub>47</sub> and Δ<sub>48</sub> values with fully propagated analytical error estimates
(<a href="https://doi.org/10.1029/2020GC009592">Daëron, 2021</a>).</p>
<p>The <strong>tutorial</strong> section takes you through a series of simple steps to import/process data and print out the results.
The <strong>how-to</strong> section provides instructions applicable to various specific tasks.</p>
<h2 id="1-tutorial">1. Tutorial</h2>
<p>Start by creating a file named <code>rawdata.csv</code> with the following contents:</p>
<pre><code class="language-csv">UID,  Sample,           d45,       d46,        d47,        d48,       d49
A01,  ETH-1,        5.79502,  11.62767,   16.89351,   24.56708,   0.79486
A02,  MYSAMPLE-1,   6.21907,  11.49107,   17.27749,   24.58270,   1.56318
A03,  ETH-2,       -6.05868,  -4.81718,  -11.63506,  -10.32578,   0.61352
A04,  MYSAMPLE-2,  -3.86184,   4.94184,    0.60612,   10.52732,   0.57118
A05,  ETH-3,        5.54365,  12.05228,   17.40555,   25.96919,   0.74608
A06,  ETH-2,       -6.06706,  -4.87710,  -11.69927,  -10.64421,   1.61234
A07,  ETH-1,        5.78821,  11.55910,   16.80191,   24.56423,   1.47963
A08,  MYSAMPLE-2,  -3.87692,   4.86889,    0.52185,   10.40390,   1.07032
</code></pre>
<p>Then instantiate a <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> object which will store and process this data:</p>
<pre><code class="language-python">import D47crunch
mydata = D47crunch.D47data()
</code></pre>
<p>For now, this object is empty:</p>
<pre><code class="language-python">&gt;&gt;&gt; print(mydata)
[]
</code></pre>
<p>To load the analyses saved in <code>rawdata.csv</code> into our <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> object and process the data:</p>
<pre><code class="language-python">mydata.read('rawdata.csv')
mydata.wg()          # compute δ13C, δ18O of working gas
mydata.crunch()      # compute all δ13C, δ18O and raw Δ47 values
mydata.standardize() # compute absolute Δ47 values
</code></pre>
<p>We can now print a summary of the data processing:</p>
<pre><code class="language-csv">&gt;&gt;&gt; mydata.summary(verbose = True, save_to_file = False)
[summary]        
–––––––––––––––––––––––––––––––  –––––––––
N samples (anchors + unknowns)   5 (3 + 2)
N analyses (anchors + unknowns)  8 (5 + 3)
Repeatability of δ13C_VPDB         4.2 ppm
Repeatability of δ18O_VSMOW       47.5 ppm
Repeatability of Δ47 (anchors)    13.4 ppm
Repeatability of Δ47 (unknowns)    2.5 ppm
Repeatability of Δ47 (all)         9.6 ppm
Model degrees of freedom                 3
Student's 95% t-factor                3.18
Standardization method              pooled
–––––––––––––––––––––––––––––––  –––––––––
</code></pre>
<p>This tells us that our data set contains 5 different samples: 3 anchors (ETH-1, ETH-2, ETH-3) and 2 unknowns (MYSAMPLE-1, MYSAMPLE-2). The total number of analyses is 8, with 5 anchor analyses and 3 unknown analyses. We get an estimate of the analytical repeatability (i.e. the overall, pooled standard deviation) for δ<sup>13</sup>C, δ<sup>18</sup>O and Δ<sub>47</sub>, as well as the number of degrees of freedom (here, 3) that these estimated standard deviations are based on, along with the corresponding Student's t-factor (here, 3.18) for 95&nbsp;% confidence limits. Finally, the summary indicates that we used a “pooled” standardization approach (see <a href="https://doi.org/10.1029/2020GC009592">Daëron, 2021</a>).</p>
<p>To see the actual results:</p>
<pre><code class="language-csv">&gt;&gt;&gt; mydata.table_of_samples(verbose = True, save_to_file = False)
[table_of_samples] 
––––––––––  –  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
Sample      N  d13C_VPDB  d18O_VSMOW     D47      SE    95% CL      SD  p_Levene
––––––––––  –  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
ETH-1       2       2.01       37.01  0.2052                    0.0131          
ETH-2       2     -10.17       19.88  0.2085                    0.0026          
ETH-3       1       1.73       37.49  0.6132                                    
MYSAMPLE-1  1       2.48       36.90  0.2996  0.0091  ± 0.0291                  
MYSAMPLE-2  2      -8.17       30.05  0.6600  0.0115  ± 0.0366  0.0025          
––––––––––  –  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
</code></pre>
<p>This table lists, for each sample, the number of analytical replicates, average δ<sup>13</sup>C and δ<sup>18</sup>O values (for the analyte CO<sub>2</sub> , <em>not</em> for the carbonate itself), the average Δ<sub>47</sub> value and the SD of Δ<sub>47</sub> for all replicates of this sample. For unknown samples, the SE and 95 % confidence limits for mean Δ<sub>47</sub> are also listed These 95 % CL take into account the number of degrees of freedom of the regression model, so that in large datasets the 95 % CL will tend to 1.96 times the SE, but in this case the applicable t-factor is much larger.</p>
<p>We can also generate a table of all analyses in the data set (again, note that <code>d18O_VSMOW</code> is the composition of the CO<sub>2</sub> analyte):</p>
<pre><code class="language-csv">&gt;&gt;&gt; mydata.table_of_analyses(verbose = True, save_to_file = False)
[table_of_analyses] 
–––  –––––––––  ––––––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––
UID    Session      Sample  d13Cwg_VPDB  d18Owg_VSMOW        d45        d46         d47         d48       d49   d13C_VPDB  d18O_VSMOW     D47raw     D48raw      D49raw       D47
–––  –––––––––  ––––––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––
A01  mySession       ETH-1       -3.807        24.921   5.795020  11.627670   16.893510   24.567080  0.794860    2.014086   37.041843  -0.574686   1.149684  -27.690250  0.214454
A02  mySession  MYSAMPLE-1       -3.807        24.921   6.219070  11.491070   17.277490   24.582700  1.563180    2.476827   36.898281  -0.499264   1.435380  -27.122614  0.299589
A03  mySession       ETH-2       -3.807        24.921  -6.058680  -4.817180  -11.635060  -10.325780  0.613520  -10.166796   19.907706  -0.685979  -0.721617   16.716901  0.206693
A04  mySession  MYSAMPLE-2       -3.807        24.921  -3.861840   4.941840    0.606120   10.527320  0.571180   -8.159927   30.087230  -0.248531   0.613099   -4.979413  0.658270
A05  mySession       ETH-3       -3.807        24.921   5.543650  12.052280   17.405550   25.969190  0.746080    1.727029   37.485567  -0.226150   1.678699  -28.280301  0.613200
A06  mySession       ETH-2       -3.807        24.921  -6.067060  -4.877100  -11.699270  -10.644210  1.612340  -10.173599   19.845192  -0.683054  -0.922832   17.861363  0.210328
A07  mySession       ETH-1       -3.807        24.921   5.788210  11.559100   16.801910   24.564230  1.479630    2.009281   36.970298  -0.591129   1.282632  -26.888335  0.195926
A08  mySession  MYSAMPLE-2       -3.807        24.921  -3.876920   4.868890    0.521850   10.403900  1.070320   -8.173486   30.011134  -0.245768   0.636159   -4.324964  0.661803
–––  –––––––––  ––––––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––
</code></pre>
<h2 id="2-how-to">2. How-to</h2>
<h3 id="21-use-a-different-set-of-anchors-change-anchor-nominal-values-andor-change-17o-correction-parameters">2.1 Use a different set of anchors, change anchor nominal values, and/or change <sup>17</sup>O correction parameters</h3>
<p>Nominal values for various carbonate standards are defined in four places:</p>
<ul>
<li><code><a title="D47crunch.D4xdata.Nominal_d13C_VPDB" href="#D47crunch.D4xdata.Nominal_d13C_VPDB">D4xdata.Nominal_d13C_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.Nominal_d18O_VPDB" href="#D47crunch.D4xdata.Nominal_d18O_VPDB">D4xdata.Nominal_d18O_VPDB</a></code></li>
<li><code><a title="D47crunch.D47data.Nominal_D4x" href="#D47crunch.D47data.Nominal_D4x">D47data.Nominal_D4x</a></code> (also accessible through <code><a title="D47crunch.D47data.Nominal_D47" href="#D47crunch.D47data.Nominal_D47">D47data.Nominal_D47</a></code>)</li>
<li><code><a title="D47crunch.D48data.Nominal_D4x" href="#D47crunch.D48data.Nominal_D4x">D48data.Nominal_D4x</a></code> (also accessible through <code><a title="D47crunch.D48data.Nominal_D48" href="#D47crunch.D48data.Nominal_D48">D48data.Nominal_D48</a></code>)</li>
</ul>
<p><sup>17</sup>O correction parameters are defined by:</p>
<ul>
<li><code><a title="D47crunch.D4xdata.R13_VPDB" href="#D47crunch.D4xdata.R13_VPDB">D4xdata.R13_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R18_VSMOW" href="#D47crunch.D4xdata.R18_VSMOW">D4xdata.R18_VSMOW</a></code></li>
<li><code><a title="D47crunch.D4xdata.R18_VPDB" href="#D47crunch.D4xdata.R18_VPDB">D4xdata.R18_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.lambda_17" href="#D47crunch.D4xdata.lambda_17">D4xdata.lambda_17</a></code></li>
<li><code><a title="D47crunch.D4xdata.R17_VSMOW" href="#D47crunch.D4xdata.R17_VSMOW">D4xdata.R17_VSMOW</a></code></li>
<li><code><a title="D47crunch.D4xdata.R17_VPDB" href="#D47crunch.D4xdata.R17_VPDB">D4xdata.R17_VPDB</a></code></li>
</ul>
<p>When creating a new instance of <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> or <code><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></code>, the current values of these variables are copied as properties of the new object. Applying custom values for, e.g., <code>R17_VSMOW</code> and <code>Nominal_D47</code> can thus be done in several ways:</p>
<p><strong>Option 1:</strong> by redefining <code><a title="D47crunch.D4xdata.R17_VSMOW" href="#D47crunch.D4xdata.R17_VSMOW">D4xdata.R17_VSMOW</a></code> and <code><a title="D47crunch.D47data.Nominal_D47" href="#D47crunch.D47data.Nominal_D47">D47data.Nominal_D47</a></code> <em>before</em> creating a <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> object:</p>
<pre><code class="language-python">from D47crunch import D4xdata, D47data

# redefine R17_VSMOW:
D4xdata.R17_VSMOW = 0.00037 # new value

# redefine R17_VPDB for consistency:
D4xdata.R17_VPDB = D4xdata.R17_VSMOW * (D4xdata.R18_VPDB/D4xdata.R18_VSMOW) ** D4xdata.lambda_17

# edit Nominal_D47 to only include ETH-1/2/3:
D47data.Nominal_D4x = {
    a: D47data.Nominal_D4x[a]
    for a in ['ETH-1', 'ETH-2', 'ETH-3']
    }
# redefine ETH-3:
D47data.Nominal_D4x['ETH-3'] = 0.600

# only now create D47data object:
mydata = D47data()

# check the results:
print(mydata.R17_VSMOW, mydata.R17_VPDB)
print(mydata.Nominal_D47)
# NB: mydata.Nominal_D47 is just an alias for mydata.Nominal_D4x

# should print out:
# 0.00037 0.00037599710894149464
# {'ETH-1': 0.2052, 'ETH-2': 0.2085, 'ETH-3': 0.6}
</code></pre>
<p><strong>Option 2:</strong> by redefining <code>R17_VSMOW</code> and <code>Nominal_D47</code> <em>after</em> creating a <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> object:</p>
<pre><code class="language-python">from D47crunch import D47data

# first create D47data object:
mydata = D47data()

# redefine R17_VSMOW:
mydata.R17_VSMOW = 0.00037 # new value

# redefine R17_VPDB for consistency:
mydata.R17_VPDB = mydata.R17_VSMOW * (mydata.R18_VPDB/mydata.R18_VSMOW) ** mydata.lambda_17

# edit Nominal_D47 to only include ETH-1/2/3:
mydata.Nominal_D47 = {
    a: mydata.Nominal_D47[a]
    for a in ['ETH-1', 'ETH-2', 'ETH-3']
    }
# redefine ETH-3:
mydata.Nominal_D47['ETH-3'] = 0.600

# check the results:
print(mydata.R17_VSMOW, mydata.R17_VPDB)
print(mydata.Nominal_D47)

# should print out:
# 0.00037 0.00037599710894149464
# {'ETH-1': 0.2052, 'ETH-2': 0.2085, 'ETH-3': 0.6}
</code></pre>
<p>The two options above are equivalent, but the latter provides a simple way to compare different data processing choices:</p>
<pre><code class="language-python">from D47crunch import D47data

# create two D47data objects:
foo = D47data()
bar = D47data()

# modify foo in various ways:
foo.lambda_17 = 0.52
foo.R17_VSMOW = 0.00037 # new value
foo.R17_VPDB = foo.R17_VSMOW * (foo.R18_VPDB/foo.R18_VSMOW) ** foo.lambda_17
foo.Nominal_D47 = {
    'ETH-1': foo.Nominal_D47['ETH-1'],
    'ETH-2': foo.Nominal_D47['ETH-1'],
    'IAEA-C2': foo.Nominal_D47['IAEA-C2'],
    'INLAB_REF_MATERIAL': 0.666,
    }

# now import the same raw data into foo and bar:
foo.read('rawdata.csv')
foo.wg()          # compute δ13C, δ18O of working gas
foo.crunch()      # compute all δ13C, δ18O and raw Δ47 values
foo.standardize() # compute absolute Δ47 values

bar.read('rawdata.csv')
bar.wg()          # compute δ13C, δ18O of working gas
bar.crunch()      # compute all δ13C, δ18O and raw Δ47 values
bar.standardize() # compute absolute Δ47 values

# and compare the final results:
foo.table_of_samples(verbose = True, save_to_file = False)
bar.table_of_samples(verbose = True, save_to_file = False)
</code></pre>
<h3 id="22-simulate-a-virtual-data-set-to-play-with">2.2 Simulate a virtual data set to play with</h3>
<p>It is sometimes convenient to quickly build a virtual data set of analyses, for instance to assess the final analytical precision achievable for a given combination of anchor and unknown analyses (see also Fig. 6 of <a href="https://doi.org/10.1029/2020GC009592">Daëron, 2021</a>).</p>
<p>This can be achieved with <code><a title="D47crunch.virtual_data" href="#D47crunch.virtual_data">virtual_data()</a></code>. The example below creates a dataset with four sessions, each of which comprises four analyses of anchor ETH-1, five of ETH-2, six of ETH-3, and two analyses of an unknown sample named <code>FOO</code> with an arbitrarily defined isotopic composition. Analytical repeatabilities for Δ<sub>47</sub> and Δ<sub>48</sub> are also specified arbitrarily. See the <code><a title="D47crunch.virtual_data" href="#D47crunch.virtual_data">virtual_data()</a></code> documentation for additional configuration parameters.</p>
<pre><code class="language-py">from D47crunch import *

args = dict(
    samples = [
        dict(Sample = 'ETH-1', N = 4),
        dict(Sample = 'ETH-2', N = 5),
        dict(Sample = 'ETH-3', N = 6),
        dict(
            Sample = 'FOO',
            N = 2,
            d13C_VPDB = -5.,
            d18O_VPDB = -10.,
            D47 = 0.3,
            D48 = 0.15
            ),
        ],
    rD47 = 0.010,
    rD48 = 0.030,
    )

session1 = virtual_data(session = 'Session_01', **args)
session2 = virtual_data(session = 'Session_02', **args)
session3 = virtual_data(session = 'Session_03', **args)
session4 = virtual_data(session = 'Session_04', **args)

D = D47data(session1 + session2 + session3 + session4)

D.crunch()
D.standardize()

D.table_of_sessions(verbose = True, save_to_file = False)
D.table_of_samples(verbose = True, save_to_file = False)
D.table_of_analyses(verbose = True, save_to_file = False)
</code></pre>
<h3 id="23-process-paired-47-and-48-values">2.3 Process paired Δ<sub>47</sub> and Δ<sub>48</sub> values</h3>
<h2 id="3-discussion">3. Discussion</h2>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#! /usr/bin/env python3
&#39;&#39;&#39;
Standardization and analytical error propagation of Δ47 and Δ48 clumped-isotope measurements

Process and standardize carbonate and/or CO&lt;sub&gt;2&lt;/sub&gt; clumped-isotope analyses,
from low-level data out of a dual-inlet mass spectrometer to final, “absolute”
Δ&lt;sub&gt;47&lt;/sub&gt; and Δ&lt;sub&gt;48&lt;/sub&gt; values with fully propagated analytical error estimates
([Daëron, 2021]).

The **tutorial** section takes you through a series of simple steps to import/process data and print out the results.
The **how-to** section provides instructions applicable to various specific tasks.

.. include:: ../docs/tutorial.md
.. include:: ../docs/howto.md
.. include:: ../docs/discussion.md

[Daëron, 2021]: https://doi.org/10.1029/2020GC009592
&#39;&#39;&#39;

__author__    = &#39;Mathieu Daëron&#39;
__contact__   = &#39;daeron@lsce.ipsl.fr&#39;
__copyright__ = &#39;Copyright (c) 2021 Mathieu Daëron&#39;
__license__   = &#39;Modified BSD License - https://opensource.org/licenses/BSD-3-Clause&#39;
__date__      = &#39;2021-07-26&#39;
__version__   = &#39;2.0.0-beta&#39;

import os
import numpy as np
from statistics import stdev
from scipy.stats import t as tstudent
from scipy.stats import levene
from scipy.interpolate import interp1d
from numpy import linalg
from lmfit import Minimizer, Parameters, report_fit
from matplotlib import pyplot as ppl
from datetime import datetime as dt
from functools import wraps
from colorsys import hls_to_rgb
from matplotlib import rcParams

rcParams[&#39;font.family&#39;] = &#39;sans-serif&#39;
rcParams[&#39;font.sans-serif&#39;] = &#39;Helvetica&#39;
rcParams[&#39;font.size&#39;] = 10
rcParams[&#39;mathtext.fontset&#39;] = &#39;custom&#39;
rcParams[&#39;mathtext.rm&#39;] = &#39;sans&#39;
rcParams[&#39;mathtext.bf&#39;] = &#39;sans:bold&#39;
rcParams[&#39;mathtext.it&#39;] = &#39;sans:italic&#39;
rcParams[&#39;mathtext.cal&#39;] = &#39;sans:italic&#39;
rcParams[&#39;mathtext.default&#39;] = &#39;rm&#39;
rcParams[&#39;xtick.major.size&#39;] = 4
rcParams[&#39;xtick.major.width&#39;] = 1
rcParams[&#39;ytick.major.size&#39;] = 4
rcParams[&#39;ytick.major.width&#39;] = 1
rcParams[&#39;axes.grid&#39;] = False
rcParams[&#39;axes.linewidth&#39;] = 1
rcParams[&#39;grid.linewidth&#39;] = .75
rcParams[&#39;grid.linestyle&#39;] = &#39;-&#39;
rcParams[&#39;grid.alpha&#39;] = .15
rcParams[&#39;savefig.dpi&#39;] = 150

Petersen_etal_CO2eqD47 = np.array([[-12, 1.147113572], [-11, 1.139961218], [-10, 1.132872856], [-9, 1.125847677], [-8, 1.118884889], [-7, 1.111983708], [-6, 1.105143366], [-5, 1.098363105], [-4, 1.091642182], [-3, 1.084979862], [-2, 1.078375423], [-1, 1.071828156], [0, 1.065337360], [1, 1.058902349], [2, 1.052522443], [3, 1.046196976], [4, 1.039925291], [5, 1.033706741], [6, 1.027540690], [7, 1.021426510], [8, 1.015363585], [9, 1.009351306], [10, 1.003389075], [11, 0.997476303], [12, 0.991612409], [13, 0.985796821], [14, 0.980028975], [15, 0.974308318], [16, 0.968634304], [17, 0.963006392], [18, 0.957424055], [19, 0.951886769], [20, 0.946394020], [21, 0.940945302], [22, 0.935540114], [23, 0.930177964], [24, 0.924858369], [25, 0.919580851], [26, 0.914344938], [27, 0.909150167], [28, 0.903996080], [29, 0.898882228], [30, 0.893808167], [31, 0.888773459], [32, 0.883777672], [33, 0.878820382], [34, 0.873901170], [35, 0.869019623], [36, 0.864175334], [37, 0.859367901], [38, 0.854596929], [39, 0.849862028], [40, 0.845162813], [41, 0.840498905], [42, 0.835869931], [43, 0.831275522], [44, 0.826715314], [45, 0.822188950], [46, 0.817696075], [47, 0.813236341], [48, 0.808809404], [49, 0.804414926], [50, 0.800052572], [51, 0.795722012], [52, 0.791422922], [53, 0.787154979], [54, 0.782917869], [55, 0.778711277], [56, 0.774534898], [57, 0.770388426], [58, 0.766271562], [59, 0.762184010], [60, 0.758125479], [61, 0.754095680], [62, 0.750094329], [63, 0.746121147], [64, 0.742175856], [65, 0.738258184], [66, 0.734367860], [67, 0.730504620], [68, 0.726668201], [69, 0.722858343], [70, 0.719074792], [71, 0.715317295], [72, 0.711585602], [73, 0.707879469], [74, 0.704198652], [75, 0.700542912], [76, 0.696912012], [77, 0.693305719], [78, 0.689723802], [79, 0.686166034], [80, 0.682632189], [81, 0.679122047], [82, 0.675635387], [83, 0.672171994], [84, 0.668731654], [85, 0.665314156], [86, 0.661919291], [87, 0.658546854], [88, 0.655196641], [89, 0.651868451], [90, 0.648562087], [91, 0.645277352], [92, 0.642014054], [93, 0.638771999], [94, 0.635551001], [95, 0.632350872], [96, 0.629171428], [97, 0.626012487], [98, 0.622873870], [99, 0.619755397], [100, 0.616656895], [102, 0.610519107], [104, 0.604459143], [106, 0.598475670], [108, 0.592567388], [110, 0.586733026], [112, 0.580971342], [114, 0.575281125], [116, 0.569661187], [118, 0.564110371], [120, 0.558627545], [122, 0.553211600], [124, 0.547861454], [126, 0.542576048], [128, 0.537354347], [130, 0.532195337], [132, 0.527098028], [134, 0.522061450], [136, 0.517084654], [138, 0.512166711], [140, 0.507306712], [142, 0.502503768], [144, 0.497757006], [146, 0.493065573], [148, 0.488428634], [150, 0.483845370], [152, 0.479314980], [154, 0.474836677], [156, 0.470409692], [158, 0.466033271], [160, 0.461706674], [162, 0.457429176], [164, 0.453200067], [166, 0.449018650], [168, 0.444884242], [170, 0.440796174], [172, 0.436753787], [174, 0.432756438], [176, 0.428803494], [178, 0.424894334], [180, 0.421028350], [182, 0.417204944], [184, 0.413423530], [186, 0.409683531], [188, 0.405984383], [190, 0.402325531], [192, 0.398706429], [194, 0.395126543], [196, 0.391585347], [198, 0.388082324], [200, 0.384616967], [202, 0.381188778], [204, 0.377797268], [206, 0.374441954], [208, 0.371122364], [210, 0.367838033], [212, 0.364588505], [214, 0.361373329], [216, 0.358192065], [218, 0.355044277], [220, 0.351929540], [222, 0.348847432], [224, 0.345797540], [226, 0.342779460], [228, 0.339792789], [230, 0.336837136], [232, 0.333912113], [234, 0.331017339], [236, 0.328152439], [238, 0.325317046], [240, 0.322510795], [242, 0.319733329], [244, 0.316984297], [246, 0.314263352], [248, 0.311570153], [250, 0.308904364], [252, 0.306265654], [254, 0.303653699], [256, 0.301068176], [258, 0.298508771], [260, 0.295975171], [262, 0.293467070], [264, 0.290984167], [266, 0.288526163], [268, 0.286092765], [270, 0.283683684], [272, 0.281298636], [274, 0.278937339], [276, 0.276599517], [278, 0.274284898], [280, 0.271993211], [282, 0.269724193], [284, 0.267477582], [286, 0.265253121], [288, 0.263050554], [290, 0.260869633], [292, 0.258710110], [294, 0.256571741], [296, 0.254454286], [298, 0.252357508], [300, 0.250281174], [302, 0.248225053], [304, 0.246188917], [306, 0.244172542], [308, 0.242175707], [310, 0.240198194], [312, 0.238239786], [314, 0.236300272], [316, 0.234379441], [318, 0.232477087], [320, 0.230593005], [322, 0.228726993], [324, 0.226878853], [326, 0.225048388], [328, 0.223235405], [330, 0.221439711], [332, 0.219661118], [334, 0.217899439], [336, 0.216154491], [338, 0.214426091], [340, 0.212714060], [342, 0.211018220], [344, 0.209338398], [346, 0.207674420], [348, 0.206026115], [350, 0.204393315], [355, 0.200378063], [360, 0.196456139], [365, 0.192625077], [370, 0.188882487], [375, 0.185226048], [380, 0.181653511], [385, 0.178162694], [390, 0.174751478], [395, 0.171417807], [400, 0.168159686], [405, 0.164975177], [410, 0.161862398], [415, 0.158819521], [420, 0.155844772], [425, 0.152936426], [430, 0.150092806], [435, 0.147312286], [440, 0.144593281], [445, 0.141934254], [450, 0.139333710], [455, 0.136790195], [460, 0.134302294], [465, 0.131868634], [470, 0.129487876], [475, 0.127158722], [480, 0.124879906], [485, 0.122650197], [490, 0.120468398], [495, 0.118333345], [500, 0.116243903], [505, 0.114198970], [510, 0.112197471], [515, 0.110238362], [520, 0.108320625], [525, 0.106443271], [530, 0.104605335], [535, 0.102805877], [540, 0.101043985], [545, 0.099318768], [550, 0.097629359], [555, 0.095974915], [560, 0.094354612], [565, 0.092767650], [570, 0.091213248], [575, 0.089690648], [580, 0.088199108], [585, 0.086737906], [590, 0.085306341], [595, 0.083903726], [600, 0.082529395], [605, 0.081182697], [610, 0.079862998], [615, 0.078569680], [620, 0.077302141], [625, 0.076059794], [630, 0.074842066], [635, 0.073648400], [640, 0.072478251], [645, 0.071331090], [650, 0.070206399], [655, 0.069103674], [660, 0.068022424], [665, 0.066962168], [670, 0.065922439], [675, 0.064902780], [680, 0.063902748], [685, 0.062921909], [690, 0.061959837], [695, 0.061016122], [700, 0.060090360], [705, 0.059182157], [710, 0.058291131], [715, 0.057416907], [720, 0.056559120], [725, 0.055717414], [730, 0.054891440], [735, 0.054080860], [740, 0.053285343], [745, 0.052504565], [750, 0.051738210], [755, 0.050985971], [760, 0.050247546], [765, 0.049522643], [770, 0.048810974], [775, 0.048112260], [780, 0.047426227], [785, 0.046752609], [790, 0.046091145], [795, 0.045441581], [800, 0.044803668], [805, 0.044177164], [810, 0.043561831], [815, 0.042957438], [820, 0.042363759], [825, 0.041780573], [830, 0.041207664], [835, 0.040644822], [840, 0.040091839], [845, 0.039548516], [850, 0.039014654], [855, 0.038490063], [860, 0.037974554], [865, 0.037467944], [870, 0.036970054], [875, 0.036480707], [880, 0.035999734], [885, 0.035526965], [890, 0.035062238], [895, 0.034605393], [900, 0.034156272], [905, 0.033714724], [910, 0.033280598], [915, 0.032853749], [920, 0.032434032], [925, 0.032021309], [930, 0.031615443], [935, 0.031216300], [940, 0.030823749], [945, 0.030437663], [950, 0.030057915], [955, 0.029684385], [960, 0.029316951], [965, 0.028955498], [970, 0.028599910], [975, 0.028250075], [980, 0.027905884], [985, 0.027567229], [990, 0.027234006], [995, 0.026906112], [1000, 0.026583445], [1005, 0.026265908], [1010, 0.025953405], [1015, 0.025645841], [1020, 0.025343124], [1025, 0.025045163], [1030, 0.024751871], [1035, 0.024463160], [1040, 0.024178947], [1045, 0.023899147], [1050, 0.023623680], [1055, 0.023352467], [1060, 0.023085429], [1065, 0.022822491], [1070, 0.022563577], [1075, 0.022308615], [1080, 0.022057533], [1085, 0.021810260], [1090, 0.021566729], [1095, 0.021326872], [1100, 0.021090622]])
_fCO2eqD47_Petersen = interp1d(Petersen_etal_CO2eqD47[:,0], Petersen_etal_CO2eqD47[:,1])
def fCO2eqD47_Petersen(T):
        &#39;&#39;&#39;
        CO&lt;sub&gt;2&lt;/sub&gt; equilibrium Δ&lt;sub&gt;47&lt;/sub&gt; value as a function of T (in degrees C)
        according to [Petersen et al. (2019)].

        [Petersen et al. (2019)]: https://doi.org/10.1029/2018GC008127
        &#39;&#39;&#39;
        return float(_fCO2eqD47_Petersen(T))


Wang_etal_CO2eqD47 = np.array([[-83., 1.8954], [-73., 1.7530], [-63., 1.6261], [-53., 1.5126], [-43., 1.4104], [-33., 1.3182], [-23., 1.2345], [-13., 1.1584], [-3., 1.0888], [7., 1.0251], [17., 0.9665], [27., 0.9125], [37., 0.8626], [47., 0.8164], [57., 0.7734], [67., 0.7334], [87., 0.6612], [97., 0.6286], [107., 0.5980], [117., 0.5693], [127., 0.5423], [137., 0.5169], [147., 0.4930], [157., 0.4704], [167., 0.4491], [177., 0.4289], [187., 0.4098], [197., 0.3918], [207., 0.3747], [217., 0.3585], [227., 0.3431], [237., 0.3285], [247., 0.3147], [257., 0.3015], [267., 0.2890], [277., 0.2771], [287., 0.2657], [297., 0.2550], [307., 0.2447], [317., 0.2349], [327., 0.2256], [337., 0.2167], [347., 0.2083], [357., 0.2002], [367., 0.1925], [377., 0.1851], [387., 0.1781], [397., 0.1714], [407., 0.1650], [417., 0.1589], [427., 0.1530], [437., 0.1474], [447., 0.1421], [457., 0.1370], [467., 0.1321], [477., 0.1274], [487., 0.1229], [497., 0.1186], [507., 0.1145], [517., 0.1105], [527., 0.1068], [537., 0.1031], [547., 0.0997], [557., 0.0963], [567., 0.0931], [577., 0.0901], [587., 0.0871], [597., 0.0843], [607., 0.0816], [617., 0.0790], [627., 0.0765], [637., 0.0741], [647., 0.0718], [657., 0.0695], [667., 0.0674], [677., 0.0654], [687., 0.0634], [697., 0.0615], [707., 0.0597], [717., 0.0579], [727., 0.0562], [737., 0.0546], [747., 0.0530], [757., 0.0515], [767., 0.0500], [777., 0.0486], [787., 0.0472], [797., 0.0459], [807., 0.0447], [817., 0.0435], [827., 0.0423], [837., 0.0411], [847., 0.0400], [857., 0.0390], [867., 0.0380], [877., 0.0370], [887., 0.0360], [897., 0.0351], [907., 0.0342], [917., 0.0333], [927., 0.0325], [937., 0.0317], [947., 0.0309], [957., 0.0302], [967., 0.0294], [977., 0.0287], [987., 0.0281], [997., 0.0274], [1007., 0.0268], [1017., 0.0261], [1027., 0.0255], [1037., 0.0249], [1047., 0.0244], [1057., 0.0238], [1067., 0.0233], [1077., 0.0228], [1087., 0.0223], [1097., 0.0218]])
_fCO2eqD47_Wang = interp1d(Wang_etal_CO2eqD47[:,0] - 0.15, Wang_etal_CO2eqD47[:,1])
def fCO2eqD47_Wang(T):
        &#39;&#39;&#39;
        CO&lt;sub&gt;2&lt;/sub&gt; equilibrium Δ&lt;sub&gt;47&lt;/sub&gt; value as a function of `T` (in degrees C)
        according to [Wang et al. (2004)] (supplementary data of [Dennis et al., 2011]).

        [Wang et al. (2004)]: https://doi.org/10.1016/j.gca.2004.05.039
        [Dennis et al., 2011]: https://doi.org/10.1016/j.gca.2011.09.025
        &#39;&#39;&#39;
        return float(_fCO2eqD47_Wang(T))


def correlated_sum(X, C, w = None):
        &#39;&#39;&#39;
        Compute covariance-aware linear combinations

        __Parameters__
        
        + `X`: list or 1-D array of values to sum
        + `C`: covariance matrix for the elements of `X`
        + `w`: list or 1-D array of weights to apply to the elements of `X`
               (all equal to 1 by default)

        Return the sum (and its SE) of the elements of `X`, with optional weights equal
        to the elements of `w`, accounting for covariances between the elements of `X`.
        &#39;&#39;&#39;
        if w is None:
                w = [1 for x in X]
        return np.dot(w,X), (np.dot(w,np.dot(C,w)))**.5


def make_csv(x, hsep = &#39;,&#39;, vsep = &#39;\n&#39;):
        &#39;&#39;&#39;
        Formats a list of lists of strings as a CSV

        __Parameters__

        + `x`: the list of lists of strings to format
        + `hsep`: the field separator (`,` by default)
        + `vsep`: the line-ending convention to use (`\\n` by default)

        __Example__

        ```py
        print(make_csv([[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [&#39;d&#39;, &#39;e&#39;, &#39;f&#39;]]))
        ```

        outputs:

        ```py
        a,b,c
        d,e,f
        ```
        &#39;&#39;&#39;
        return vsep.join([hsep.join(l) for l in x])


def pf(txt):
        &#39;&#39;&#39;
        Modify string `txt` to follow `lmfit.Parameter()` naming rules.
        &#39;&#39;&#39;
        return txt.replace(&#39;-&#39;,&#39;_&#39;).replace(&#39;.&#39;,&#39;_&#39;).replace(&#39; &#39;,&#39;_&#39;)


def smart_type(x):
        &#39;&#39;&#39;
        Tries to convert string `x` to a float if it includes a decimal point, or
        to an integer if it does not. If both attempts fail, return the original
        string unchanged.
        &#39;&#39;&#39;
        try:
                y = float(x)
        except ValueError:
                return x
        if &#39;.&#39; not in x:
                return int(y)
        return y


def pretty_table(x, header = 1, hsep = &#39;  &#39;, vsep = &#39;–&#39;, align = &#39;&lt;&#39;):
        &#39;&#39;&#39;
        Reads a list of lists of strings and outputs an ascii table

        __Parameters__

        + `x`: a list of lists of strings
        + `header`: the number of lines to treat as header lines
        + `hsep`: the horizontal separator between columns
        + `vsep`: the character to use as vertical separator
        + `align`: string of left (`&lt;`) or right (`&gt;`) alignment characters.

        __Example__

        ```python
        x = [[&#39;A&#39;,&#39;B&#39;, &#39;C&#39;], [&#39;1&#39;, &#39;1.9999&#39;, &#39;foo&#39;], [&#39;10&#39;, &#39;x&#39;, &#39;bar&#39;]]
        print(pretty_table(x))
        ```

        output:

        ```python
        --  ------  ---
        A        B    C
        --  ------  ---
        1   1.9999  foo
        10       x  bar
        --  ------  ---
        ```
        &#39;&#39;&#39;
        txt = []
        widths = [np.max([len(e) for e in c]) for c in zip(*x)]

        if len(widths) &gt; len(align):
                align += &#39;&gt;&#39; * (len(widths)-len(align))
        sepline = hsep.join([vsep*w for w in widths])
        txt += [sepline]
        for k,l in enumerate(x):
                if k and k == header:
                        txt += [sepline]
                txt += [hsep.join([f&#39;{e:{a}{w}}&#39; for e, w, a in zip(l, widths, align)])]
        txt += [sepline]
        txt += [&#39;&#39;]
        return &#39;\n&#39;.join(txt)


def transpose_table(x):
        &#39;&#39;&#39;
        Transpose a list if lists

        __Parameters__

        + `x`: a list of lists

        __Example__

        ```python
        x = [[1, 2], [3, 4]]
        print(transpose_table(x))
        ```

        outputs:

        ```python
        [[1, 3], [2, 4]]
        ```

        &#39;&#39;&#39;
        return [[e for e in c] for c in zip(*x)]


def w_avg(X, sX) :
        &#39;&#39;&#39;
        Compute variance-weighted average

        Returns the value and SE of the weighted average of the elements of `X`,
        with relative weights equal to their inverse variances (`1/sX**2`).

        __Parameters__

        + `X`: array-like of elements to average
        + `sX`: array-like of the corresponding SE values

        __Tip__

        If `X` and `sX` are initially arranged as a list of `(x, sx)` doublets,
        they may be rearranged using `zip()`:

        ```python
        foo = [(0, 0.1), (1, 0.05), (2, 0.05)]
        print(w_avg(*zip(*foo)))

        # output:
        # (1.3333333333333333, 0.03333333333333334)
        ```
        &#39;&#39;&#39;
        X = [ x for x in X ]
        sX = [ sx for sx in sX ]
        W = [ sx**-2 for sx in sX ]
        W = [ w/sum(W) for w in W ]
        Xavg = sum([ w*x for w,x in zip(W,X) ])
        sXavg = sum([ w**2*sx**2 for w,sx in zip(W,sX) ])**.5
        return Xavg, sXavg


def read_csv(filename, sep = &#39;&#39;):
        &#39;&#39;&#39;
        Read contents of `filename` in csv format and return a list of dictionaries.

        In the csv string, spaces before and after field separators (`&#39;,&#39;` by default)
        are optional.

        __Parameters__

        + `filename`: the csv file to read
        + `sep`: csv separator delimiting the fields. By default, use `,`, `;`, or `\t`,
        whichever appers most often in the contents of `filename`.
        &#39;&#39;&#39;
        with open(filename) as fid:
                txt = fid.read()

        if sep == &#39;&#39;:
                sep = sorted(&#39;,;\t&#39;, key = lambda x: - txt.count(x))[0]
        txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
        return [{k: smart_type(v) for k,v in zip(txt[0], l) if v} for l in txt[1:]]


class D4xdata(list):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ&lt;sub&gt;47&lt;/sub&gt; and/or Δ&lt;sub&gt;48&lt;/sub&gt;
        analyses, usually comprising more than one analytical session.
        &#39;&#39;&#39;

        ### 17O CORRECTION PARAMETERS
        R13_VPDB = 0.01118  # (Chang &amp; Li, 1990)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;13&lt;/sup&gt;C/&lt;sup&gt;12&lt;/sup&gt;C) ratio of VPDB.
        By default equal to 0.01118 ([Chang &amp; Li, 1990])

        [Chang &amp; Li, 1990]: http://www.cnki.com.cn/Article/CJFDTotal-JXTW199004006.htm
        &#39;&#39;&#39;

        R18_VSMOW = 0.0020052  # (Baertschi, 1976)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VSMOW.
        By default equal to 0.0020052 ([Baertschi, 1976])

        [Baertschi, 1976]: https://doi.org/10.1016/0012-821X(76)90115-1
        &#39;&#39;&#39;

        lambda_17 = 0.528  # (Barkan &amp; Luz, 2005)
        &#39;&#39;&#39;
        Mass-dependent exponent for triple oxygen isotopes.
        By default equal to 0.528 ([Barkan &amp; Luz, 2005])

        [Barkan &amp; Luz, 2005]: https://doi.org/10.1002/rcm.2250
        &#39;&#39;&#39;

        R17_VSMOW = 0.00038475  # (Assonov &amp; Brenninkmeijer, 2003, rescaled to R13_VPDB)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;17&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VSMOW.
        By default equal to 0.00038475
        ([Assonov &amp; Brenninkmeijer, 2003], rescaled to `R13_VPDB`)

        [Assonov &amp; Brenninkmeijer, 2003]: https://dx.doi.org/10.1002/rcm.1011
        &#39;&#39;&#39;

        R18_VPDB = R18_VSMOW * 1.03092
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VPDB.
        By definition equal to `R18_VSMOW * 1.03092`.
        &#39;&#39;&#39;

        R17_VPDB = R17_VSMOW * 1.03092 ** lambda_17
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;17&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VPDB.
        By definition equal to `R17_VSMOW * 1.03092 ** lambda_17`.
        &#39;&#39;&#39;

        LEVENE_REF_SAMPLE = &#39;ETH-3&#39;
        &#39;&#39;&#39;
        After the Δ&lt;sub&gt;4x&lt;/sub&gt; standardization step, each sample is tested to
        assess whether the Δ&lt;sub&gt;4x&lt;/sub&gt; variance within all analyses for that
        sample differs significantly from that observed for a given reference
        sample (using [Levene&#39;s test], which yields a p-value corresponding to
        the null hypothesis that the underlying variances are equal).

        `LEVENE_REF_SAMPLE` (by default equal to `&#39;ETH-3&#39;`) specifies which
        sample should be used as a reference for this test.

        [Levene&#39;s test]: https://en.wikipedia.org/wiki/Levene%27s_test
        &#39;&#39;&#39;

        ALPHA_18O_ACID_REACTION = round(np.exp(3.59 / (90 + 273.15) - 1.79e-3), 6)  # (Kim et al., 2007, calcite)
        &#39;&#39;&#39;
        Specifies the &lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;O fractionation factor generally applicable
        to acid reactions in the dataset. Currently used by `D4xdata.wg()`,
        `D4xdata.standardize_d13C`, and `D4xdata.standardize_d18O`.

        By default equal to 1.008129 (calcite reacted at 90 °C, [Kim et al., 2007]).

        [Kim et al., 2007]: https://dx.doi.org/10.1016/j.chemgeo.2007.08.005
        &#39;&#39;&#39;

        Nominal_d13C_VPDB = {
                &#39;ETH-1&#39;: 2.02,
                &#39;ETH-2&#39;: -10.17,
                &#39;ETH-3&#39;: 1.71,
                }       # (Bernasconi et al., 2018)
        &#39;&#39;&#39;
        Nominal δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; values assigned to carbonate standards, used by
        `D4xdata.standardize_d13C()`.

        By default equal to `{&#39;ETH-1&#39;: 2.02, &#39;ETH-2&#39;: -10.17, &#39;ETH-3&#39;: 1.71}` after
        [Bernasconi et al. (2018)].

        [Bernasconi et al. (2018)]: https://doi.org/10.1029/2017GC007385
        &#39;&#39;&#39;

        Nominal_d18O_VPDB = {
                &#39;ETH-1&#39;: -2.19,
                &#39;ETH-2&#39;: -18.69,
                &#39;ETH-3&#39;: -1.78,
                }       # (Bernasconi et al., 2018)
        &#39;&#39;&#39;
        Nominal δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VPDB&lt;/sub&gt; values assigned to carbonate standards, used by
        `D4xdata.standardize_d18O()`.

        By default equal to `{&#39;ETH-1&#39;: -2.19, &#39;ETH-2&#39;: -18.69, &#39;ETH-3&#39;: -1.78}` after
        [Bernasconi et al. (2018)].

        [Bernasconi et al. (2018)]: https://doi.org/10.1029/2017GC007385
        &#39;&#39;&#39;

        d13C_STANDARDIZATION_METHOD = &#39;2pt&#39;
        &#39;&#39;&#39;
        Method by which to standardize δ&lt;sup&gt;13&lt;/sup&gt;C values:
        
        + `none`: do not apply any δ&lt;sup&gt;13&lt;/sup&gt;C standardization.
        + `&#39;1pt&#39;`: within each session, offset all initial δ&lt;sup&gt;13&lt;/sup&gt;C values so as to
        minimize the difference between final δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; values and
        `Nominal_d13C_VPDB` (averaged over all analyses for which `Nominal_d13C_VPDB` is defined).
        + `&#39;2pt&#39;`: within each session, apply a affine trasformation to all δ&lt;sup&gt;13&lt;/sup&gt;C
        values so as to minimize the difference between final δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt;
        values and `Nominal_d13C_VPDB` (averaged over all analyses for which `Nominal_d13C_VPDB`
        is defined).
        &#39;&#39;&#39;

        d18O_STANDARDIZATION_METHOD = &#39;2pt&#39;
        &#39;&#39;&#39;
        Method by which to standardize δ&lt;sup&gt;18&lt;/sup&gt;O values:
        
        + `none`: do not apply any δ&lt;sup&gt;18&lt;/sup&gt;O standardization.
        + `&#39;1pt&#39;`: within each session, offset all initial δ&lt;sup&gt;18&lt;/sup&gt;O values so as to
        minimize the difference between final δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VPDB&lt;/sub&gt; values and
        `Nominal_d18O_VPDB` (averaged over all analyses for which `Nominal_d18O_VPDB` is defined).
        + `&#39;2pt&#39;`: within each session, apply a affine trasformation to all δ&lt;sup&gt;18&lt;/sup&gt;O
        values so as to minimize the difference between final δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VPDB&lt;/sub&gt;
        values and `Nominal_d18O_VPDB` (averaged over all analyses for which `Nominal_d18O_VPDB`
        is defined).
        &#39;&#39;&#39;

        def __init__(self, l = [], mass = &#39;47&#39;, logfile = &#39;&#39;, session = &#39;mySession&#39;, verbose = False):
                &#39;&#39;&#39;
                __Parameters__

                + `l`: a list of dictionaries, with each dictionary including at least the keys
                `Sample`, `d45`, `d46`, and `d47` or `d48`.
                + `logfile`: if specified, write detailed logs to this file path when calling `D4xdata` methods.
                + `session`: define session name for analyses without a `Session` key
                + `verbose`: if `True`, print out detailed logs when calling `D4xdata` methods.

                Returns a `D4xdata` object derived from `list`.
                &#39;&#39;&#39;
                self._4x = mass
                self.verbose = verbose
                self.prefix = &#39;D4xdata&#39;
                self.logfile = logfile
                list.__init__(self, l)
                self.Nf = None
                self.repeatability = {}
                self.refresh(session = session)


        def make_verbal(oldfun):
                &#39;&#39;&#39;
                Decorator: allow temporarily changing `self.prefix` and overriding `self.verbose`.
                &#39;&#39;&#39;
                @wraps(oldfun)
                def newfun(*args, verbose = &#39;&#39;, **kwargs):
                        myself = args[0]
                        oldprefix = myself.prefix
                        myself.prefix = oldfun.__name__
                        if verbose != &#39;&#39;:
                                oldverbose = myself.verbose
                                myself.verbose = verbose
                        out = oldfun(*args, **kwargs)
                        myself.prefix = oldprefix
                        if verbose != &#39;&#39;:
                                myself.verbose = oldverbose
                        return out
                return newfun


        def msg(self, txt):
                &#39;&#39;&#39;
                Log a message to `self.logfile`, and print it out if `verbose = True`
                &#39;&#39;&#39;
                self.log(txt)
                if self.verbose:
                        print(f&#39;{f&#34;[{self.prefix}]&#34;:&lt;16} {txt}&#39;)


        def vmsg(self, txt):
                &#39;&#39;&#39;
                Log a message to `self.logfile` and print it out
                &#39;&#39;&#39;
                self.log(txt)
                print(txt)


        def log(self, *txts):
                &#39;&#39;&#39;
                Log a message to `self.logfile`
                &#39;&#39;&#39;
                if self.logfile:
                        with open(self.logfile, &#39;a&#39;) as fid:
                                for txt in txts:
                                        fid.write(f&#39;\n{dt.now().strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)} {f&#34;[{self.prefix}]&#34;:&lt;16} {txt}&#39;)


        def refresh(self, session = &#39;mySession&#39;):
                &#39;&#39;&#39;
                Update `self.sessions`, `self.samples`, `self.anchors`, and `self.unknowns`.
                &#39;&#39;&#39;
                self.fill_in_missing_info(session = session)
                self.refresh_sessions()
                self.refresh_samples()


        def refresh_sessions(self):
                &#39;&#39;&#39;
                Update `self.sessions` and set `scrambling_drift`, `slope_drift`, and `wg_drift`
                to `False` for all sessions.
                &#39;&#39;&#39;
                self.sessions = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                        for s in sorted({r[&#39;Session&#39;] for r in self})
                        }
                for s in self.sessions:
                        self.sessions[s][&#39;scrambling_drift&#39;] = False
                        self.sessions[s][&#39;slope_drift&#39;] = False
                        self.sessions[s][&#39;wg_drift&#39;] = False
                        self.sessions[s][&#39;d13C_standardization_method&#39;] = self.d13C_STANDARDIZATION_METHOD
                        self.sessions[s][&#39;d18O_standardization_method&#39;] = self.d18O_STANDARDIZATION_METHOD


        def refresh_samples(self):
                &#39;&#39;&#39;
                Define `self.samples`, `self.anchors`, and `self.unknowns`.
                &#39;&#39;&#39;
                self.samples = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                        for s in sorted({r[&#39;Sample&#39;] for r in self})
                        }
                self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D4x}
                self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D4x}


        def read(self, filename, sep = &#39;&#39;, session = &#39;&#39;):
                &#39;&#39;&#39;
                Read file in csv format to load data into a `D47data` object.

                In the csv file, spaces before and after field separators (`&#39;,&#39;` by default)
                are optional. Each line corresponds to a single analysis.

                The required fields are:

                + `UID`: a unique identifier
                + `Session`: an identifier for the analytical session
                + `Sample`: a sample identifier
                + `d45`, `d46`, and at least one of `d47` or `d48`: the working-gas delta values

                Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
                VSMOW, λ = `self.lambda_17`), and are otherwise assumed to be zero. Working-gas deltas `d47`, `d48`
                and `d49` are optional, and set to NaN by default.

                __Parameters__

                + `fileneme`: the path of the file to read
                + `sep`: csv separator delimiting the fields
                + `session`: set `Session` field to this string for all analyses
                &#39;&#39;&#39;
                with open(filename) as fid:
                        self.input(fid.read(), sep = sep, session = session)


        def input(self, txt, sep = &#39;&#39;, session = &#39;&#39;):
                &#39;&#39;&#39;
                Read `txt` string in csv format to load analysis data into a `D47data` object.

                In the csv string, spaces before and after field separators (`&#39;,&#39;` by default)
                are optional. Each line corresponds to a single analysis.

                The required fields are:

                + `UID`: a unique identifier
                + `Session`: an identifier for the analytical session
                + `Sample`: a sample identifier
                + `d45`, `d46`, and at least one of `d47` or `d48`: the working-gas delta values

                Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
                VSMOW, λ = `self.lambda_17`), and are otherwise assumed to be zero. Working-gas deltas `d47`, `d48`
                and `d49` are optional, and set to NaN by default.

                __Parameters__

                + `txt`: the csv string to read
                + `sep`: csv separator delimiting the fields. By default, use `,`, `;`, or `\t`,
                whichever appers most often in `txt`.
                + `session`: set `Session` field to this string for all analyses
                &#39;&#39;&#39;
                if sep == &#39;&#39;:
                        sep = sorted(&#39;,;\t&#39;, key = lambda x: - txt.count(x))[0]
                txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
                data = [{k: v if k in [&#39;UID&#39;, &#39;Session&#39;, &#39;Sample&#39;] else smart_type(v) for k,v in zip(txt[0], l) if v != &#39;&#39;} for l in txt[1:]]

                if session != &#39;&#39;:
                        for r in data:
                                r[&#39;Session&#39;] = session

                self += data
                self.refresh()


        @make_verbal
        def wg(self, samples = None, a18_acid = None):
                &#39;&#39;&#39;
                Compute bulk composition of the working gas for each session based on
                the carbonate standards defined in both `self.Nominal_d13C_VPDB` and
                `self.Nominal_d18O_VPDB`.
                &#39;&#39;&#39;

                self.msg(&#39;Computing WG composition:&#39;)

                if a18_acid is None:
                        a18_acid = self.ALPHA_18O_ACID_REACTION
                if samples is None:
                        samples = [s for s in self.Nominal_d13C_VPDB if s in self.Nominal_d18O_VPDB]

                assert a18_acid, f&#39;Acid fractionation factor should not be zero.&#39;

                samples = [s for s in samples if s in self.Nominal_d13C_VPDB and s in self.Nominal_d18O_VPDB]
                R45R46_standards = {}
                for sample in samples:
                        d13C_vpdb = self.Nominal_d13C_VPDB[sample]
                        d18O_vpdb = self.Nominal_d18O_VPDB[sample]
                        R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
                        R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
                        R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

                        C12_s = 1 / (1 + R13_s)
                        C13_s = R13_s / (1 + R13_s)
                        C16_s = 1 / (1 + R17_s + R18_s)
                        C17_s = R17_s / (1 + R17_s + R18_s)
                        C18_s = R18_s / (1 + R17_s + R18_s)

                        C626_s = C12_s * C16_s ** 2
                        C627_s = 2 * C12_s * C16_s * C17_s
                        C628_s = 2 * C12_s * C16_s * C18_s
                        C636_s = C13_s * C16_s ** 2
                        C637_s = 2 * C13_s * C16_s * C17_s
                        C727_s = C12_s * C17_s ** 2

                        R45_s = (C627_s + C636_s) / C626_s
                        R46_s = (C628_s + C637_s + C727_s) / C626_s
                        R45R46_standards[sample] = (R45_s, R46_s)
                
                for s in self.sessions:
                        db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in samples]
                        assert db, f&#39;No sample from {samples} found in session &#34;{s}&#34;.&#39;
#                       dbsamples = sorted({r[&#39;Sample&#39;] for r in db})

                        X = [r[&#39;d45&#39;] for r in db]
                        Y = [R45R46_standards[r[&#39;Sample&#39;]][0] for r in db]
                        x1, x2 = np.min(X), np.max(X)

                        if x1 &lt; x2:
                                wgcoord = x1/(x1-x2)
                        else:
                                wgcoord = 999

                        if wgcoord &lt; -.5 or wgcoord &gt; 1.5:
                                # unreasonable to extrapolate to d45 = 0
                                R45_wg = np.mean([y/(1+x/1000) for x,y in zip(X,Y)])
                        else :
                                # d45 = 0 is reasonably well bracketed
                                R45_wg = np.polyfit(X, Y, 1)[1]

                        X = [r[&#39;d46&#39;] for r in db]
                        Y = [R45R46_standards[r[&#39;Sample&#39;]][1] for r in db]
                        x1, x2 = np.min(X), np.max(X)

                        if x1 &lt; x2:
                                wgcoord = x1/(x1-x2)
                        else:
                                wgcoord = 999

                        if wgcoord &lt; -.5 or wgcoord &gt; 1.5:
                                # unreasonable to extrapolate to d46 = 0
                                R46_wg = np.mean([y/(1+x/1000) for x,y in zip(X,Y)])
                        else :
                                # d46 = 0 is reasonably well bracketed
                                R46_wg = np.polyfit(X, Y, 1)[1]

                        d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_delta(R45_wg, R46_wg)

                        self.msg(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                        self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                        for r in self.sessions[s][&#39;data&#39;]:
                                r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                                r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW


        def compute_bulk_delta(self, R45, R46, D17O = 0):
                &#39;&#39;&#39;
                Compute δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; and δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;,
                by solving the generalized form of equation (17) from [Brand et al. (2010)],
                assuming that δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; is not too big (0 ± 50 ‰) and
                solving the corresponding second-order Taylor polynomial.
                (Appendix A of [Daëron et al., 2016])

                [Brand et al. (2010)]: https://doi.org/10.1351/PAC-REP-09-01-05
                [Daëron et al., 2016]: https://doi.org/10.1016/j.chemgeo.2016.08.014
                &#39;&#39;&#39;

                K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

                A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
                B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
                C = 2 * self.R18_VSMOW
                D = -R46

                aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
                bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
                cc = A + B + C + D

                d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

                R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
                R17 = K * R18 ** self.lambda_17
                R13 = R45 - 2 * R17

                d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

                return d13C_VPDB, d18O_VSMOW


        @make_verbal
        def crunch(self, verbose = &#39;&#39;):
                &#39;&#39;&#39;
                Compute bulk composition and raw clumped isotope anomalies for all analyses.
                &#39;&#39;&#39;
                for r in self:
                        self.compute_bulk_and_clumping_deltas(r)
                self.standardize_d13C()
                self.standardize_d18O()
                self.msg(f&#34;Crunched {len(self)} analyses.&#34;)


        def fill_in_missing_info(self, session = &#39;mySession&#39;):
                &#39;&#39;&#39;
                Fill in optional fields with default values
                &#39;&#39;&#39;
                for i,r in enumerate(self):
                        if &#39;D17O&#39; not in r:
                                r[&#39;D17O&#39;] = 0.
                        if &#39;UID&#39; not in r:
                                r[&#39;UID&#39;] = f&#39;{i+1}&#39;
                        if &#39;Session&#39; not in r:
                                r[&#39;Session&#39;] = session
                        for k in [&#39;d47&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                                if k not in r:
                                        r[k] = np.nan


        def standardize_d13C(self):
                &#39;&#39;&#39;
                Perform δ&lt;sup&gt;13&lt;/sup&gt;C standadization within each session `s` according to
                `self.sessions[s][&#39;d13C_standardization_method&#39;]`, which is defined by default
                by `D47data.refresh_sessions()`as equal to `self.d13C_STANDARDIZATION_METHOD`, but
                may be redefined abitrarily at a later stage.
                &#39;&#39;&#39;
                for s in self.sessions:
                        if self.sessions[s][&#39;d13C_standardization_method&#39;] in [&#39;1pt&#39;, &#39;2pt&#39;]:
                                XY = [(r[&#39;d13C_VPDB&#39;], self.Nominal_d13C_VPDB[r[&#39;Sample&#39;]]) for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in self.Nominal_d13C_VPDB]
                                X,Y = zip(*XY)
                                if self.sessions[s][&#39;d13C_standardization_method&#39;] == &#39;1pt&#39;:
                                        offset = np.mean(Y) - np.mean(X)
                                        for r in self.sessions[s][&#39;data&#39;]:
                                                r[&#39;d13C_VPDB&#39;] += offset                                
                                elif self.sessions[s][&#39;d13C_standardization_method&#39;] == &#39;2pt&#39;:
                                        a,b = np.polyfit(X,Y,1)
                                        for r in self.sessions[s][&#39;data&#39;]:
                                                r[&#39;d13C_VPDB&#39;] = a * r[&#39;d13C_VPDB&#39;] + b

        def standardize_d18O(self):
                &#39;&#39;&#39;
                Perform δ&lt;sup&gt;18&lt;/sup&gt;O standadization within each session `s` according to
                `self.ALPHA_18O_ACID_REACTION` and `self.sessions[s][&#39;d18O_standardization_method&#39;]`,
                which is defined by default by `D47data.refresh_sessions()`as equal to
                `self.d18O_STANDARDIZATION_METHOD`, but may be redefined abitrarily at a later stage.
                &#39;&#39;&#39;
                for s in self.sessions:
                        if self.sessions[s][&#39;d18O_standardization_method&#39;] in [&#39;1pt&#39;, &#39;2pt&#39;]:
                                XY = [(r[&#39;d18O_VSMOW&#39;], self.Nominal_d18O_VPDB[r[&#39;Sample&#39;]]) for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in self.Nominal_d18O_VPDB]
                                X,Y = zip(*XY)
                                Y = [(1000+y) * self.R18_VPDB * self.ALPHA_18O_ACID_REACTION / self.R18_VSMOW - 1000 for y in Y]
                                if self.sessions[s][&#39;d18O_standardization_method&#39;] == &#39;1pt&#39;:
                                        offset = np.mean(Y) - np.mean(X)
                                        for r in self.sessions[s][&#39;data&#39;]:
                                                r[&#39;d18O_VSMOW&#39;] += offset                               
                                elif self.sessions[s][&#39;d18O_standardization_method&#39;] == &#39;2pt&#39;:
                                        a,b = np.polyfit(X,Y,1)
                                        for r in self.sessions[s][&#39;data&#39;]:
                                                r[&#39;d18O_VSMOW&#39;] = a * r[&#39;d18O_VSMOW&#39;] + b
        

        def compute_bulk_and_clumping_deltas(self, r):
                &#39;&#39;&#39;
                Compute δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt;, δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;, and
                raw Δ&lt;sub&gt;47&lt;/sub&gt;, Δ&lt;sub&gt;48&lt;/sub&gt;, Δ&lt;sub&gt;49&lt;/sub&gt; values for an analysis `r`.
                &#39;&#39;&#39;

                # Compute working gas R13, R18, and isobar ratios
                R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
                R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
                R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

                # Compute analyte isobar ratios
                R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
                R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
                R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
                R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
                R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

                r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_delta(R45, R46, D17O = r[&#39;D17O&#39;])
                R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
                R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

                # Compute stochastic isobar ratios of the analyte
                R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                        R13, R18, D17O = r[&#39;D17O&#39;]
                )

                # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
                # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
                if (R45 / R45stoch - 1) &gt; 5e-8:
                        self.vmsg(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):.3f} ppm&#39;)
                if (R46 / R46stoch - 1) &gt; 5e-8:
                        self.vmsg(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):.3f} ppm&#39;)

                # Compute raw clumped isotope anomalies
                r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
                r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
                r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)


        def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
                &#39;&#39;&#39;
                Compute isobar ratios for a sample with isotopic ratios `R13` and `R18`,
                optionally accounting for non-zero values of Δ&lt;sup&gt;17&lt;/sup&gt;O (`D17O`) and clumped isotope
                anomalies (`D47`, `D48`, `D49`), all expressed in permil.
                &#39;&#39;&#39;

                # Compute R17
                R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

                # Compute isotope concentrations
                C12 = (1 + R13) ** -1
                C13 = C12 * R13
                C16 = (1 + R17 + R18) ** -1
                C17 = C16 * R17
                C18 = C16 * R18

                # Compute stochastic isotopologue concentrations
                C626 = C16 * C12 * C16
                C627 = C16 * C12 * C17 * 2
                C628 = C16 * C12 * C18 * 2
                C636 = C16 * C13 * C16
                C637 = C16 * C13 * C17 * 2
                C638 = C16 * C13 * C18 * 2
                C727 = C17 * C12 * C17
                C728 = C17 * C12 * C18 * 2
                C737 = C17 * C13 * C17
                C738 = C17 * C13 * C18 * 2
                C828 = C18 * C12 * C18
                C838 = C18 * C13 * C18

                # Compute stochastic isobar ratios
                R45 = (C636 + C627) / C626
                R46 = (C628 + C637 + C727) / C626
                R47 = (C638 + C728 + C737) / C626
                R48 = (C738 + C828) / C626
                R49 = C838 / C626

                # Account for stochastic anomalies
                R47 *= 1 + D47 / 1000
                R48 *= 1 + D48 / 1000
                R49 *= 1 + D49 / 1000

                # Return isobar ratios
                return R45, R46, R47, R48, R49


        def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_session&#39;):
                &#39;&#39;&#39;
                Split unknown samples by UID (treat all analyses as different samples)
                or by session (treat analyses of a given sample in different sessions as
                different samples).

                __Parameters__

                + `samples_to_split`: a list of samples to split, e.g., `[&#39;IAEA-C1&#39;, &#39;IAEA-C2&#39;]`
                + `grouping`: `by_uid` | `by_session`
                &#39;&#39;&#39;
                if samples_to_split == &#39;all&#39;:
                        samples_to_split = [s for s in self.unknowns]
                gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
                self.grouping = grouping.lower()
                if self.grouping in gkeys:
                        gkey = gkeys[self.grouping]
                for r in self:
                        if r[&#39;Sample&#39;] in samples_to_split:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                        elif r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                self.refresh_samples()


        def unsplit_samples(self, tables = False):
                &#39;&#39;&#39;
                Reverse the effects of `D47data.split_samples()`.
                
                This should only be used after `D4xdata.standardize()` with `method=&#39;pooled&#39;`.
                
                After `D4xdata.standardize()` with `method=&#39;indep_sessions&#39;`, one should
                probably use `D4xdata.combine_samples()` instead to reverse the effects of
                `D47data.split_samples()` with `grouping=&#39;by_uid&#39;`, or `w_avg()` to reverse the
                effects of `D47data.split_samples()` with `grouping=&#39;by_sessions&#39;` (because in
                that case session-averaged Δ&lt;sub&gt;4x&lt;/sub&gt; values are statistically independent).
                &#39;&#39;&#39;
                unknowns_old = sorted({s for s in self.unknowns})
                CM_old = self.standardization.covar[:,:]
                VD_old = self.standardization.params.valuesdict().copy()
                vars_old = self.standardization.var_names

                unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})

                Ns = len(vars_old) - len(unknowns_old)
                vars_new = vars_old[:Ns] + [f&#39;D{self._4x}_{pf(u)}&#39; for u in unknowns_new]
                VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

                W = np.zeros((len(vars_new), len(vars_old)))
                W[:Ns,:Ns] = np.eye(Ns)
                for u in unknowns_new:
                        splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                        if self.grouping == &#39;by_session&#39;:
                                weights = [self.samples[s][f&#39;SE_D{self._4x}&#39;]**-2 for s in splits]
                        elif self.grouping == &#39;by_uid&#39;:
                                weights = [1 for s in splits]
                        sw = sum(weights)
                        weights = [w/sw for w in weights]
                        W[vars_new.index(f&#39;D{self._4x}_{pf(u)}&#39;),[vars_old.index(f&#39;D{self._4x}_{pf(s)}&#39;) for s in splits]] = weights[:]

                CM_new = W @ CM_old @ W.T
                V = W @ np.array([[VD_old[k]] for k in vars_old])
                VD_new = {k:v[0] for k,v in zip(vars_new, V)}

                self.standardization.covar = CM_new
                self.standardization.params.valuesdict = lambda : VD_new
                self.standardization.var_names = vars_new

                for r in self:
                        if r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]

                self.refresh_samples()
                self.consolidate_samples()
                self.repeatabilities()

                if tables:
                        self.table_of_analyses()
                        self.table_of_samples()

        def assign_timestamps(self):
                &#39;&#39;&#39;
                Assign a time field `t` of type `float` to each analysis.

                If `TimeTag` is one of the data fields, `t` is equal within a given session
                to `TimeTag` minus the mean value of `TimeTag` for that session.
                Otherwise, `TimeTag` is by default equal to the index of each analysis
                in the dataset and `t` is defined as above.
                &#39;&#39;&#39;
                for session in self.sessions:
                        sdata = self.sessions[session][&#39;data&#39;]
                        try:
                                t0 = np.mean([r[&#39;TimeTag&#39;] for r in sdata])
                                for r in sdata:
                                        r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
#                               print(&#39;DEBUG - USING TimeTag        &lt;-----------------------------------&#39;)
                        except KeyError:
                                t0 = (len(sdata)-1)/2
                                for t,r in enumerate(sdata):
                                        r[&#39;t&#39;] = t - t0


        def report(self):
                &#39;&#39;&#39;
                Prints a report on the standardization fit.
                Only applicable after `D4xdata.standardize(method=&#39;pooled&#39;)`.
                &#39;&#39;&#39;
                report_fit(self.standardization)


        def combine_samples(self, sample_groups):
                &#39;&#39;&#39;
                Combine analyses of different samples to compute weighted average Δ&lt;sub&gt;4x&lt;/sub&gt;
                and new error (co)variances corresponding to the groups defined by the `sample_groups`
                dictionary.
                
                Caution: samples are weighted by number of replicate analyses, which is a
                reasonable default behavior but is not always optimal (e.g., in the case of strongly
                correlated analytical errors for one or more samples).
                
                Returns a tuplet of:
                
                + the list of group names
                + an array of the corresponding Δ&lt;sub&gt;4x&lt;/sub&gt; values
                + the corresponding (co)variance matrix
                
                __Parameters__

                + `sample_groups`: a dictionary of the form:
                ```py
                {&#39;group1&#39;: [&#39;sample_1&#39;, &#39;sample_2&#39;],
                 &#39;group2&#39;: [&#39;sample_3&#39;, &#39;sample_4&#39;, &#39;sample_5&#39;]}
                ```
                &#39;&#39;&#39;
                
                samples = [s for k in sorted(sample_groups.keys()) for s in sorted(sample_groups[k])]
                groups = sorted(sample_groups.keys())
                group_total_weights = {k: sum([self.samples[s][&#39;N&#39;] for s in sample_groups[k]]) for k in groups}
                D4x_old = np.array([[self.samples[x][f&#39;D{self._4x}&#39;]] for x in samples])
                CM_old = np.array([[self.sample_D4x_covar(x,y) for x in samples] for y in samples])
                W = np.array([
                        [self.samples[i][&#39;N&#39;]/group_total_weights[j] if i in sample_groups[j] else 0 for i in samples]
                        for j in groups])
                D4x_new = W @ D4x_old
                CM_new = W @ CM_old @ W.T

                return groups, D4x_new[:,0], CM_new
                

        @make_verbal
        def standardize(self,
                method = &#39;pooled&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = False,
                consolidate_plots = False,
                constraints = {},
                ):
                &#39;&#39;&#39;
                Compute absolute Δ&lt;sub&gt;4x&lt;/sub&gt; values for all replicate analyses and for sample averages.
                If `method` argument is set to `&#39;pooled&#39;`, the standardization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous, i.e. that their true Δ&lt;sub&gt;4x&lt;/sub&gt; value does not change between sessions,
                ([Daëron, 2021]).
                If `method` argument is set to `&#39;indep_sessions&#39;`, the standardization processes each
                session independently, based only on anchors analyses.
                
                [Daëron, 2021]: https://doi.org/10.1029/2020GC009592
                &#39;&#39;&#39;

                self.standardization_method = method
                self.assign_timestamps()

                if method == &#39;pooled&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D4xdata([r for r in self if r[&#39;Session&#39;] in session_group], mass = self._4x)
                                        X.Nominal_D4x = self.Nominal_D4x.copy()
                                        X.refresh()
                                        result = X.standardize(method = &#39;pooled&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.msg(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[f&#39;wD{self._4x}raw&#39;] *= w
                        else:
                                self.msg(f&#39;All D{self._4x}raw weights set to 1 ‰&#39;)
                                for r in self:
                                        r[f&#39;wD{self._4x}raw&#39;] = 1.

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.msg(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.msg(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.msg(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D{self._4x}_{pf(sample)}&#39;, value = 0.5)

                        for k in constraints:
                                params[k].expr = constraints[k]

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D4x:
                                                R += [ (
                                                        r[f&#39;D{self._4x}raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D4x[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D4x[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[f&#39;wD{self._4x}raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[f&#39;D{self._4x}raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D{self._4x}_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D{self._4x}_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[f&#39;wD{self._4x}raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.least_squares()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[f&#39;D{self._4x}&#39;] = (r[f&#39;D{self._4x}raw&#39;] - c - b * r[f&#39;d{self._4x}&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[f&#39;d{self._4x}&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.standardization = result

                        for session in self.sessions:
                                self.sessions[session][&#39;Np&#39;] = 3
                                for k in [&#39;scrambling&#39;, &#39;slope&#39;, &#39;wg&#39;]:
                                        if self.sessions[session][f&#39;{k}_drift&#39;]:
                                                self.sessions[session][&#39;Np&#39;] += 1

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result


                elif method == &#39;indep_sessions&#39;:

                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D4xdata([r for r in self if r[&#39;Session&#39;] in session_group], mass = self._4x)
                                        X.Nominal_D4x = self.Nominal_D4x.copy()
                                        X.refresh()
                                        # This is only done to assign r[&#39;wD47raw&#39;] for r in X:
                                        X.standardize(method = method, weighted_sessions = [], consolidate = False)
                                        self.msg(f&#39;D{self._4x}raw weights set to {1000*X[0][f&#34;wD{self._4x}raw&#34;]:.1f} ppm for sessions in {session_group}&#39;)
                        else:
                                self.msg(&#39;All weights set to 1 ‰&#39;)
                                for r in self:
                                        r[f&#39;wD{self._4x}raw&#39;] = 1

                        for session in self.sessions:
                                s = self.sessions[session]
                                p_names = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;a2&#39;, &#39;b2&#39;, &#39;c2&#39;]
                                p_active = [True, True, True, s[&#39;scrambling_drift&#39;], s[&#39;slope_drift&#39;], s[&#39;wg_drift&#39;]]
                                s[&#39;Np&#39;] = sum(p_active)
                                sdata = s[&#39;data&#39;]

                                A = np.array([
                                        [
                                                self.Nominal_D4x[r[&#39;Sample&#39;]] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[f&#39;d{self._4x}&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                1 / r[f&#39;wD{self._4x}raw&#39;],
                                                self.Nominal_D4x[r[&#39;Sample&#39;]] * r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[f&#39;d{self._4x}&#39;] * r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;]
                                                ]
                                        for r in sdata if r[&#39;Sample&#39;] in self.anchors
                                        ])[:,p_active] # only keep columns for the active parameters
                                Y = np.array([[r[f&#39;D{self._4x}raw&#39;] / r[f&#39;wD{self._4x}raw&#39;]] for r in sdata if r[&#39;Sample&#39;] in self.anchors])
                                s[&#39;Na&#39;] = Y.size
                                CM = linalg.inv(A.T @ A)
                                bf = (CM @ A.T @ Y).T[0,:]
                                k = 0
                                for n,a in zip(p_names, p_active):
                                        if a:
                                                s[n] = bf[k]
#                                               self.msg(f&#39;{n} = {bf[k]}&#39;)
                                                k += 1
                                        else:
                                                s[n] = 0.
#                                               self.msg(f&#39;{n} = 0.0&#39;)

                                for r in sdata :
                                        a, b, c, a2, b2, c2 = s[&#39;a&#39;], s[&#39;b&#39;], s[&#39;c&#39;], s[&#39;a2&#39;], s[&#39;b2&#39;], s[&#39;c2&#39;]
                                        r[f&#39;D{self._4x}&#39;] = (r[f&#39;D{self._4x}raw&#39;] - c - b * r[f&#39;d{self._4x}&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[f&#39;d{self._4x}&#39;]) / (a + a2 * r[&#39;t&#39;])
                                        r[f&#39;wD{self._4x}&#39;] = r[f&#39;wD{self._4x}raw&#39;] / (a + a2 * r[&#39;t&#39;])

                                s[&#39;CM&#39;] = np.zeros((6,6))
                                i = 0
                                k_active = [j for j,a in enumerate(p_active) if a]
                                for j,a in enumerate(p_active):
                                        if a:
                                                s[&#39;CM&#39;][j,k_active] = CM[i,:]
                                                i += 1

                        if not weighted_sessions:
                                w = self.rmswd()[&#39;rmswd&#39;]
                                for r in self:
                                                r[f&#39;wD{self._4x}&#39;] *= w
                                                r[f&#39;wD{self._4x}raw&#39;] *= w
                                for session in self.sessions:
                                        self.sessions[session][&#39;CM&#39;] *= w**2

                        for session in self.sessions:
                                s = self.sessions[session]
                                s[&#39;SE_a&#39;] = s[&#39;CM&#39;][0,0]**.5
                                s[&#39;SE_b&#39;] = s[&#39;CM&#39;][1,1]**.5
                                s[&#39;SE_c&#39;] = s[&#39;CM&#39;][2,2]**.5
                                s[&#39;SE_a2&#39;] = s[&#39;CM&#39;][3,3]**.5
                                s[&#39;SE_b2&#39;] = s[&#39;CM&#39;][4,4]**.5
                                s[&#39;SE_c2&#39;] = s[&#39;CM&#39;][5,5]**.5

                        if not weighted_sessions:
                                self.Nf = len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        else:
                                self.Nf = 0
                                for sg in weighted_sessions:
                                        self.Nf += self.rmswd(sessions = sg)[&#39;Nf&#39;]

                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)

                        avgD4x = {
                                sample: np.mean([r[f&#39;D{self._4x}&#39;] for r in self if r[&#39;Sample&#39;] == sample])
                                for sample in self.samples
                                }
                        chi2 = np.sum([(r[f&#39;D{self._4x}&#39;] - avgD4x[r[&#39;Sample&#39;]])**2 for r in self])
                        rD4x = (chi2/self.Nf)**.5
                        self.repeatability[f&#39;sigma_{self._4x}&#39;] = rD4x

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)


        def standardization_error(self, session, d4x, D4x, t = 0):
                &#39;&#39;&#39;
                Compute standardization error for a given session and
                (δ&lt;sub&gt;47&lt;/sub&gt;, Δ&lt;sub&gt;47&lt;/sub&gt;) composition.
                &#39;&#39;&#39;
                a = self.sessions[session][&#39;a&#39;]
                b = self.sessions[session][&#39;b&#39;]
                c = self.sessions[session][&#39;c&#39;]
                a2 = self.sessions[session][&#39;a2&#39;]
                b2 = self.sessions[session][&#39;b2&#39;]
                c2 = self.sessions[session][&#39;c2&#39;]
                CM = self.sessions[session][&#39;CM&#39;]

                x, y = D4x, d4x
                z = a * x + b * y + c + a2 * x * t + b2 * y * t + c2 * t
#               x = (z - b*y - b2*y*t - c - c2*t) / (a+a2*t)
                dxdy = -(b+b2*t) / (a+a2*t)
                dxdz = 1. / (a+a2*t)
                dxda = -x / (a+a2*t)
                dxdb = -y / (a+a2*t)
                dxdc = -1. / (a+a2*t)
                dxda2 = -x * a2 / (a+a2*t)
                dxdb2 = -y * t / (a+a2*t)
                dxdc2 = -t / (a+a2*t)
                V = np.array([dxda, dxdb, dxdc, dxda2, dxdb2, dxdc2])
                sx = (V @ CM @ V.T) ** .5
                return sx


        @make_verbal
        def summary(self,
                dir = &#39;output&#39;,
                filename = None,
                save_to_file = True,
                print_out = True,
                ):
                &#39;&#39;&#39;
                Print out an/or save to disk a summary of the standardization results.

                __Parameters__

                + `dir`: the directory in which to save the table
                + `filename`: the name to the csv file to write to
                + `save_to_file`: whether to save the table to disk
                + `print_out`: whether to print out the table
                &#39;&#39;&#39;

                out = []
                out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
                out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
                out += [[&#39;Repeatability of δ13C_VPDB&#39;, f&#34;{1000 * self.repeatability[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
                out += [[&#39;Repeatability of δ18O_VSMOW&#39;, f&#34;{1000 * self.repeatability[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
                out += [[f&#39;Repeatability of Δ{self._4x} (anchors)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}a&#39;]:.1f} ppm&#34;]]
                out += [[f&#39;Repeatability of Δ{self._4x} (unknowns)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}u&#39;]:.1f} ppm&#34;]]
                out += [[f&#39;Repeatability of Δ{self._4x} (all)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}&#39;]:.1f} ppm&#34;]]
                out += [[&#39;Model degrees of freedom&#39;, f&#34;{self.Nf}&#34;]]
                out += [[&#39;Student\&#39;s 95% t-factor&#39;, f&#34;{self.t95:.2f}&#34;]]
                out += [[&#39;Standardization method&#39;, self.standardization_method]]

                if save_to_file:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename is None:
                                filename = f&#39;D{self._4x}_summary.csv&#39;
                        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                fid.write(make_csv(out))
                if print_out:
                        self.msg(&#39;\n&#39; + pretty_table(out, header = 0))


        @make_verbal
        def table_of_sessions(self,
                dir = &#39;output&#39;,
                filename = None,
                save_to_file = True,
                print_out = True,
                output = None,
                ):
                &#39;&#39;&#39;
                Print out an/or save to disk a table of sessions.

                __Parameters__

                + `dir`: the directory in which to save the table
                + `filename`: the name to the csv file to write to
                + `save_to_file`: whether to save the table to disk
                + `print_out`: whether to print out the table
                + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                    if set to `&#39;raw&#39;`: return a list of list of strings
                    (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
                &#39;&#39;&#39;
                include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
                include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
                include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])

                out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,f&#39;r_D{self._4x}&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
                if include_a2:
                        out[-1] += [&#39;a2 ± SE&#39;]
                if include_b2:
                        out[-1] += [&#39;b2 ± SE&#39;]
                if include_c2:
                        out[-1] += [&#39;c2 ± SE&#39;]
                for session in self.sessions:
                        out += [[
                                session,
                                f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][f&#39;r_D{self._4x}&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                                f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                                ]]
                        if include_a2:
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_b2:
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_c2:
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]

                if save_to_file:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename is None:
                                filename = f&#39;D{self._4x}_sessions.csv&#39;
                        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                fid.write(make_csv(out))
                if print_out:
                        self.msg(&#39;\n&#39; + pretty_table(out))
                if output == &#39;raw&#39;:
                        return out
                elif output == &#39;pretty&#39;:
                        return pretty_table(out)


        @make_verbal
        def table_of_analyses(
                self,
                dir = &#39;output&#39;,
                filename = None,
                save_to_file = True,
                print_out = True,
                output = None,
                ):
                &#39;&#39;&#39;
                Print out an/or save to disk a table of analyses.

                __Parameters__

                + `dir`: the directory in which to save the table
                + `filename`: the name to the csv file to write to
                + `save_to_file`: whether to save the table to disk
                + `print_out`: whether to print out the table
                + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                    if set to `&#39;raw&#39;`: return a list of list of strings
                    (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
                &#39;&#39;&#39;

                out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
                extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
                for f in extra_fields:
                        out[-1] += [f[0]]
                out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,f&#39;D{self._4x}&#39;]
                for r in self:
                        out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                        for f in extra_fields:
                                out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                        out[-1] += [
                                f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d13C_VPDB&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d18O_VSMOW&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                                f&#34;{r[f&#39;D{self._4x}&#39;]:.6f}&#34;
                                ]
                if save_to_file:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename is None:
                                filename = f&#39;D{self._4x}_analyses.csv&#39;
                        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                fid.write(make_csv(out))
                if print_out:
                        self.msg(&#39;\n&#39; + pretty_table(out))
                return out


        @make_verbal
        def table_of_samples(
                self,
                dir = &#39;output&#39;,
                filename = None,
                save_to_file = True,
                print_out = True,
                output = None,
                ):
                &#39;&#39;&#39;
                Print out, save to disk and/or return a table of samples.

                __Parameters__

                + `dir`: the directory in which to save the table
                + `filename`: the name to the csv file to write to
                + `save_to_file`: whether to save the table to disk
                + `print_out`: whether to print out the table
                + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                    if set to `&#39;raw&#39;`: return a list of list of strings
                    (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
                &#39;&#39;&#39;

                out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,f&#39;D{self._4x}&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
                for sample in self.anchors:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][f&#39;D{self._4x}&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                                f&#34;{self.samples[sample][f&#39;SD_D{self._4x}&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                                ]]
                for sample in self.unknowns:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][f&#39;D{self._4x}&#39;]:.4f}&#34;,
                                f&#34;{self.samples[sample][f&#39;SE_D{self._4x}&#39;]:.4f}&#34;,
                                f&#34;± {self.samples[sample][f&#39;SE_D{self._4x}&#39;] * self.t95:.4f}&#34;,
                                f&#34;{self.samples[sample][f&#39;SD_D{self._4x}&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                                f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 2 else &#39;&#39;
                                ]]
                if save_to_file:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename is None:
                                filename = f&#39;D{self._4x}_samples.csv&#39;
                        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                fid.write(make_csv(out))
                if print_out:
                        self.msg(&#39;\n&#39;+pretty_table(out))
                if output == &#39;raw&#39;:
                        return out
                elif output == &#39;pretty&#39;:
                        return pretty_table(out)


        def plot_sessions(self, dir = &#39;output&#39;, figsize = (8,8)):
                &#39;&#39;&#39;
                Generate session plots and save them to disk.

                __Parameters__

                + `dir`: the directory in which to save the plots
                + `figsize`: the width and height (in inches) of each plot
                &#39;&#39;&#39;
                if not os.path.exists(dir):
                        os.makedirs(dir)

                for session in self.sessions:
                        sp = self.plot_single_session(session, xylimits = &#39;constant&#39;)
                        ppl.savefig(f&#39;{dir}/D{self._4x}_plot_{session}.pdf&#39;)
                        ppl.close(sp.fig)


        @make_verbal
        def consolidate_samples(self):
                &#39;&#39;&#39;
                Compile various statistics for each sample.

                For each anchor sample:

                + `D47` or `D48`: the nominal Δ&lt;sub&gt;4x&lt;/sub&gt; value for this anchor, specified by `self.Nominal_D4x`
                + `SE_D47` or `SE_D48`: set to zero by definition

                For each unknown sample:

                + `D47` or `D48`: the standardized Δ&lt;sub&gt;4x&lt;/sub&gt; value for this unknown
                + `SE_D47` or `SE_D48`: the standard error of Δ&lt;sub&gt;4x&lt;/sub&gt; for this unknown

                For each anchor and unknown:

                + `N`: the total number of analyses of this sample
                + `SD_D47` or `SD_D48`: the “sample” (in the statistical sense) standard deviation for this sample
                + `d13C_VPDB`: the average δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; value for this sample
                + `d18O_VSMOW`: the average δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; value for this sample (as CO&lt;sub&gt;2&lt;/sub&gt;)
                + `p_Levene`: the p-value from a [Levene test] of equal variance, indicating whether
                the Δ&lt;sub&gt;4x&lt;/sub&gt; repeatability this sample differs significantly from that observed
                for the reference sample specified by `self.LEVENE_REF_SAMPLE`.

                [Levene test]: https://en.wikipedia.org/wiki/Levene%27s_test
                &#39;&#39;&#39;
                D4x_ref_pop = [r[f&#39;D{self._4x}&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]
                for sample in self.samples:
                        self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                        if self.samples[sample][&#39;N&#39;] &gt; 1:
                                self.samples[sample][f&#39;SD_D{self._4x}&#39;] = stdev([r[f&#39;D{self._4x}&#39;] for r in self.samples[sample][&#39;data&#39;]])

                        self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                        self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

                        D4x_pop = [r[f&#39;D{self._4x}&#39;] for r in self.samples[sample][&#39;data&#39;]]
                        if len(D4x_pop) &gt; 2:
                                self.samples[sample][&#39;p_Levene&#39;] = levene(D4x_ref_pop, D4x_pop, center = &#39;median&#39;)[1]

                if self.standardization_method == &#39;pooled&#39;:
                        for sample in self.anchors:
                                self.samples[sample][f&#39;D{self._4x}&#39;] = self.Nominal_D4x[sample]
                                self.samples[sample][f&#39;SE_D{self._4x}&#39;] = 0.
                        for sample in self.unknowns:
                                self.samples[sample][f&#39;D{self._4x}&#39;] = self.standardization.params.valuesdict()[f&#39;D{self._4x}_{pf(sample)}&#39;]
                                try:
                                        self.samples[sample][f&#39;SE_D{self._4x}&#39;] = self.sample_D4x_covar(sample)**.5
                                except ValueError:
                                        # when `sample` is constrained by self.standardize(constraints = {...}),
                                        # it is no longer listed in self.standardization.var_names.
                                        # Temporary fix: define SE as zero for now
                                        self.samples[sample][f&#39;SE_D4{self._4x}&#39;] = 0.

                elif self.standardization_method == &#39;indep_sessions&#39;:
                        for sample in self.anchors:
                                self.samples[sample][f&#39;D{self._4x}&#39;] = self.Nominal_D4x[sample]
                                self.samples[sample][f&#39;SE_D{self._4x}&#39;] = 0.
                        for sample in self.unknowns:
                                self.msg(f&#39;Consolidating sample {sample}&#39;)
                                self.unknowns[sample][f&#39;session_D{self._4x}&#39;] = {}
                                session_avg = []
                                for session in self.sessions:
                                        sdata = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                                        if sdata:
                                                self.msg(f&#39;{sample} found in session {session}&#39;)
                                                avg_D4x = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata])
                                                avg_d4x = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata])
                                                # !! TODO: sigma_s below does not account for temporal changes in standardization error
                                                sigma_s = self.standardization_error(session, avg_d4x, avg_D4x)
                                                sigma_u = sdata[0][f&#39;wD{self._4x}raw&#39;] / self.sessions[session][&#39;a&#39;] / len(sdata)**.5
                                                session_avg.append([avg_D4x, (sigma_u**2 + sigma_s**2)**.5])
                                                self.unknowns[sample][f&#39;session_D{self._4x}&#39;][session] = session_avg[-1]
                                self.samples[sample][f&#39;D{self._4x}&#39;], self.samples[sample][f&#39;SE_D{self._4x}&#39;] = w_avg(*zip(*session_avg))
                                weights = {s: self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s][1]**-2 for s in self.unknowns[sample][f&#39;session_D{self._4x}&#39;]}
                                wsum = sum([weights[s] for s in weights])
                                for s in weights:
                                        self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s] += [self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s][1]**-2 / wsum]


        def consolidate_sessions(self):
                &#39;&#39;&#39;
                Compute various statistics for each session.

                + `Na`: Number of anchor analyses in the session
                + `Nu`: Number of unknown analyses in the session
                + `r_d13C_VPDB`: δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; repeatability of analyses within the session
                + `r_d18O_VSMOW`: δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; repeatability of analyses within the session
                + `r_D47` or `r_D48`: Δ&lt;sub&gt;4x&lt;/sub&gt; repeatability of analyses within the session
                + `a`: scrambling factor
                + `b`: compositional slope
                + `c`: WG offset
                + `SE_a`: Model stadard erorr of `a`
                + `SE_b`: Model stadard erorr of `b`
                + `SE_c`: Model stadard erorr of `c`
                + `scrambling_drift` (boolean): whether to allow a temporal drift in the scrambling factor (`a`)
                + `slope_drift` (boolean): whether to allow a temporal drift in the compositional slope (`b`)
                + `wg_drift` (boolean): whether to allow a temporal drift in the WG offset (`c`)
                + `a2`: scrambling factor drift
                + `b2`: compositional slope drift
                + `c2`: WG offset drift
                + `Np`: Number of standardization parameters to fit
                + `CM`: model covariance matrix for (`a`, `b`, `c`, `a2`, `b2`, `c2`)
                + `d13Cwg_VPDB`: δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; of WG
                + `d18Owg_VSMOW`: δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; of WG
                &#39;&#39;&#39;
                for session in self.sessions:
                        if &#39;d13Cwg_VPDB&#39; not in self.sessions[session]:
                                self.sessions[session][&#39;d13Cwg_VPDB&#39;] = self.sessions[session][&#39;data&#39;][0][&#39;d13Cwg_VPDB&#39;]
                        if &#39;d18Owg_VSMOW&#39; not in self.sessions[session]:
                                self.sessions[session][&#39;d18Owg_VSMOW&#39;] = self.sessions[session][&#39;data&#39;][0][&#39;d18Owg_VSMOW&#39;]
                        self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                        self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])

                        self.msg(f&#39;Computing repeatabilities for session {session}&#39;)
                        self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_r(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_r(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][f&#39;r_D{self._4x}&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, sessions = [session])

                if self.standardization_method == &#39;pooled&#39;:
                        for session in self.sessions:

                                self.sessions[session][&#39;a&#39;] = self.standardization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                                i = self.standardization.var_names.index(f&#39;a_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_a&#39;] = self.standardization.covar[i,i]**.5

                                self.sessions[session][&#39;b&#39;] = self.standardization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                                i = self.standardization.var_names.index(f&#39;b_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_b&#39;] = self.standardization.covar[i,i]**.5

                                self.sessions[session][&#39;c&#39;] = self.standardization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                                i = self.standardization.var_names.index(f&#39;c_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_c&#39;] = self.standardization.covar[i,i]**.5

                                self.sessions[session][&#39;a2&#39;] = self.standardization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        i = self.standardization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_a2&#39;] = self.standardization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_a2&#39;] = 0.

                                self.sessions[session][&#39;b2&#39;] = self.standardization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        i = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_b2&#39;] = self.standardization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_b2&#39;] = 0.

                                self.sessions[session][&#39;c2&#39;] = self.standardization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        i = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_c2&#39;] = self.standardization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_c2&#39;] = 0.

                                i = self.standardization.var_names.index(f&#39;a_{pf(session)}&#39;)
                                j = self.standardization.var_names.index(f&#39;b_{pf(session)}&#39;)
                                k = self.standardization.var_names.index(f&#39;c_{pf(session)}&#39;)
                                CM = np.zeros((6,6))
                                CM[:3,:3] = self.standardization.covar[[i,j,k],:][:,[i,j,k]]
                                try:
                                        i2 = self.standardization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                        CM[3,[0,1,2,3]] = self.standardization.covar[i2,[i,j,k,i2]]
                                        CM[[0,1,2,3],3] = self.standardization.covar[[i,j,k,i2],i2]
                                        try:
                                                j2 = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                                CM[3,4] = self.standardization.covar[i2,j2]
                                                CM[4,3] = self.standardization.covar[j2,i2]
                                        except ValueError:
                                                pass
                                        try:
                                                k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                                CM[3,5] = self.standardization.covar[i2,k2]
                                                CM[5,3] = self.standardization.covar[k2,i2]
                                        except ValueError:
                                                pass
                                except ValueError:
                                        pass
                                try:
                                        j2 = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                        CM[4,[0,1,2,4]] = self.standardization.covar[j2,[i,j,k,j2]]
                                        CM[[0,1,2,4],4] = self.standardization.covar[[i,j,k,j2],j2]
                                        try:
                                                k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                                CM[4,5] = self.standardization.covar[j2,k2]
                                                CM[5,4] = self.standardization.covar[k2,j2]
                                        except ValueError:
                                                pass
                                except ValueError:
                                        pass
                                try:
                                        k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                        CM[5,[0,1,2,5]] = self.standardization.covar[k2,[i,j,k,k2]]
                                        CM[[0,1,2,5],5] = self.standardization.covar[[i,j,k,k2],k2]
                                except ValueError:
                                        pass

                                self.sessions[session][&#39;CM&#39;] = CM

                elif self.standardization_method == &#39;indep_sessions&#39;:
                        pass # Not implemented yet


        @make_verbal
        def repeatabilities(self):
                &#39;&#39;&#39;
                Compute analytical repeatabilities for δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt;,
                δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;, Δ&lt;sub&gt;4x&lt;/sub&gt; (for all samples, for anchors,
                and for unknowns).
                &#39;&#39;&#39;
                self.msg(&#39;Computing reproducibilities for all sessions&#39;)

                self.repeatability[&#39;r_d13C_VPDB&#39;] = self.compute_r(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
                self.repeatability[&#39;r_d18O_VSMOW&#39;] = self.compute_r(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)
                self.repeatability[f&#39;r_D{self._4x}a&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;anchors&#39;)
                self.repeatability[f&#39;r_D{self._4x}u&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;unknowns&#39;)
                self.repeatability[f&#39;r_D{self._4x}&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;all samples&#39;)


        @make_verbal
        def consolidate(self, tables = True, plots = True):
                &#39;&#39;&#39;
                Collect information about samples, sessions and repeatabilities.
                &#39;&#39;&#39;
                self.consolidate_samples()
                self.consolidate_sessions()
                self.repeatabilities()

                if tables:
                        self.summary()
                        self.table_of_sessions()
                        self.table_of_analyses()
                        self.table_of_samples()

                if plots:
                        self.plot_sessions()


        @make_verbal
        def rmswd(self,
                samples = &#39;all samples&#39;,
                sessions = &#39;all sessions&#39;,
                ):
                &#39;&#39;&#39;
                Compute the χ&lt;sup&gt;2&lt;/sup&gt;, root mean squared weighted deviation
                (i.e. reduced χ&lt;sup&gt;2&lt;/sup&gt;), and corresponding degrees of freedom of the
                Δ&lt;sub&gt;4x&lt;/sub&gt; values for samples in `samples` and sessions in `sessions`.
                
                Only used in `D4xdata.standardize()` with `method=&#39;indep_sessions&#39;`.
                &#39;&#39;&#39;
                if samples == &#39;all samples&#39;:
                        mysamples = [k for k in self.samples]
                elif samples == &#39;anchors&#39;:
                        mysamples = [k for k in self.anchors]
                elif samples == &#39;unknowns&#39;:
                        mysamples = [k for k in self.unknowns]
                else:
                        mysamples = samples

                if sessions == &#39;all sessions&#39;:
                        sessions = [k for k in self.sessions]

                chisq, Nf = 0, 0
                for sample in mysamples :
                        G = [ r for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                        if len(G) &gt; 1 :
                                X, sX = w_avg([r[f&#39;D{self._4x}&#39;] for r in G], [r[f&#39;wD{self._4x}&#39;] for r in G])
                                Nf += (len(G) - 1)
                                chisq += np.sum([ ((r[f&#39;D{self._4x}&#39;]-X)/r[f&#39;wD{self._4x}&#39;])**2 for r in G])
                r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
                self.msg(f&#39;RMSWD of r[&#34;D{self._4x}&#34;] is {r:.6f} for {samples}.&#39;)
                return {&#39;rmswd&#39;: r, &#39;chisq&#39;: chisq, &#39;Nf&#39;: Nf}

        
        @make_verbal
        def compute_r(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
                &#39;&#39;&#39;
                Compute the repeatability of `[r[key] for r in self]`
                &#39;&#39;&#39;
                # NB: it&#39;s debatable whether rD47 should be computed
                # with Nf = len(self)-len(self.samples) instead of
                # Nf = len(self) - len(self.unknwons) - 3*len(self.sessions)

                if samples == &#39;all samples&#39;:
                        mysamples = [k for k in self.samples]
                elif samples == &#39;anchors&#39;:
                        mysamples = [k for k in self.anchors]
                elif samples == &#39;unknowns&#39;:
                        mysamples = [k for k in self.unknowns]
                else:
                        mysamples = samples

                if sessions == &#39;all sessions&#39;:
                        sessions = [k for k in self.sessions]

                if key in [&#39;D47&#39;, &#39;D48&#39;]:
                        chisq, Nf = 0, 0
                        for sample in mysamples :
                                X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                                if len(X) &gt; 1 :
                                        chisq += np.sum([ (x-self.samples[sample][key])**2 for x in X ])
                                        if sample in self.unknowns:
                                                Nf += len(X) - 1
                                        else:
                                                Nf += len(X)
                        if samples in [&#39;anchors&#39;, &#39;all samples&#39;]:
                                Nf -= sum([self.sessions[s][&#39;Np&#39;] for s in sessions])
                        r = (chisq / Nf)**.5 if Nf &gt; 0 else 0

                else: # if key not in [&#39;D47&#39;, &#39;D48&#39;]
                        chisq, Nf = 0, 0
                        for sample in mysamples :
                                X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                                if len(X) &gt; 1 :
                                        Nf += len(X) - 1
                                        chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
                        r = (chisq / Nf)**.5 if Nf &gt; 0 else 0

                self.msg(f&#39;Repeatability of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
                return r

        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Weighted average Δ&lt;sub&gt;4x&lt;/sub&gt; value of a group of samples, accounting for covariance.

                Returns the weighed average Δ&lt;sub&gt;4x&lt;/sub&gt; value and associated SE
                of a group of samples. Weights are equal by default. If `normalize` is
                true, `weights` will be rescaled so that their sum equals 1.

                __Examples__

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])
                ```

                returns the value and SE of [Δ&lt;sub&gt;4x&lt;/sub&gt;(X) + 2 Δ&lt;sub&gt;4x&lt;/sub&gt;(Y)]/3,
                where Δ&lt;sub&gt;4x&lt;/sub&gt;(X) and Δ&lt;sub&gt;4x&lt;/sub&gt;(Y) are the average Δ&lt;sub&gt;4x&lt;/sub&gt;
                values of samples X and Y, respectively.

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                ```

                returns the value and SE of the difference Δ&lt;sub&gt;4x&lt;/sub&gt;(X) - Δ&lt;sub&gt;4x&lt;/sub&gt;(Y).
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        if s:
                                weights = [w/s for w in weights]

                try:
#                       indices = [self.standardization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.standardization.covar[indices,:][:,indices]
                        C = np.array([[self.sample_D4x_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][f&#39;D{self._4x}&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)


        def sample_D4x_covar(self, sample1, sample2 = None):
                &#39;&#39;&#39;
                Covariance between Δ&lt;sub&gt;4x&lt;/sub&gt; values of samples

                Returns the error covariance between the average Δ&lt;sub&gt;4x&lt;/sub&gt; values of two
                samples. If if only `sample_1` is specified, or if `sample_1 == sample_2`),
                returns the Δ&lt;sub&gt;4x&lt;/sub&gt; variance for that sample.
                &#39;&#39;&#39;
                if sample2 is None:
                        sample2 = sample1
                if self.standardization_method == &#39;pooled&#39;:
                        i = self.standardization.var_names.index(f&#39;D{self._4x}_{pf(sample1)}&#39;)
                        j = self.standardization.var_names.index(f&#39;D{self._4x}_{pf(sample2)}&#39;)
                        return self.standardization.covar[i, j]
                elif self.standardization_method == &#39;indep_sessions&#39;:
                        if sample1 == sample2:
                                return self.samples[sample1][f&#39;SE_D{self._4x}&#39;]**2
                        else:
                                c = 0
                                for session in self.sessions:
                                        sdata1 = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample1]
                                        sdata2 = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample2]
                                        if sdata1 and sdata2:
                                                a = self.sessions[session][&#39;a&#39;]
                                                # !! TODO: CM below does not account for temporal changes in standardization parameters
                                                CM = self.sessions[session][&#39;CM&#39;][:3,:3]
                                                avg_D4x_1 = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata1])
                                                avg_d4x_1 = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata1])
                                                avg_D4x_2 = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata2])
                                                avg_d4x_2 = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata2])
                                                c += (
                                                        self.unknowns[sample1][f&#39;session_D{self._4x}&#39;][session][2]
                                                        * self.unknowns[sample2][f&#39;session_D{self._4x}&#39;][session][2]
                                                        * np.array([[avg_D4x_1, avg_d4x_1, 1]])
                                                        @ CM
                                                        @ np.array([[avg_D4x_2, avg_d4x_2, 1]]).T
                                                        ) / a**2
                                return float(c)

        def sample_D4x_correl(self, sample1, sample2 = None):
                &#39;&#39;&#39;
                Correlation between Δ&lt;sub&gt;4x&lt;/sub&gt; errors of samples

                Returns the error correlation between the average Δ4x values of two samples.
                &#39;&#39;&#39;
                if sample2 is None or sample2 == sample1:
                        return 1.
                return (
                        self.sample_D4x_covar(sample1, sample2)
                        / self.unknowns[sample1][f&#39;SE_D{self._4x}&#39;]
                        / self.unknowns[sample2][f&#39;SE_D{self._4x}&#39;]
                        )

        def plot_single_session(self,
                session,
                kw_plot_anchors = dict(ls=&#39;None&#39;, marker=&#39;x&#39;, mec=(.75, 0, 0), mew = .75, ms = 4),
                kw_plot_unknowns = dict(ls=&#39;None&#39;, marker=&#39;x&#39;, mec=(0, 0, .75), mew = .75, ms = 4),
                kw_plot_anchor_avg = dict(ls=&#39;-&#39;, marker=&#39;None&#39;, color=(.75, 0, 0), lw = .75),
                kw_plot_unknown_avg = dict(ls=&#39;-&#39;, marker=&#39;None&#39;, color=(0, 0, .75), lw = .75),
                kw_contour_error = dict(colors = [[0, 0, 0]], alpha = .5, linewidths = 0.75),
                xylimits = &#39;free&#39;, # | &#39;constant&#39;
                x_label = None,
                y_label = None,
                error_contour_interval = &#39;auto&#39;,
                fig = &#39;new&#39;,
                ):
                &#39;&#39;&#39;
                Generate plot for a single session
                &#39;&#39;&#39;
                if x_label is None:
                        x_label = f&#39;δ$_{{{self._4x}}}$ (‰)&#39;
                if y_label is None:
                        y_label = f&#39;Δ$_{{{self._4x}}}$ (‰)&#39;

                out = _SessionPlot()
                anchors = [a for a in self.anchors if [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == a]]
                unknowns = [u for u in self.unknowns if [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == u]]
                
                if fig == &#39;new&#39;:
                        out.fig = ppl.figure(figsize = (6,6))
                        ppl.subplots_adjust(.1,.1,.9,.9)

                out.anchor_analyses, = ppl.plot(
                        [r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors],
                        [r[f&#39;D{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors],
                        **kw_plot_anchors)
                out.unknown_analyses, = ppl.plot(
                        [r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns],
                        [r[f&#39;D{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns],
                        **kw_plot_unknowns)
                out.anchor_avg = ppl.plot(
                        np.array([ np.array([
                                np.min([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) - 1,
                                np.max([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) + 1
                                ]) for sample in anchors]).T,
                        np.array([ np.array([0, 0]) + self.Nominal_D4x[sample] for sample in anchors]).T,
                        **kw_plot_anchor_avg)
                out.unknown_avg = ppl.plot(
                        np.array([ np.array([
                                np.min([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) - 1,
                                np.max([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) + 1
                                ]) for sample in unknowns]).T,
                        np.array([ np.array([0, 0]) + self.unknowns[sample][f&#39;D{self._4x}&#39;] for sample in unknowns]).T,
                        **kw_plot_unknown_avg)
                if xylimits == &#39;constant&#39;:
                        x = [r[f&#39;d{self._4x}&#39;] for r in self]
                        y = [r[f&#39;D{self._4x}&#39;] for r in self]
                        x1, x2, y1, y2 = np.min(x), np.max(x), np.min(y), np.max(y)
                        w, h = x2-x1, y2-y1
                        x1 -= w/20
                        x2 += w/20
                        y1 -= h/20
                        y2 += h/20
                        ppl.axis([x1, x2, y1, y2])
                elif xylimits == &#39;free&#39;:
                        x1, x2, y1, y2 = ppl.axis()
                else:
                        x1, x2, y1, y2 = ppl.axis(xylimits)
                                
                if error_contour_interval != &#39;none&#39;:
                        xi, yi = np.linspace(x1, x2), np.linspace(y1, y2)
                        XI,YI = np.meshgrid(xi, yi)
                        SI = np.array([[self.standardization_error(session, x, y) for x in xi] for y in yi])
                        if error_contour_interval == &#39;auto&#39;:
                                rng = np.max(SI) - np.min(SI)
                                if rng &lt;= 0.01:
                                        cinterval = 0.001
                                elif rng &lt;= 0.03:
                                        cinterval = 0.004
                                elif rng &lt;= 0.1:
                                        cinterval = 0.01
                                elif rng &lt;= 0.3:
                                        cinterval = 0.03
                                elif rng &lt;= 1.:
                                        cinterval = 0.1
                                else:
                                        cinterval = 0.5
                        else:
                                cinterval = error_contour_interval

                        cval = np.arange(np.ceil(SI.min() / .001) * .001, np.ceil(SI.max() / .001 + 1) * .001, cinterval)
                        out.contour = ppl.contour(XI, YI, SI, cval, **kw_contour_error)
                        out.clabel = ppl.clabel(out.contour)

                ppl.xlabel(x_label)
                ppl.ylabel(y_label)
                ppl.title(session, weight = &#39;bold&#39;)
                ppl.grid(alpha = .2)
                out.ax = ppl.gca()              

                return out

        def plot_residuals(self, dir = &#39;output&#39;, filename = None, highlight = [], colors = None):
                &#39;&#39;&#39;
                Plot residuals of each analysis as a function of time (actually, as a function of
                the order of analyses in the D4xdata() object)

                + `dir`: the directory in which to save the plot
                + `highlight`: a list of samples to highlight
                + `colors`: a dict of {&lt;sample&gt;: &lt;color&gt;} for all samples
                &#39;&#39;&#39;
                fig = ppl.figure(figsize = (8,4))
                ppl.subplots_adjust(.1,.05,.78,.8)
                N = len(self.anchors)
                if colors is None:
                        if len(highlight) &gt; 0:
                                Nh = len(highlight)
                                if Nh == 1:
                                        colors = {highlight[0]: (0,0,0)}
                                elif Nh == 3:
                                        colors = {a: c for a,c in zip(highlight, [(0,0,1), (1,0,0), (0,2/3,0)])}
                                elif Nh == 4:
                                        colors = {a: c for a,c in zip(highlight, [(0,0,1), (1,0,0), (0,2/3,0), (.75,0,.75)])}
                                else:
                                        colors = {a: hls_to_rgb(k/Nh, .4, 1) for k,a in enumerate(highlight)}
                        else:
                                if N == 3:
                                        colors = {a: c for a,c in zip(self.anchors, [(0,0,1), (1,0,0), (0,2/3,0)])}
                                elif N == 4:
                                        colors = {a: c for a,c in zip(self.anchors, [(0,0,1), (1,0,0), (0,2/3,0), (.75,0,.75)])}
                                else:
                                        colors = {a: hls_to_rgb(k/N, .4, 1) for k,a in enumerate(self.anchors)}
                session = self[0][&#39;Session&#39;]
                x1 = 0
#               ymax = np.max([1e3 * (r[&#39;D47&#39;] - self.samples[r[&#39;Sample&#39;]][&#39;D47&#39;]) for r in self])
                x_sessions = {}
                one_or_more_singlets = False
                one_or_more_multiplets = False
                for k,r in enumerate(self):
                        if r[&#39;Session&#39;] != session:
                                x2 = k-1
                                x_sessions[session] = (x1+x2)/2
                                ppl.axvline(k - 0.5, color = &#39;k&#39;, lw = .5)
                                session = r[&#39;Session&#39;]
                                x1 = k
                        singlet = len(self.samples[r[&#39;Sample&#39;]][&#39;data&#39;]) == 1
                        if r[&#39;Sample&#39;] in self.unknowns:
                                if singlet:
                                        one_or_more_singlets = True
                                else:
                                        one_or_more_multiplets = True
                        kw = dict(
                                marker = &#39;x&#39; if singlet else &#39;+&#39;,
                                ms = 4 if singlet else 5,
                                ls = &#39;None&#39;,
                                mec = colors[r[&#39;Sample&#39;]] if r[&#39;Sample&#39;] in colors else (0,0,0),
                                mew = 1,
                                alpha = 0.2 if singlet else 1,
                                )
                        if highlight and r[&#39;Sample&#39;] not in highlight:
                                kw[&#39;alpha&#39;] = 0.2
                        ppl.plot(k, 1e3 * (r[&#39;D47&#39;] - self.samples[r[&#39;Sample&#39;]][&#39;D47&#39;]), **kw)
                x2 = k
                x_sessions[session] = (x1+x2)/2

                ppl.axhspan(-self.repeatability[&#39;r_D47&#39;]*1000, self.repeatability[&#39;r_D47&#39;]*1000, color = &#39;k&#39;, alpha = .05, lw = 1)
                ppl.text(len(self), self.repeatability[&#39;r_D47&#39;]*1000, f&#34;   SD = {self.repeatability[&#39;r_D47&#39;]*1000:.1f} ppm&#34;, size = 9, alpha = .75, va = &#39;center&#39;)
                ppl.axhspan(-self.repeatability[&#39;r_D47&#39;]*1000*self.t95, self.repeatability[&#39;r_D47&#39;]*1000*self.t95, color = &#39;k&#39;, alpha = .05, lw = 1)
                ppl.text(len(self), self.repeatability[&#39;r_D47&#39;]*1000*self.t95, f&#34;   95% CL: ± {self.repeatability[&#39;r_D47&#39;]*1000*self.t95:.1f} ppm&#34;, size = 9, alpha = .75, va = &#39;center&#39;)

                ymax = ppl.axis()[3]
                for s in x_sessions:
                        ppl.text(
                                x_sessions[s],
                                ymax +1,
                                s,
                                va = &#39;bottom&#39;,
                                **(
                                        dict(ha = &#39;center&#39;)
                                        if len(self.sessions[s][&#39;data&#39;]) &gt; (0.15 * len(self))
                                        else dict(ha = &#39;left&#39;, rotation = 45)
                                        )
                                )

                for s in colors:
                        kw[&#39;marker&#39;] = &#39;+&#39;
                        kw[&#39;ms&#39;] = 5
                        kw[&#39;mec&#39;] = colors[s]
                        kw[&#39;label&#39;] = s
                        kw[&#39;alpha&#39;] = 1
                        ppl.plot([], [], **kw)

                kw[&#39;mec&#39;] = (0,0,0)

                if one_or_more_singlets:
                        kw[&#39;marker&#39;] = &#39;x&#39;
                        kw[&#39;ms&#39;] = 4
                        kw[&#39;alpha&#39;] = .2
                        kw[&#39;label&#39;] = &#39;other (N$\\,$=$\\,$1)&#39; if one_or_more_multiplets else &#39;other&#39;
                        ppl.plot([], [], **kw)

                if one_or_more_multiplets:
                        kw[&#39;marker&#39;] = &#39;+&#39;
                        kw[&#39;ms&#39;] = 4
                        kw[&#39;alpha&#39;] = 1
                        kw[&#39;label&#39;] = &#39;other (N$\\,$&gt;$\\,$1)&#39; if one_or_more_singlets else &#39;other&#39;
                        ppl.plot([], [], **kw)

                ppl.legend(loc = &#39;lower left&#39;, bbox_to_anchor = (1.03, 0), borderaxespad = 0)
                ppl.xticks([])
                ppl.ylabel(&#39;Δ$_{47}$ residuals (ppm)&#39;)
                ppl.axis([-1, len(self), None, None])

                if not os.path.exists(dir):
                        os.makedirs(dir)
                if filename is None:
                        return fig
                elif filename == &#39;&#39;:
                        filename = f&#39;D{self._4x}_residuals.pdf&#39;
                ppl.savefig(f&#39;{dir}/{filename}&#39;)
                ppl.close(fig)
                                

        def simulate(self, *args, **kwargs):
                &#39;&#39;&#39;
                Legacy function with warning message pointing to `virtual_data()`
                &#39;&#39;&#39;
                raise DeprecationWarning(&#39;D4xdata.simulate is deprecated and has been replaced by virtual_data()&#39;)

        def plot_distribution_of_analyses(self, dir = &#39;output&#39;, filename = None, vs_time = False, output = None):
                &#39;&#39;&#39;
                Plot temporal distribution of all analyses in the data set.
                
                __Parameters__

                + `vs_time`: if `True`, plot as a function of `TimeTag` rather than sequentially.
                &#39;&#39;&#39;

                asamples = [s for s in self.anchors]
                usamples = [s for s in self.unknowns]
                if output is None or output == &#39;fig&#39;:
                        fig = ppl.figure(figsize = (6,4))
                        ppl.subplots_adjust(0.02, 0.03, 0.9, 0.8)
                Xmax = max([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self)])
                for k, s in enumerate(asamples + usamples):
                        if vs_time:
                                X = [r[&#39;TimeTag&#39;] for r in self if r[&#39;Sample&#39;] == s]
                        else:
                                X = [x for x,r in enumerate(self) if r[&#39;Sample&#39;] == s]
                        Y = [k for x in X]
                        ppl.plot(X, Y, &#39;o&#39;, mec = None, mew = 0, mfc = &#39;b&#39; if s in usamples else &#39;r&#39;, ms = 3, alpha = .5)
                        ppl.axhline(k, color = &#39;b&#39; if s in usamples else &#39;r&#39;, lw = .5, alpha = .25)
                        ppl.text(Xmax, k, f&#39;  {s}&#39;, va = &#39;center&#39;, ha = &#39;left&#39;, size = 7)
                if vs_time:
                        t = [r[&#39;TimeTag&#39;] for r in self]
                        t1, t2 = min(t), max(t)
                        tspan = t2 - t1
                        t1 -= tspan / len(self)
                        t2 += tspan / len(self)
                        ppl.axis([t1, t2, -1, k+1])
                else:
                        ppl.axis([-1, len(self), -1, k+1])
                        

                x2 = 0
                for session in self.sessions:
                        x1 = min([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self) if r[&#39;Session&#39;] == session])
                        if vs_time:
                                ppl.axvline(x1, color = &#39;k&#39;, lw = .75)
                        if k:
                                if vs_time:
                                        ppl.axvspan(x1,x2,color = &#39;k&#39;, zorder = -100, alpha = .2)
                                else:
                                        ppl.axvline((x1+x2)/2, color = &#39;k&#39;, lw = .75)
                        x2 = max([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self) if r[&#39;Session&#39;] == session])
#                       from xlrd import xldate_as_datetime
#                       print(session, xldate_as_datetime(x1, 0), xldate_as_datetime(x2, 0))
                        if vs_time:
                                ppl.axvline(x2, color = &#39;k&#39;, lw = .75)
                        ppl.text((2*x1+x2)/3, k+1, session, ha = &#39;left&#39;, va = &#39;bottom&#39;, rotation = 45, size = 8)

                ppl.xticks([])
                ppl.yticks([])

                if output is None:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename == None:
                                filename = f&#39;D{self._4x}_distribution_of_analyses.pdf&#39;
                        ppl.savefig(f&#39;{dir}/{filename}&#39;)
                        ppl.close(fig)
                elif output == &#39;ax&#39;:
                        return ppl.gca()
                elif output == &#39;fig&#39;:
                        return fig


class D47data(D4xdata):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ&lt;sub&gt;47&lt;/sub&gt; analyses,
        usually comprising more than one analytical session.
        &#39;&#39;&#39;

        Nominal_D4x = {
                &#39;ETH-1&#39;:   0.2052,
                &#39;ETH-2&#39;:   0.2085,
                &#39;ETH-3&#39;:   0.6132,
                &#39;ETH-4&#39;:   0.4511,
                &#39;IAEA-C1&#39;: 0.3018,
                &#39;IAEA-C2&#39;: 0.6409,
                &#39;MERCK&#39;:   0.5135,
                } # I-CDES (Bernasconi et al., 2021)
        &#39;&#39;&#39;
        Nominal Δ&lt;sub&gt;47&lt;/sub&gt; values assigned to the Δ&lt;sub&gt;47&lt;/sub&gt; anchor samples, used by
        `D47data.standardize()` to normalize unknown samples to an absolute Δ&lt;sub&gt;47&lt;/sub&gt;
        reference frame.

        By default equal to (after [Bernasconi et al. (2021)]):
        ```py
        {
                &#39;ETH-1&#39;   : 0.2052,
                &#39;ETH-2&#39;   : 0.2085,
                &#39;ETH-3&#39;   : 0.6132,
                &#39;ETH-4&#39;   : 0.4511,
                &#39;IAEA-C1&#39; : 0.3018,
                &#39;IAEA-C2&#39; : 0.6409,
                &#39;MERCK&#39;   : 0.5135,
        }
        ```

        [Bernasconi et al. (2021)]: https://doi.org/10.1029/2020GC009588
        &#39;&#39;&#39;


        @property
        def Nominal_D47(self):
                return self.Nominal_D4x
        

        @Nominal_D47.setter
        def Nominal_D47(self, new):
                self.Nominal_D4x = dict(**new)
                self.refresh()


        def __init__(self, l = [], **kwargs):
                &#39;&#39;&#39;
                __Parameters:__ same as `D4xdata.__init__()`
                &#39;&#39;&#39;
                D4xdata.__init__(self, l = l, mass = &#39;47&#39;, **kwargs)


        def D47fromTeq(self, fCo2eqD47 = &#39;petersen&#39;, priority = &#39;new&#39;):
                &#39;&#39;&#39;
                Find all samples for which `Teq` is specified, compute equilibrium Δ&lt;sub&gt;47&lt;/sub&gt;
                value for that temperature, and add treat these samples as additional anchors.

                __Parameters__

                + `fCo2eqD47`: Which CO&lt;sub&gt;2&lt;/sub&gt; equilibrium law to use
                (`petersen`: [Petersen et al. (2019)];
                `wang`: [Wang et al. (2019)]).
                + `priority`: if `replace`: forget old anchors and only use the new ones;
                if `new`: keep pre-existing anchors but update them in case of conflict
                between old and new Δ&lt;sub&gt;47&lt;/sub&gt; values;
                if `old`: keep pre-existing anchors but preserve their original Δ&lt;sub&gt;47&lt;/sub&gt;
                values in case of conflict.

                [Petersen et al. (2019)]: https://doi.org/10.1029/2018GC008127
                [Wang et al. (2019)]: https://doi.org/10.1016/j.gca.2004.05.039
                &#39;&#39;&#39;
                f = {
                        &#39;petersen&#39;: fCO2eqD47_Petersen,
                        &#39;wang&#39;: fCO2eqD47_Wang,
                        }[fCo2eqD47]
                foo = {}
                for r in self:
                        if &#39;Teq&#39; in r:
                                if r[&#39;Sample&#39;] in foo:
                                        assert foo[r[&#39;Sample&#39;]] == f(r[&#39;Teq&#39;]), f&#39;Different values of `Teq` provided for sample `{r[&#34;Sample&#34;]}`.&#39;
                                else:
                                        foo[r[&#39;Sample&#39;]] = f(r[&#39;Teq&#39;])
                        else:
                                        assert r[&#39;Sample&#39;] not in foo, f&#39;`Teq` is inconsistently specified for sample `{r[&#34;Sample&#34;]}`.&#39;

                if priority == &#39;replace&#39;:
                        self.Nominal_D47 = {}
                for s in foo:
                        if priority != &#39;old&#39; or s not in self.Nominal_D47:
                                self.Nominal_D47[s] = foo[s]
        



class D48data(D4xdata):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ&lt;sub&gt;48&lt;/sub&gt; analyses,
        usually comprising more than one analytical session.
        &#39;&#39;&#39;

        Nominal_D4x = {
                &#39;ETH-1&#39;:  0.138,
                &#39;ETH-2&#39;:  0.138,
                &#39;ETH-3&#39;:  0.270,
                &#39;ETH-4&#39;:  0.223,
                &#39;GU-1&#39;:  -0.419,
                } # (Fiebig et al., 2019, 2021)
        &#39;&#39;&#39;
        Nominal Δ&lt;sub&gt;48&lt;/sub&gt; values assigned to the Δ&lt;sub&gt;48&lt;/sub&gt; anchor samples, used by
        `D48data.standardize()` to normalize unknown samples to an absolute Δ&lt;sub&gt;48&lt;/sub&gt;
        reference frame.

        By default equal to (after [Fiebig et al. (2019)], Fiebig et al. (in press)):
        ```py
        {
                &#39;ETH-1&#39; :  0.138,
                &#39;ETH-2&#39; :  0.138,
                &#39;ETH-3&#39; :  0.270,
                &#39;ETH-4&#39; :  0.223,
                &#39;GU-1&#39;  : -0.419,
        }
        ```

        [Fiebig et al. (2019)]: https://doi.org/10.1016/j.chemgeo.2019.05.019
        &#39;&#39;&#39;


        @property
        def Nominal_D48(self):
                return self.Nominal_D4x

        
        @Nominal_D48.setter
        def Nominal_D48(self, new):
                self.Nominal_D4x = dict(**new)
                self.refresh()


        def __init__(self, l = [], **kwargs):
                &#39;&#39;&#39;
                __Parameters:__ same as `D4xdata.__init__()`
                &#39;&#39;&#39;
                D4xdata.__init__(self, l = l, mass = &#39;48&#39;, **kwargs)


class _SessionPlot():
        &#39;&#39;&#39;
        Simple placeholder class
        &#39;&#39;&#39;
        def __init__(self):
                pass

def simulate_single_analysis(
        sample = &#39;MYSAMPLE&#39;,
        d13Cwg_VPDB = -4., d18Owg_VSMOW = 26.,
        d13C_VPDB = None, d18O_VPDB = None,
        D47 = None, D48 = None, D49 = 0., D17O = 0.,
        Nominal_D47 = D47data().Nominal_D47,
        Nominal_D48 = D48data().Nominal_D48,
        Nominal_d13C_VPDB = D4xdata().Nominal_d13C_VPDB,
        Nominal_d18O_VPDB = D4xdata().Nominal_d18O_VPDB,
        ALPHA_18O_ACID_REACTION = D4xdata().ALPHA_18O_ACID_REACTION,
        a47 = 1., b47 = 0., c47 = -0.9,
        a48 = 1., b48 = 0., c48 = -0.45,
        R13_VPDB = D4xdata().R13_VPDB,
        R17_VSMOW = D4xdata().R17_VSMOW,
        R18_VSMOW = D4xdata().R18_VSMOW,
        lambda_17 = D4xdata().lambda_17,
        R18_VPDB = D4xdata().R18_VPDB,
        ):
        &#39;&#39;&#39;
        Compute working-gas delta values for a single analysis, assuming a stochastic working
        gas and a “perfect” measurement (i.e. raw Δ values are identical to absolute values).
        
        __Parameters__

        + `sample`: sample name
        + `d13Cwg_VPDB`, `d18Owg_VSMOW`: bulk composition of the working gas
                (respectively –4 and +26 ‰ by default)
        + `d13C_VPDB`, `d18O_VPDB`: bulk composition of the carbonate sample
        + `D47`, `D48`, `D49`, `D17O`: clumped-isotope and oxygen-17 anomalies
                of the carbonate sample
        + `Nominal_D47`, `Nominal_D48`: where to lookup Δ&lt;sub&gt;47&lt;/sub&gt; and
                Δ&lt;sub&gt;48&lt;/sub&gt; values if `D47` or `D48` are not specified
        + `Nominal_d13C_VPDB`, `Nominal_d18O_VPDB`: where to lookup δ&lt;sup&gt;13&lt;/sup&gt;C and
                δ&lt;sup&gt;18&lt;/sup&gt;O values if `d13C_VPDB` or `d18O_VPDB` are not specified
        + `ALPHA_18O_ACID_REACTION`: &lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;O acid fractionation factor
        + `R13_VPDB`, `R17_VSMOW`, `R18_VSMOW`, `lambda_17`, `R18_VPDB`: oxygen-17
                correction parameters (by default equal to the `D4xdata` default values)
        
        Returns a dictionary with fields
        `[&#39;Sample&#39;, &#39;D17O&#39;, &#39;d13Cwg_VPDB&#39;, &#39;d18Owg_VSMOW&#39;, &#39;d45&#39;, &#39;d46&#39;, &#39;d47&#39;, &#39;d48&#39;, &#39;d49&#39;]`.
        &#39;&#39;&#39;
        
        R17_VPDB = R17_VSMOW * (R18_VPDB / R18_VSMOW) ** lambda_17
        
        if d13C_VPDB is None:
                if sample in Nominal_d13C_VPDB:
                        d13C_VPDB = Nominal_d13C_VPDB[sample]
                else:
                        raise KeyError(f&#34;Sample {sample} is missing d13C_VDP value, and it is not defined in Nominal_d13C_VDP.&#34;)

        if d18O_VPDB is None:
                if sample in Nominal_d18O_VPDB:
                        d18O_VPDB = Nominal_d18O_VPDB[sample]
                else:
                        raise KeyError(f&#34;Sample {sample} is missing d18O_VPDB value, and it is not defined in Nominal_d18O_VPDB.&#34;)

        if D47 is None:
                if sample in Nominal_D47:
                        D47 = Nominal_D47[sample]
                else:
                        raise KeyError(f&#34;Sample {sample} is missing D47 value, and it is not defined in Nominal_D47.&#34;)

        if D48 is None:
                if sample in Nominal_D48:
                        D48 = Nominal_D48[sample]
                else:
                        raise KeyError(f&#34;Sample {sample} is missing D48 value, and it is not defined in Nominal_D48.&#34;)

        X = D4xdata()
        X.R13_VPDB = R13_VPDB
        X.R17_VSMOW = R17_VSMOW
        X.R18_VSMOW = R18_VSMOW
        X.lambda_17 = lambda_17
        X.R18_VPDB = R18_VPDB
        X.R17_VPDB = R17_VSMOW * (R18_VPDB / R18_VSMOW)**lambda_17

        R45wg, R46wg, R47wg, R48wg, R49wg = X.compute_isobar_ratios(
                R13 = R13_VPDB * (1 + d13Cwg_VPDB/1000),
                R18 = R18_VSMOW * (1 + d18Owg_VSMOW/1000),
                )
        R45, R46, R47, R48, R49 = X.compute_isobar_ratios(
                R13 = R13_VPDB * (1 + d13C_VPDB/1000),
                R18 = R18_VPDB * (1 + d18O_VPDB/1000) * ALPHA_18O_ACID_REACTION,
                D17O=D17O, D47=D47, D48=D48, D49=D49,
                )
        R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = X.compute_isobar_ratios(
                R13 = R13_VPDB * (1 + d13C_VPDB/1000),
                R18 = R18_VPDB * (1 + d18O_VPDB/1000) * ALPHA_18O_ACID_REACTION,
                D17O=D17O,
                )
        
        d45 = 1000 * (R45/R45wg - 1)
        d46 = 1000 * (R46/R46wg - 1)
        d47 = 1000 * (R47/R47wg - 1)
        d48 = 1000 * (R48/R48wg - 1)
        d49 = 1000 * (R49/R49wg - 1)

        for k in range(3): # dumb iteration to adjust for small changes in d47
                R47raw = (1 + (a47 * D47 + b47 * d47 + c47)/1000) * R47stoch
                R48raw = (1 + (a48 * D48 + b48 * d48 + c48)/1000) * R48stoch    
                d47 = 1000 * (R47raw/R47wg - 1)
                d48 = 1000 * (R48raw/R48wg - 1)

        return dict(
                Sample = sample,
                D17O = D17O,
                d13Cwg_VPDB = d13Cwg_VPDB,
                d18Owg_VSMOW = d18Owg_VSMOW,
                d45 = d45,
                d46 = d46,
                d47 = d47,
                d48 = d48,
                d49 = d49,
                )


def virtual_data(
        samples = [],
        a47 = 1., b47 = 0., c47 = -0.9,
        a48 = 1., b48 = 0., c48 = -0.45,
        rD47 = 0.015, rD48 = 0.045,
        d13Cwg_VPDB = None, d18Owg_VSMOW = None,
        session = None,
        Nominal_D47 = None, Nominal_D48 = None,
        Nominal_d13C_VPDB = None, Nominal_d18O_VPDB = None,
        ALPHA_18O_ACID_REACTION = None,
        R13_VPDB = None,
        R17_VSMOW = None,
        R18_VSMOW = None,
        lambda_17 = None,
        R18_VPDB = None,
        seed = 0,
        ):
        &#39;&#39;&#39;
        Return list with simulated analyses from a single session.
        
        __Parameters__
        
        + `samples`: a list of entries; each entry is a dictionary with the following fields:
            * `Sample`: the name of the sample
            * `d13C_VPDB`, `d18O_VPDB`: bulk composition of the carbonate sample
            * `D47`, `D48`, `D49`, `D17O` (all optional): clumped-isotope and oxygen-17 anomalies of the carbonate sample
            * `N`: how many analyses to generate for this sample
        + `a47`: scrambling factor for Δ&lt;sub&gt;47&lt;/sub&gt;
        + `b47`: compositional nonlinearity for Δ&lt;sub&gt;47&lt;/sub&gt;
        + `c47`: working gas offset for Δ&lt;sub&gt;47&lt;/sub&gt;
        + `a48`: scrambling factor for Δ&lt;sub&gt;48&lt;/sub&gt;
        + `b48`: compositional nonlinearity for Δ&lt;sub&gt;48&lt;/sub&gt;
        + `c48`: working gas offset for Δ&lt;sub&gt;48&lt;/sub&gt;
        + `rD47`: analytical repeatability of Δ&lt;sub&gt;47&lt;/sub&gt;
        + `rD48`: analytical repeatability of Δ&lt;sub&gt;48&lt;/sub&gt;
        + `d13Cwg_VPDB`, `d18Owg_VSMOW`: bulk composition of the working gas
                (by default equal to the `simulate_single_analysis` default values)
        + `session`: name of the session (no name by default)
        + `Nominal_D47`, `Nominal_D48`: where to lookup Δ&lt;sub&gt;47&lt;/sub&gt; and Δ&lt;sub&gt;48&lt;/sub&gt; values
                if `D47` or `D48` are not specified (by default equal to the `simulate_single_analysis` defaults)
        + `Nominal_d13C_VPDB`, `Nominal_d18O_VPDB`: where to lookup δ&lt;sup&gt;13&lt;/sup&gt;C and
                δ&lt;sup&gt;18&lt;/sup&gt;O values if `d13C_VPDB` or `d18O_VPDB` are not specified 
                (by default equal to the `simulate_single_analysis` defaults)
        + `ALPHA_18O_ACID_REACTION`: &lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;O acid fractionation factor
                (by default equal to the `simulate_single_analysis` defaults)
        + `R13_VPDB`, `R17_VSMOW`, `R18_VSMOW`, `lambda_17`, `R18_VPDB`: oxygen-17
                correction parameters (by default equal to the `simulate_single_analysis` default)
        + `seed`: explicitly set to a non-zero value to achieve random but repeatable simulations
        
                
        Here is an example of using this method to generate an arbitrary combination of
        anchors and unknowns for a bunch of sessions:

        ```py
        args = dict(
                samples = [
                        dict(Sample = &#39;ETH-1&#39;, N = 4),
                        dict(Sample = &#39;ETH-2&#39;, N = 5),
                        dict(Sample = &#39;ETH-3&#39;, N = 6),
                        dict(
                                Sample = &#39;FOO&#39;,
                                N = 2,
                                d13C_VPDB = -5.,
                                d18O_VPDB = -10.,
                                D47 = 0.3,
                                D48 = 0.15
                                ),
                        ],
                rD47 = 0.010,
                rD48 = 0.030,
                )
        session1 = virtual_data(session = &#39;Session_01&#39;, **args, seed = 123)
        session2 = virtual_data(session = &#39;Session_02&#39;, **args, seed = 1234)
        session3 = virtual_data(session = &#39;Session_03&#39;, **args, seed = 12345)
        session4 = virtual_data(session = &#39;Session_04&#39;, **args, seed = 123456)
        D = D47data(session1 + session2 + session3 + session4)
        D.crunch()
        D.standardize()
        D.table_of_sessions(verbose = True, save_to_file = False)
        D.table_of_samples(verbose = True, save_to_file = False)
        D.table_of_analyses(verbose = True, save_to_file = False)
        ```
        
        This should output something like:
        
        ```
        [table_of_sessions] 
        ––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––
        Session     Na  Nu  d13Cwg_VPDB  d18Owg_VSMOW  r_d13C  r_d18O   r_D47         a ± SE    1e3 x b ± SE          c ± SE
        ––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––
        Session_01  15   2       -4.000        26.000  0.0000  0.0000  0.0110  0.997 ± 0.017  -0.097 ± 0.244  -0.896 ± 0.006
        Session_02  15   2       -4.000        26.000  0.0000  0.0000  0.0109  1.002 ± 0.017  -0.110 ± 0.244  -0.901 ± 0.006
        Session_03  15   2       -4.000        26.000  0.0000  0.0000  0.0107  1.010 ± 0.017  -0.037 ± 0.244  -0.904 ± 0.006
        Session_04  15   2       -4.000        26.000  0.0000  0.0000  0.0106  1.001 ± 0.017  -0.181 ± 0.244  -0.894 ± 0.006
        ––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––

        [table_of_samples] 
        ––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
        Sample   N  d13C_VPDB  d18O_VSMOW     D47      SE    95% CL      SD  p_Levene
        ––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
        ETH-1   16       2.02       37.02  0.2052                    0.0079          
        ETH-2   20     -10.17       19.88  0.2085                    0.0100          
        ETH-3   24       1.71       37.45  0.6132                    0.0105          
        FOO      8      -5.00       28.91  0.2989  0.0040  ± 0.0080  0.0101     0.638
        ––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––

        [table_of_analyses] 
        –––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
        UID     Session  Sample  d13Cwg_VPDB  d18Owg_VSMOW        d45        d46         d47         d48         d49   d13C_VPDB  d18O_VSMOW     D47raw     D48raw     D49raw       D47
        –––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
        1    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.122986   21.273526   27.780042    2.020000   37.024281  -0.706013  -0.328878  -0.000013  0.192554
        2    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.130144   21.282615   27.780042    2.020000   37.024281  -0.698974  -0.319981  -0.000013  0.199615
        3    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.149219   21.299572   27.780042    2.020000   37.024281  -0.680215  -0.303383  -0.000013  0.218429
        4    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.136616   21.233128   27.780042    2.020000   37.024281  -0.692609  -0.368421  -0.000013  0.205998
        5    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.697171  -12.203054  -18.023381  -10.170000   19.875825  -0.680771  -0.290128  -0.000002  0.215054
        6    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701124  -12.184422  -18.023381  -10.170000   19.875825  -0.684772  -0.271272  -0.000002  0.211041
        7    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.715105  -12.195251  -18.023381  -10.170000   19.875825  -0.698923  -0.282232  -0.000002  0.196848
        8    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701529  -12.204963  -18.023381  -10.170000   19.875825  -0.685182  -0.292061  -0.000002  0.210630
        9    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.711420  -12.228478  -18.023381  -10.170000   19.875825  -0.695193  -0.315859  -0.000002  0.200589
        10   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.666719   22.296486   28.306614    1.710000   37.450394  -0.290459  -0.147284  -0.000014  0.609363
        11   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.671553   22.291060   28.306614    1.710000   37.450394  -0.285706  -0.152592  -0.000014  0.614130
        12   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.652854   22.273271   28.306614    1.710000   37.450394  -0.304093  -0.169990  -0.000014  0.595689
        13   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.684168   22.263156   28.306614    1.710000   37.450394  -0.273302  -0.179883  -0.000014  0.626572
        14   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.662702   22.253578   28.306614    1.710000   37.450394  -0.294409  -0.189251  -0.000014  0.605401
        15   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.681957   22.230907   28.306614    1.710000   37.450394  -0.275476  -0.211424  -0.000014  0.624391
        16   Session_01     FOO       -4.000        26.000  -0.840413   2.828738    1.312044    5.395798    4.665655   -5.000000   28.907344  -0.598436  -0.268176  -0.000006  0.298996
        17   Session_01     FOO       -4.000        26.000  -0.840413   2.828738    1.328123    5.307086    4.665655   -5.000000   28.907344  -0.582387  -0.356389  -0.000006  0.315092
        18   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.122201   21.340606   27.780042    2.020000   37.024281  -0.706785  -0.263217  -0.000013  0.195135
        19   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.134868   21.305714   27.780042    2.020000   37.024281  -0.694328  -0.297370  -0.000013  0.207564
        20   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.140008   21.261931   27.780042    2.020000   37.024281  -0.689273  -0.340227  -0.000013  0.212607
        21   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.135540   21.298472   27.780042    2.020000   37.024281  -0.693667  -0.304459  -0.000013  0.208224
        22   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701213  -12.202602  -18.023381  -10.170000   19.875825  -0.684862  -0.289671  -0.000002  0.213842
        23   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.685649  -12.190405  -18.023381  -10.170000   19.875825  -0.669108  -0.277327  -0.000002  0.229559
        24   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.719003  -12.257955  -18.023381  -10.170000   19.875825  -0.702869  -0.345692  -0.000002  0.195876
        25   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.700592  -12.204641  -18.023381  -10.170000   19.875825  -0.684233  -0.291735  -0.000002  0.214469
        26   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.720426  -12.214561  -18.023381  -10.170000   19.875825  -0.704308  -0.301774  -0.000002  0.194439
        27   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.673044   22.262090   28.306614    1.710000   37.450394  -0.284240  -0.180926  -0.000014  0.616730
        28   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.666542   22.263401   28.306614    1.710000   37.450394  -0.290634  -0.179643  -0.000014  0.610350
        29   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.680487   22.243486   28.306614    1.710000   37.450394  -0.276921  -0.199121  -0.000014  0.624031
        30   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.663900   22.245175   28.306614    1.710000   37.450394  -0.293231  -0.197469  -0.000014  0.607759
        31   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.674379   22.301309   28.306614    1.710000   37.450394  -0.282927  -0.142568  -0.000014  0.618039
        32   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.660825   22.270466   28.306614    1.710000   37.450394  -0.296255  -0.172733  -0.000014  0.604742
        33   Session_02     FOO       -4.000        26.000  -0.840413   2.828738    1.294076    5.349940    4.665655   -5.000000   28.907344  -0.616369  -0.313776  -0.000006  0.283707
        34   Session_02     FOO       -4.000        26.000  -0.840413   2.828738    1.313775    5.292121    4.665655   -5.000000   28.907344  -0.596708  -0.371269  -0.000006  0.303323
        35   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.121613   21.259909   27.780042    2.020000   37.024281  -0.707364  -0.342207  -0.000013  0.194934
        36   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.145714   21.304889   27.780042    2.020000   37.024281  -0.683661  -0.298178  -0.000013  0.218401
        37   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.126573   21.325093   27.780042    2.020000   37.024281  -0.702485  -0.278401  -0.000013  0.199764
        38   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.132057   21.323211   27.780042    2.020000   37.024281  -0.697092  -0.280244  -0.000013  0.205104
        39   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.708448  -12.232023  -18.023381  -10.170000   19.875825  -0.692185  -0.319447  -0.000002  0.208915
        40   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.714417  -12.202504  -18.023381  -10.170000   19.875825  -0.698226  -0.289572  -0.000002  0.202934
        41   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.720039  -12.264469  -18.023381  -10.170000   19.875825  -0.703917  -0.352285  -0.000002  0.197300
        42   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701953  -12.228550  -18.023381  -10.170000   19.875825  -0.685611  -0.315932  -0.000002  0.215423
        43   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.704535  -12.213634  -18.023381  -10.170000   19.875825  -0.688224  -0.300836  -0.000002  0.212837
        44   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.652920   22.230043   28.306614    1.710000   37.450394  -0.304028  -0.212269  -0.000014  0.594265
        45   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.691485   22.261017   28.306614    1.710000   37.450394  -0.266106  -0.181975  -0.000014  0.631810
        46   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.679119   22.305357   28.306614    1.710000   37.450394  -0.278266  -0.138609  -0.000014  0.619771
        47   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.663623   22.327286   28.306614    1.710000   37.450394  -0.293503  -0.117161  -0.000014  0.604685
        48   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.678524   22.282103   28.306614    1.710000   37.450394  -0.278851  -0.161352  -0.000014  0.619192
        49   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.666246   22.283361   28.306614    1.710000   37.450394  -0.290925  -0.160121  -0.000014  0.607238
        50   Session_03     FOO       -4.000        26.000  -0.840413   2.828738    1.309929    5.340249    4.665655   -5.000000   28.907344  -0.600546  -0.323413  -0.000006  0.300148
        51   Session_03     FOO       -4.000        26.000  -0.840413   2.828738    1.317548    5.334102    4.665655   -5.000000   28.907344  -0.592942  -0.329524  -0.000006  0.307676
        52   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.136865   21.300298   27.780042    2.020000   37.024281  -0.692364  -0.302672  -0.000013  0.204033
        53   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.133538   21.291260   27.780042    2.020000   37.024281  -0.695637  -0.311519  -0.000013  0.200762
        54   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.139991   21.319865   27.780042    2.020000   37.024281  -0.689290  -0.283519  -0.000013  0.207107
        55   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.145748   21.330075   27.780042    2.020000   37.024281  -0.683629  -0.273524  -0.000013  0.212766
        56   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.702989  -12.202762  -18.023381  -10.170000   19.875825  -0.686660  -0.289833  -0.000002  0.204507
        57   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.692830  -12.240287  -18.023381  -10.170000   19.875825  -0.676377  -0.327811  -0.000002  0.214786
        58   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.702899  -12.180291  -18.023381  -10.170000   19.875825  -0.686568  -0.267091  -0.000002  0.204598
        59   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.709282  -12.282257  -18.023381  -10.170000   19.875825  -0.693029  -0.370287  -0.000002  0.198140
        60   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.679330  -12.235994  -18.023381  -10.170000   19.875825  -0.662712  -0.323466  -0.000002  0.228446
        61   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.695594   22.238663   28.306614    1.710000   37.450394  -0.262066  -0.203838  -0.000014  0.634200
        62   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.663504   22.286354   28.306614    1.710000   37.450394  -0.293620  -0.157194  -0.000014  0.602656
        63   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.666457   22.254290   28.306614    1.710000   37.450394  -0.290717  -0.188555  -0.000014  0.605558
        64   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.666910   22.223232   28.306614    1.710000   37.450394  -0.290271  -0.218930  -0.000014  0.606004
        65   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.679662   22.257256   28.306614    1.710000   37.450394  -0.277732  -0.185653  -0.000014  0.618539
        66   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.676768   22.267680   28.306614    1.710000   37.450394  -0.280578  -0.175459  -0.000014  0.615693
        67   Session_04     FOO       -4.000        26.000  -0.840413   2.828738    1.307663    5.317330    4.665655   -5.000000   28.907344  -0.602808  -0.346202  -0.000006  0.290853
        68   Session_04     FOO       -4.000        26.000  -0.840413   2.828738    1.308562    5.331400    4.665655   -5.000000   28.907344  -0.601911  -0.332212  -0.000006  0.291749
        –––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
        ```
        &#39;&#39;&#39;
        
        kwargs = locals().copy()

        from numpy import random as nprandom
        if seed:
                rng = nprandom.default_rng(seed)
        else:
                rng = nprandom.default_rng()
        
        N = sum([s[&#39;N&#39;] for s in samples])
        errors47 = rng.normal(loc = 0, scale = 1, size = N) # generate random measurement errors
        errors47 *= rD47 / stdev(errors47) # scale errors to rD47
        errors48 = rng.normal(loc = 0, scale = 1, size = N) # generate random measurement errors
        errors48 *= rD48 / stdev(errors48) # scale errors to rD48
        
        k = 0
        out = []
        for s in samples:
                kw = {}
                kw[&#39;sample&#39;] = s[&#39;Sample&#39;]
                kw = {
                        **kw,
                        **{var: kwargs[var]
                                for var in [
                                        &#39;d13Cwg_VPDB&#39;, &#39;d18Owg_VSMOW&#39;, &#39;ALPHA_18O_ACID_REACTION&#39;,
                                        &#39;Nominal_D47&#39;, &#39;Nominal_D48&#39;, &#39;Nominal_d13C_VPDB&#39;, &#39;Nominal_d18O_VPDB&#39;,
                                        &#39;R13_VPDB&#39;, &#39;R17_VSMOW&#39;, &#39;R18_VSMOW&#39;, &#39;lambda_17&#39;, &#39;R18_VPDB&#39;,
                                        &#39;a47&#39;, &#39;b47&#39;, &#39;c47&#39;, &#39;a48&#39;, &#39;b48&#39;, &#39;c48&#39;,
                                        ]
                                if kwargs[var] is not None},
                        **{var: s[var]
                                for var in [&#39;d13C_VPDB&#39;, &#39;d18O_VPDB&#39;, &#39;D47&#39;, &#39;D48&#39;, &#39;D49&#39;, &#39;D17O&#39;]
                                if var in s},
                        }

                sN = s[&#39;N&#39;]
                while sN:
                        out.append(simulate_single_analysis(**kw))
                        out[-1][&#39;d47&#39;] += errors47[k] * a47
                        out[-1][&#39;d48&#39;] += errors48[k] * a48
                        sN -= 1
                        k += 1

                if session is not None:
                        for r in out:
                                r[&#39;Session&#39;] = session
        return out

def table_of_samples(
        data47 = None,
        data48 = None,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out, save to disk and/or return a combined table of samples
        for a pair of `D47data` and `D48data` objects.

        __Parameters__

        + `data47`: `D47data` instance
        + `data48`: `D48data` instance
        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                if set to `&#39;raw&#39;`: return a list of list of strings
                (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;
        if data47 is None:
                if data48 is None:
                        raise TypeError(&#34;Arguments must include at least one D47data() or D48data() instance.&#34;)
                else:
                        return data48.table_of_samples(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
        else:
                if data48 is None:
                        return data47.table_of_samples(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
                else:
                        out47 = data47.table_of_samples(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        out48 = data48.table_of_samples(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        out = transpose_table(transpose_table(out47) + transpose_table(out48)[4:])

                        if save_to_file:
                                if not os.path.exists(dir):
                                        os.makedirs(dir)
                                if filename is None:
                                        filename = f&#39;D47D48_samples.csv&#39;
                                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                        fid.write(make_csv(out))
                        if print_out:
                                print(&#39;\n&#39;+pretty_table(out))
                        if output == &#39;raw&#39;:
                                return out
                        elif output == &#39;pretty&#39;:
                                return pretty_table(out)


def table_of_sessions(
        data47 = None,
        data48 = None,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out, save to disk and/or return a combined table of sessions
        for a pair of `D47data` and `D48data` objects.
        __*Only applicable if the sessions in `data47` and those in `data48`
        consist of the exact same sets of analyses.*__

        __Parameters__

        + `data47`: `D47data` instance
        + `data48`: `D48data` instance
        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                if set to `&#39;raw&#39;`: return a list of list of strings
                (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;
        if data47 is None:
                if data48 is None:
                        raise TypeError(&#34;Arguments must include at least one D47data() or D48data() instance.&#34;)
                else:
                        return data48.table_of_sessions(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
        else:
                if data48 is None:
                        return data47.table_of_sessions(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
                else:
                        out47 = data47.table_of_sessions(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        out48 = data48.table_of_sessions(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        for k,x in enumerate(out47[0]):
                                if k&gt;7:
                                        out47[0][k] = out47[0][k].replace(&#39;a&#39;, &#39;a_47&#39;).replace(&#39;b&#39;, &#39;b_47&#39;).replace(&#39;c&#39;, &#39;c_47&#39;)
                                        out48[0][k] = out48[0][k].replace(&#39;a&#39;, &#39;a_48&#39;).replace(&#39;b&#39;, &#39;b_48&#39;).replace(&#39;c&#39;, &#39;c_48&#39;)
                        out = transpose_table(transpose_table(out47) + transpose_table(out48)[7:])

                        if save_to_file:
                                if not os.path.exists(dir):
                                        os.makedirs(dir)
                                if filename is None:
                                        filename = f&#39;D47D48_sessions.csv&#39;
                                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                        fid.write(make_csv(out))
                        if print_out:
                                print(&#39;\n&#39;+pretty_table(out))
                        if output == &#39;raw&#39;:
                                return out
                        elif output == &#39;pretty&#39;:
                                return pretty_table(out)


def table_of_analyses(
        data47 = None,
        data48 = None,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out, save to disk and/or return a combined table of analyses
        for a pair of `D47data` and `D48data` objects.

        If the sessions in `data47` and those in `data48` do not consist of
        the exact same sets of analyses, the table will have two columns
        `Session_47` and `Session_48` instead of a single `Session` column.

        __Parameters__

        + `data47`: `D47data` instance
        + `data48`: `D48data` instance
        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                if set to `&#39;raw&#39;`: return a list of list of strings
                (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;
        if data47 is None:
                if data48 is None:
                        raise TypeError(&#34;Arguments must include at least one D47data() or D48data() instance.&#34;)
                else:
                        return data48.table_of_analyses(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
        else:
                if data48 is None:
                        return data47.table_of_analyses(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
                else:
                        out47 = data47.table_of_analyses(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        out48 = data48.table_of_analyses(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        
                        if [l[1] for l in out47[1:]] == [l[1] for l in out48[1:]]: # if sessions are identical
                                out = transpose_table(transpose_table(out47) + transpose_table(out48)[-1:])
                        else:
                                out47[0][1] = &#39;Session_47&#39;
                                out48[0][1] = &#39;Session_48&#39;
                                out47 = transpose_table(out47)
                                out48 = transpose_table(out48)
                                out = transpose_table(out47[:2] + out48[1:2] + out47[2:] + out48[-1:])

                        if save_to_file:
                                if not os.path.exists(dir):
                                        os.makedirs(dir)
                                if filename is None:
                                        filename = f&#39;D47D48_sessions.csv&#39;
                                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                        fid.write(make_csv(out))
                        if print_out:
                                print(&#39;\n&#39;+pretty_table(out))
                        if output == &#39;raw&#39;:
                                return out
                        elif output == &#39;pretty&#39;:
                                return pretty_table(out)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="D47crunch.correlated_sum"><code class="name flex">
<span>def <span class="ident">correlated_sum</span></span>(<span>X, C, w=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute covariance-aware linear combinations</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>X</code>: list or 1-D array of values to sum</li>
<li><code>C</code>: covariance matrix for the elements of <code>X</code></li>
<li><code>w</code>: list or 1-D array of weights to apply to the elements of <code>X</code>
(all equal to 1 by default)</li>
</ul>
<p>Return the sum (and its SE) of the elements of <code>X</code>, with optional weights equal
to the elements of <code>w</code>, accounting for covariances between the elements of <code>X</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correlated_sum(X, C, w = None):
        &#39;&#39;&#39;
        Compute covariance-aware linear combinations

        __Parameters__
        
        + `X`: list or 1-D array of values to sum
        + `C`: covariance matrix for the elements of `X`
        + `w`: list or 1-D array of weights to apply to the elements of `X`
               (all equal to 1 by default)

        Return the sum (and its SE) of the elements of `X`, with optional weights equal
        to the elements of `w`, accounting for covariances between the elements of `X`.
        &#39;&#39;&#39;
        if w is None:
                w = [1 for x in X]
        return np.dot(w,X), (np.dot(w,np.dot(C,w)))**.5</code></pre>
</details>
</dd>
<dt id="D47crunch.fCO2eqD47_Petersen"><code class="name flex">
<span>def <span class="ident">fCO2eqD47_Petersen</span></span>(<span>T)</span>
</code></dt>
<dd>
<div class="desc"><p>CO<sub>2</sub> equilibrium Δ<sub>47</sub> value as a function of T (in degrees C)
according to <a href="https://doi.org/10.1029/2018GC008127">Petersen et al. (2019)</a>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fCO2eqD47_Petersen(T):
        &#39;&#39;&#39;
        CO&lt;sub&gt;2&lt;/sub&gt; equilibrium Δ&lt;sub&gt;47&lt;/sub&gt; value as a function of T (in degrees C)
        according to [Petersen et al. (2019)].

        [Petersen et al. (2019)]: https://doi.org/10.1029/2018GC008127
        &#39;&#39;&#39;
        return float(_fCO2eqD47_Petersen(T))</code></pre>
</details>
</dd>
<dt id="D47crunch.fCO2eqD47_Wang"><code class="name flex">
<span>def <span class="ident">fCO2eqD47_Wang</span></span>(<span>T)</span>
</code></dt>
<dd>
<div class="desc"><p>CO<sub>2</sub> equilibrium Δ<sub>47</sub> value as a function of <code>T</code> (in degrees C)
according to <a href="https://doi.org/10.1016/j.gca.2004.05.039">Wang et al. (2004)</a> (supplementary data of <a href="https://doi.org/10.1016/j.gca.2011.09.025">Dennis et al., 2011</a>).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fCO2eqD47_Wang(T):
        &#39;&#39;&#39;
        CO&lt;sub&gt;2&lt;/sub&gt; equilibrium Δ&lt;sub&gt;47&lt;/sub&gt; value as a function of `T` (in degrees C)
        according to [Wang et al. (2004)] (supplementary data of [Dennis et al., 2011]).

        [Wang et al. (2004)]: https://doi.org/10.1016/j.gca.2004.05.039
        [Dennis et al., 2011]: https://doi.org/10.1016/j.gca.2011.09.025
        &#39;&#39;&#39;
        return float(_fCO2eqD47_Wang(T))</code></pre>
</details>
</dd>
<dt id="D47crunch.make_csv"><code class="name flex">
<span>def <span class="ident">make_csv</span></span>(<span>x, hsep=',', vsep='\n')</span>
</code></dt>
<dd>
<div class="desc"><p>Formats a list of lists of strings as a CSV</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>x</code>: the list of lists of strings to format</li>
<li><code>hsep</code>: the field separator (<code>,</code> by default)</li>
<li><code>vsep</code>: the line-ending convention to use (<code>\n</code> by default)</li>
</ul>
<p><strong>Example</strong></p>
<pre><code class="language-py">print(make_csv([['a', 'b', 'c'], ['d', 'e', 'f']]))
</code></pre>
<p>outputs:</p>
<pre><code class="language-py">a,b,c
d,e,f
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_csv(x, hsep = &#39;,&#39;, vsep = &#39;\n&#39;):
        &#39;&#39;&#39;
        Formats a list of lists of strings as a CSV

        __Parameters__

        + `x`: the list of lists of strings to format
        + `hsep`: the field separator (`,` by default)
        + `vsep`: the line-ending convention to use (`\\n` by default)

        __Example__

        ```py
        print(make_csv([[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [&#39;d&#39;, &#39;e&#39;, &#39;f&#39;]]))
        ```

        outputs:

        ```py
        a,b,c
        d,e,f
        ```
        &#39;&#39;&#39;
        return vsep.join([hsep.join(l) for l in x])</code></pre>
</details>
</dd>
<dt id="D47crunch.pf"><code class="name flex">
<span>def <span class="ident">pf</span></span>(<span>txt)</span>
</code></dt>
<dd>
<div class="desc"><p>Modify string <code>txt</code> to follow <code>lmfit.Parameter()</code> naming rules.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pf(txt):
        &#39;&#39;&#39;
        Modify string `txt` to follow `lmfit.Parameter()` naming rules.
        &#39;&#39;&#39;
        return txt.replace(&#39;-&#39;,&#39;_&#39;).replace(&#39;.&#39;,&#39;_&#39;).replace(&#39; &#39;,&#39;_&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.pretty_table"><code class="name flex">
<span>def <span class="ident">pretty_table</span></span>(<span>x, header=1, hsep='
', vsep='–', align=&#x27;&lt;&#x27;)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a list of lists of strings and outputs an ascii table</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>x</code>: a list of lists of strings</li>
<li><code>header</code>: the number of lines to treat as header lines</li>
<li><code>hsep</code>: the horizontal separator between columns</li>
<li><code>vsep</code>: the character to use as vertical separator</li>
<li><code>align</code>: string of left (<code>&lt;</code>) or right (<code>&gt;</code>) alignment characters.</li>
</ul>
<p><strong>Example</strong></p>
<pre><code class="language-python">x = [['A','B', 'C'], ['1', '1.9999', 'foo'], ['10', 'x', 'bar']]
print(pretty_table(x))
</code></pre>
<p>output:</p>
<pre><code class="language-python">--  ------  ---
A        B    C
--  ------  ---
1   1.9999  foo
10       x  bar
--  ------  ---
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pretty_table(x, header = 1, hsep = &#39;  &#39;, vsep = &#39;–&#39;, align = &#39;&lt;&#39;):
        &#39;&#39;&#39;
        Reads a list of lists of strings and outputs an ascii table

        __Parameters__

        + `x`: a list of lists of strings
        + `header`: the number of lines to treat as header lines
        + `hsep`: the horizontal separator between columns
        + `vsep`: the character to use as vertical separator
        + `align`: string of left (`&lt;`) or right (`&gt;`) alignment characters.

        __Example__

        ```python
        x = [[&#39;A&#39;,&#39;B&#39;, &#39;C&#39;], [&#39;1&#39;, &#39;1.9999&#39;, &#39;foo&#39;], [&#39;10&#39;, &#39;x&#39;, &#39;bar&#39;]]
        print(pretty_table(x))
        ```

        output:

        ```python
        --  ------  ---
        A        B    C
        --  ------  ---
        1   1.9999  foo
        10       x  bar
        --  ------  ---
        ```
        &#39;&#39;&#39;
        txt = []
        widths = [np.max([len(e) for e in c]) for c in zip(*x)]

        if len(widths) &gt; len(align):
                align += &#39;&gt;&#39; * (len(widths)-len(align))
        sepline = hsep.join([vsep*w for w in widths])
        txt += [sepline]
        for k,l in enumerate(x):
                if k and k == header:
                        txt += [sepline]
                txt += [hsep.join([f&#39;{e:{a}{w}}&#39; for e, w, a in zip(l, widths, align)])]
        txt += [sepline]
        txt += [&#39;&#39;]
        return &#39;\n&#39;.join(txt)</code></pre>
</details>
</dd>
<dt id="D47crunch.read_csv"><code class="name flex">
<span>def <span class="ident">read_csv</span></span>(<span>filename, sep='')</span>
</code></dt>
<dd>
<div class="desc"><p>Read contents of <code>filename</code> in csv format and return a list of dictionaries.</p>
<p>In the csv string, spaces before and after field separators (<code>','</code> by default)
are optional.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>filename</code>: the csv file to read</li>
<li><code>sep</code>: csv separator delimiting the fields. By default, use <code>,</code>, <code>;</code>, or <code>
</code>,
whichever appers most often in the contents of <code>filename</code>.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_csv(filename, sep = &#39;&#39;):
        &#39;&#39;&#39;
        Read contents of `filename` in csv format and return a list of dictionaries.

        In the csv string, spaces before and after field separators (`&#39;,&#39;` by default)
        are optional.

        __Parameters__

        + `filename`: the csv file to read
        + `sep`: csv separator delimiting the fields. By default, use `,`, `;`, or `\t`,
        whichever appers most often in the contents of `filename`.
        &#39;&#39;&#39;
        with open(filename) as fid:
                txt = fid.read()

        if sep == &#39;&#39;:
                sep = sorted(&#39;,;\t&#39;, key = lambda x: - txt.count(x))[0]
        txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
        return [{k: smart_type(v) for k,v in zip(txt[0], l) if v} for l in txt[1:]]</code></pre>
</details>
</dd>
<dt id="D47crunch.simulate_single_analysis"><code class="name flex">
<span>def <span class="ident">simulate_single_analysis</span></span>(<span>sample='MYSAMPLE', d13Cwg_VPDB=-4.0, d18Owg_VSMOW=26.0, d13C_VPDB=None, d18O_VPDB=None, D47=None, D48=None, D49=0.0, D17O=0.0, Nominal_D47={'ETH-1': 0.2052, 'ETH-2': 0.2085, 'ETH-3': 0.6132, 'ETH-4': 0.4511, 'IAEA-C1': 0.3018, 'IAEA-C2': 0.6409, 'MERCK': 0.5135}, Nominal_D48={'ETH-1': 0.138, 'ETH-2': 0.138, 'ETH-3': 0.27, 'ETH-4': 0.223, 'GU-1': -0.419}, Nominal_d13C_VPDB={'ETH-1': 2.02, 'ETH-2': -10.17, 'ETH-3': 1.71}, Nominal_d18O_VPDB={'ETH-1': -2.19, 'ETH-2': -18.69, 'ETH-3': -1.78}, ALPHA_18O_ACID_REACTION=1.008129, a47=1.0, b47=0.0, c47=-0.9, a48=1.0, b48=0.0, c48=-0.45, R13_VPDB=0.01118, R17_VSMOW=0.00038475, R18_VSMOW=0.0020052, lambda_17=0.528, R18_VPDB=0.0020672007840000003)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute working-gas delta values for a single analysis, assuming a stochastic working
gas and a “perfect” measurement (i.e. raw Δ values are identical to absolute values).</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>sample</code>: sample name</li>
<li><code>d13Cwg_VPDB</code>, <code>d18Owg_VSMOW</code>: bulk composition of the working gas
(respectively –4 and +26 ‰ by default)</li>
<li><code>d13C_VPDB</code>, <code>d18O_VPDB</code>: bulk composition of the carbonate sample</li>
<li><code>D47</code>, <code>D48</code>, <code>D49</code>, <code>D17O</code>: clumped-isotope and oxygen-17 anomalies
of the carbonate sample</li>
<li><code>Nominal_D47</code>, <code>Nominal_D48</code>: where to lookup Δ<sub>47</sub> and
Δ<sub>48</sub> values if <code>D47</code> or <code>D48</code> are not specified</li>
<li><code>Nominal_d13C_VPDB</code>, <code>Nominal_d18O_VPDB</code>: where to lookup δ<sup>13</sup>C and
δ<sup>18</sup>O values if <code>d13C_VPDB</code> or <code>d18O_VPDB</code> are not specified</li>
<li><code>ALPHA_18O_ACID_REACTION</code>: <sup>18</sup>O/<sup>16</sup>O acid fractionation factor</li>
<li><code>R13_VPDB</code>, <code>R17_VSMOW</code>, <code>R18_VSMOW</code>, <code>lambda_17</code>, <code>R18_VPDB</code>: oxygen-17
correction parameters (by default equal to the <code><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></code> default values)</li>
</ul>
<p>Returns a dictionary with fields
<code>['Sample', 'D17O', 'd13Cwg_VPDB', 'd18Owg_VSMOW', 'd45', 'd46', 'd47', 'd48', 'd49']</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_single_analysis(
        sample = &#39;MYSAMPLE&#39;,
        d13Cwg_VPDB = -4., d18Owg_VSMOW = 26.,
        d13C_VPDB = None, d18O_VPDB = None,
        D47 = None, D48 = None, D49 = 0., D17O = 0.,
        Nominal_D47 = D47data().Nominal_D47,
        Nominal_D48 = D48data().Nominal_D48,
        Nominal_d13C_VPDB = D4xdata().Nominal_d13C_VPDB,
        Nominal_d18O_VPDB = D4xdata().Nominal_d18O_VPDB,
        ALPHA_18O_ACID_REACTION = D4xdata().ALPHA_18O_ACID_REACTION,
        a47 = 1., b47 = 0., c47 = -0.9,
        a48 = 1., b48 = 0., c48 = -0.45,
        R13_VPDB = D4xdata().R13_VPDB,
        R17_VSMOW = D4xdata().R17_VSMOW,
        R18_VSMOW = D4xdata().R18_VSMOW,
        lambda_17 = D4xdata().lambda_17,
        R18_VPDB = D4xdata().R18_VPDB,
        ):
        &#39;&#39;&#39;
        Compute working-gas delta values for a single analysis, assuming a stochastic working
        gas and a “perfect” measurement (i.e. raw Δ values are identical to absolute values).
        
        __Parameters__

        + `sample`: sample name
        + `d13Cwg_VPDB`, `d18Owg_VSMOW`: bulk composition of the working gas
                (respectively –4 and +26 ‰ by default)
        + `d13C_VPDB`, `d18O_VPDB`: bulk composition of the carbonate sample
        + `D47`, `D48`, `D49`, `D17O`: clumped-isotope and oxygen-17 anomalies
                of the carbonate sample
        + `Nominal_D47`, `Nominal_D48`: where to lookup Δ&lt;sub&gt;47&lt;/sub&gt; and
                Δ&lt;sub&gt;48&lt;/sub&gt; values if `D47` or `D48` are not specified
        + `Nominal_d13C_VPDB`, `Nominal_d18O_VPDB`: where to lookup δ&lt;sup&gt;13&lt;/sup&gt;C and
                δ&lt;sup&gt;18&lt;/sup&gt;O values if `d13C_VPDB` or `d18O_VPDB` are not specified
        + `ALPHA_18O_ACID_REACTION`: &lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;O acid fractionation factor
        + `R13_VPDB`, `R17_VSMOW`, `R18_VSMOW`, `lambda_17`, `R18_VPDB`: oxygen-17
                correction parameters (by default equal to the `D4xdata` default values)
        
        Returns a dictionary with fields
        `[&#39;Sample&#39;, &#39;D17O&#39;, &#39;d13Cwg_VPDB&#39;, &#39;d18Owg_VSMOW&#39;, &#39;d45&#39;, &#39;d46&#39;, &#39;d47&#39;, &#39;d48&#39;, &#39;d49&#39;]`.
        &#39;&#39;&#39;
        
        R17_VPDB = R17_VSMOW * (R18_VPDB / R18_VSMOW) ** lambda_17
        
        if d13C_VPDB is None:
                if sample in Nominal_d13C_VPDB:
                        d13C_VPDB = Nominal_d13C_VPDB[sample]
                else:
                        raise KeyError(f&#34;Sample {sample} is missing d13C_VDP value, and it is not defined in Nominal_d13C_VDP.&#34;)

        if d18O_VPDB is None:
                if sample in Nominal_d18O_VPDB:
                        d18O_VPDB = Nominal_d18O_VPDB[sample]
                else:
                        raise KeyError(f&#34;Sample {sample} is missing d18O_VPDB value, and it is not defined in Nominal_d18O_VPDB.&#34;)

        if D47 is None:
                if sample in Nominal_D47:
                        D47 = Nominal_D47[sample]
                else:
                        raise KeyError(f&#34;Sample {sample} is missing D47 value, and it is not defined in Nominal_D47.&#34;)

        if D48 is None:
                if sample in Nominal_D48:
                        D48 = Nominal_D48[sample]
                else:
                        raise KeyError(f&#34;Sample {sample} is missing D48 value, and it is not defined in Nominal_D48.&#34;)

        X = D4xdata()
        X.R13_VPDB = R13_VPDB
        X.R17_VSMOW = R17_VSMOW
        X.R18_VSMOW = R18_VSMOW
        X.lambda_17 = lambda_17
        X.R18_VPDB = R18_VPDB
        X.R17_VPDB = R17_VSMOW * (R18_VPDB / R18_VSMOW)**lambda_17

        R45wg, R46wg, R47wg, R48wg, R49wg = X.compute_isobar_ratios(
                R13 = R13_VPDB * (1 + d13Cwg_VPDB/1000),
                R18 = R18_VSMOW * (1 + d18Owg_VSMOW/1000),
                )
        R45, R46, R47, R48, R49 = X.compute_isobar_ratios(
                R13 = R13_VPDB * (1 + d13C_VPDB/1000),
                R18 = R18_VPDB * (1 + d18O_VPDB/1000) * ALPHA_18O_ACID_REACTION,
                D17O=D17O, D47=D47, D48=D48, D49=D49,
                )
        R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = X.compute_isobar_ratios(
                R13 = R13_VPDB * (1 + d13C_VPDB/1000),
                R18 = R18_VPDB * (1 + d18O_VPDB/1000) * ALPHA_18O_ACID_REACTION,
                D17O=D17O,
                )
        
        d45 = 1000 * (R45/R45wg - 1)
        d46 = 1000 * (R46/R46wg - 1)
        d47 = 1000 * (R47/R47wg - 1)
        d48 = 1000 * (R48/R48wg - 1)
        d49 = 1000 * (R49/R49wg - 1)

        for k in range(3): # dumb iteration to adjust for small changes in d47
                R47raw = (1 + (a47 * D47 + b47 * d47 + c47)/1000) * R47stoch
                R48raw = (1 + (a48 * D48 + b48 * d48 + c48)/1000) * R48stoch    
                d47 = 1000 * (R47raw/R47wg - 1)
                d48 = 1000 * (R48raw/R48wg - 1)

        return dict(
                Sample = sample,
                D17O = D17O,
                d13Cwg_VPDB = d13Cwg_VPDB,
                d18Owg_VSMOW = d18Owg_VSMOW,
                d45 = d45,
                d46 = d46,
                d47 = d47,
                d48 = d48,
                d49 = d49,
                )</code></pre>
</details>
</dd>
<dt id="D47crunch.smart_type"><code class="name flex">
<span>def <span class="ident">smart_type</span></span>(<span>x)</span>
</code></dt>
<dd>
<div class="desc"><p>Tries to convert string <code>x</code> to a float if it includes a decimal point, or
to an integer if it does not. If both attempts fail, return the original
string unchanged.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def smart_type(x):
        &#39;&#39;&#39;
        Tries to convert string `x` to a float if it includes a decimal point, or
        to an integer if it does not. If both attempts fail, return the original
        string unchanged.
        &#39;&#39;&#39;
        try:
                y = float(x)
        except ValueError:
                return x
        if &#39;.&#39; not in x:
                return int(y)
        return y</code></pre>
</details>
</dd>
<dt id="D47crunch.table_of_analyses"><code class="name flex">
<span>def <span class="ident">table_of_analyses</span></span>(<span>data47=None, data48=None, dir='output', filename=None, save_to_file=True, print_out=True, output=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print out, save to disk and/or return a combined table of analyses
for a pair of <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> and <code><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></code> objects.</p>
<p>If the sessions in <code>data47</code> and those in <code>data48</code> do not consist of
the exact same sets of analyses, the table will have two columns
<code>Session_47</code> and <code>Session_48</code> instead of a single <code>Session</code> column.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>data47</code>: <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> instance</li>
<li><code>data48</code>: <code><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></code> instance</li>
<li><code>dir</code>: the directory in which to save the table</li>
<li><code>filename</code>: the name to the csv file to write to</li>
<li><code>save_to_file</code>: whether to save the table to disk</li>
<li><code>print_out</code>: whether to print out the table</li>
<li><code>output</code>: if set to <code>'pretty'</code>: return a pretty text table (see <code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table()</a></code>);
if set to <code>'raw'</code>: return a list of list of strings
(e.g., <code>[['header1', 'header2'], ['0.1', '0.2']]</code>)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def table_of_analyses(
        data47 = None,
        data48 = None,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out, save to disk and/or return a combined table of analyses
        for a pair of `D47data` and `D48data` objects.

        If the sessions in `data47` and those in `data48` do not consist of
        the exact same sets of analyses, the table will have two columns
        `Session_47` and `Session_48` instead of a single `Session` column.

        __Parameters__

        + `data47`: `D47data` instance
        + `data48`: `D48data` instance
        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                if set to `&#39;raw&#39;`: return a list of list of strings
                (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;
        if data47 is None:
                if data48 is None:
                        raise TypeError(&#34;Arguments must include at least one D47data() or D48data() instance.&#34;)
                else:
                        return data48.table_of_analyses(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
        else:
                if data48 is None:
                        return data47.table_of_analyses(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
                else:
                        out47 = data47.table_of_analyses(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        out48 = data48.table_of_analyses(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        
                        if [l[1] for l in out47[1:]] == [l[1] for l in out48[1:]]: # if sessions are identical
                                out = transpose_table(transpose_table(out47) + transpose_table(out48)[-1:])
                        else:
                                out47[0][1] = &#39;Session_47&#39;
                                out48[0][1] = &#39;Session_48&#39;
                                out47 = transpose_table(out47)
                                out48 = transpose_table(out48)
                                out = transpose_table(out47[:2] + out48[1:2] + out47[2:] + out48[-1:])

                        if save_to_file:
                                if not os.path.exists(dir):
                                        os.makedirs(dir)
                                if filename is None:
                                        filename = f&#39;D47D48_sessions.csv&#39;
                                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                        fid.write(make_csv(out))
                        if print_out:
                                print(&#39;\n&#39;+pretty_table(out))
                        if output == &#39;raw&#39;:
                                return out
                        elif output == &#39;pretty&#39;:
                                return pretty_table(out)</code></pre>
</details>
</dd>
<dt id="D47crunch.table_of_samples"><code class="name flex">
<span>def <span class="ident">table_of_samples</span></span>(<span>data47=None, data48=None, dir='output', filename=None, save_to_file=True, print_out=True, output=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print out, save to disk and/or return a combined table of samples
for a pair of <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> and <code><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></code> objects.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>data47</code>: <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> instance</li>
<li><code>data48</code>: <code><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></code> instance</li>
<li><code>dir</code>: the directory in which to save the table</li>
<li><code>filename</code>: the name to the csv file to write to</li>
<li><code>save_to_file</code>: whether to save the table to disk</li>
<li><code>print_out</code>: whether to print out the table</li>
<li><code>output</code>: if set to <code>'pretty'</code>: return a pretty text table (see <code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table()</a></code>);
if set to <code>'raw'</code>: return a list of list of strings
(e.g., <code>[['header1', 'header2'], ['0.1', '0.2']]</code>)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def table_of_samples(
        data47 = None,
        data48 = None,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out, save to disk and/or return a combined table of samples
        for a pair of `D47data` and `D48data` objects.

        __Parameters__

        + `data47`: `D47data` instance
        + `data48`: `D48data` instance
        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                if set to `&#39;raw&#39;`: return a list of list of strings
                (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;
        if data47 is None:
                if data48 is None:
                        raise TypeError(&#34;Arguments must include at least one D47data() or D48data() instance.&#34;)
                else:
                        return data48.table_of_samples(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
        else:
                if data48 is None:
                        return data47.table_of_samples(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
                else:
                        out47 = data47.table_of_samples(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        out48 = data48.table_of_samples(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        out = transpose_table(transpose_table(out47) + transpose_table(out48)[4:])

                        if save_to_file:
                                if not os.path.exists(dir):
                                        os.makedirs(dir)
                                if filename is None:
                                        filename = f&#39;D47D48_samples.csv&#39;
                                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                        fid.write(make_csv(out))
                        if print_out:
                                print(&#39;\n&#39;+pretty_table(out))
                        if output == &#39;raw&#39;:
                                return out
                        elif output == &#39;pretty&#39;:
                                return pretty_table(out)</code></pre>
</details>
</dd>
<dt id="D47crunch.table_of_sessions"><code class="name flex">
<span>def <span class="ident">table_of_sessions</span></span>(<span>data47=None, data48=None, dir='output', filename=None, save_to_file=True, print_out=True, output=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print out, save to disk and/or return a combined table of sessions
for a pair of <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> and <code><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></code> objects.
<strong><em>Only applicable if the sessions in <code>data47</code> and those in <code>data48</code>
consist of the exact same sets of analyses.</em></strong></p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>data47</code>: <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> instance</li>
<li><code>data48</code>: <code><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></code> instance</li>
<li><code>dir</code>: the directory in which to save the table</li>
<li><code>filename</code>: the name to the csv file to write to</li>
<li><code>save_to_file</code>: whether to save the table to disk</li>
<li><code>print_out</code>: whether to print out the table</li>
<li><code>output</code>: if set to <code>'pretty'</code>: return a pretty text table (see <code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table()</a></code>);
if set to <code>'raw'</code>: return a list of list of strings
(e.g., <code>[['header1', 'header2'], ['0.1', '0.2']]</code>)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def table_of_sessions(
        data47 = None,
        data48 = None,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out, save to disk and/or return a combined table of sessions
        for a pair of `D47data` and `D48data` objects.
        __*Only applicable if the sessions in `data47` and those in `data48`
        consist of the exact same sets of analyses.*__

        __Parameters__

        + `data47`: `D47data` instance
        + `data48`: `D48data` instance
        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                if set to `&#39;raw&#39;`: return a list of list of strings
                (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;
        if data47 is None:
                if data48 is None:
                        raise TypeError(&#34;Arguments must include at least one D47data() or D48data() instance.&#34;)
                else:
                        return data48.table_of_sessions(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
        else:
                if data48 is None:
                        return data47.table_of_sessions(
                                dir = dir,
                                filename = filename,
                                save_to_file = save_to_file,
                                print_out = print_out,
                                output = output
                                )
                else:
                        out47 = data47.table_of_sessions(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        out48 = data48.table_of_sessions(save_to_file = False, print_out = False, output = &#39;raw&#39;)
                        for k,x in enumerate(out47[0]):
                                if k&gt;7:
                                        out47[0][k] = out47[0][k].replace(&#39;a&#39;, &#39;a_47&#39;).replace(&#39;b&#39;, &#39;b_47&#39;).replace(&#39;c&#39;, &#39;c_47&#39;)
                                        out48[0][k] = out48[0][k].replace(&#39;a&#39;, &#39;a_48&#39;).replace(&#39;b&#39;, &#39;b_48&#39;).replace(&#39;c&#39;, &#39;c_48&#39;)
                        out = transpose_table(transpose_table(out47) + transpose_table(out48)[7:])

                        if save_to_file:
                                if not os.path.exists(dir):
                                        os.makedirs(dir)
                                if filename is None:
                                        filename = f&#39;D47D48_sessions.csv&#39;
                                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                        fid.write(make_csv(out))
                        if print_out:
                                print(&#39;\n&#39;+pretty_table(out))
                        if output == &#39;raw&#39;:
                                return out
                        elif output == &#39;pretty&#39;:
                                return pretty_table(out)</code></pre>
</details>
</dd>
<dt id="D47crunch.transpose_table"><code class="name flex">
<span>def <span class="ident">transpose_table</span></span>(<span>x)</span>
</code></dt>
<dd>
<div class="desc"><p>Transpose a list if lists</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>x</code>: a list of lists</li>
</ul>
<p><strong>Example</strong></p>
<pre><code class="language-python">x = [[1, 2], [3, 4]]
print(transpose_table(x))
</code></pre>
<p>outputs:</p>
<pre><code class="language-python">[[1, 3], [2, 4]]
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transpose_table(x):
        &#39;&#39;&#39;
        Transpose a list if lists

        __Parameters__

        + `x`: a list of lists

        __Example__

        ```python
        x = [[1, 2], [3, 4]]
        print(transpose_table(x))
        ```

        outputs:

        ```python
        [[1, 3], [2, 4]]
        ```

        &#39;&#39;&#39;
        return [[e for e in c] for c in zip(*x)]</code></pre>
</details>
</dd>
<dt id="D47crunch.virtual_data"><code class="name flex">
<span>def <span class="ident">virtual_data</span></span>(<span>samples=[], a47=1.0, b47=0.0, c47=-0.9, a48=1.0, b48=0.0, c48=-0.45, rD47=0.015, rD48=0.045, d13Cwg_VPDB=None, d18Owg_VSMOW=None, session=None, Nominal_D47=None, Nominal_D48=None, Nominal_d13C_VPDB=None, Nominal_d18O_VPDB=None, ALPHA_18O_ACID_REACTION=None, R13_VPDB=None, R17_VSMOW=None, R18_VSMOW=None, lambda_17=None, R18_VPDB=None, seed=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Return list with simulated analyses from a single session.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>samples</code>: a list of entries; each entry is a dictionary with the following fields:<ul>
<li><code>Sample</code>: the name of the sample</li>
<li><code>d13C_VPDB</code>, <code>d18O_VPDB</code>: bulk composition of the carbonate sample</li>
<li><code>D47</code>, <code>D48</code>, <code>D49</code>, <code>D17O</code> (all optional): clumped-isotope and oxygen-17 anomalies of the carbonate sample</li>
<li><code>N</code>: how many analyses to generate for this sample</li>
</ul>
</li>
<li><code>a47</code>: scrambling factor for Δ<sub>47</sub></li>
<li><code>b47</code>: compositional nonlinearity for Δ<sub>47</sub></li>
<li><code>c47</code>: working gas offset for Δ<sub>47</sub></li>
<li><code>a48</code>: scrambling factor for Δ<sub>48</sub></li>
<li><code>b48</code>: compositional nonlinearity for Δ<sub>48</sub></li>
<li><code>c48</code>: working gas offset for Δ<sub>48</sub></li>
<li><code>rD47</code>: analytical repeatability of Δ<sub>47</sub></li>
<li><code>rD48</code>: analytical repeatability of Δ<sub>48</sub></li>
<li><code>d13Cwg_VPDB</code>, <code>d18Owg_VSMOW</code>: bulk composition of the working gas
(by default equal to the <code><a title="D47crunch.simulate_single_analysis" href="#D47crunch.simulate_single_analysis">simulate_single_analysis()</a></code> default values)</li>
<li><code>session</code>: name of the session (no name by default)</li>
<li><code>Nominal_D47</code>, <code>Nominal_D48</code>: where to lookup Δ<sub>47</sub> and Δ<sub>48</sub> values
if <code>D47</code> or <code>D48</code> are not specified (by default equal to the <code><a title="D47crunch.simulate_single_analysis" href="#D47crunch.simulate_single_analysis">simulate_single_analysis()</a></code> defaults)</li>
<li><code>Nominal_d13C_VPDB</code>, <code>Nominal_d18O_VPDB</code>: where to lookup δ<sup>13</sup>C and
δ<sup>18</sup>O values if <code>d13C_VPDB</code> or <code>d18O_VPDB</code> are not specified
(by default equal to the <code><a title="D47crunch.simulate_single_analysis" href="#D47crunch.simulate_single_analysis">simulate_single_analysis()</a></code> defaults)</li>
<li><code>ALPHA_18O_ACID_REACTION</code>: <sup>18</sup>O/<sup>16</sup>O acid fractionation factor
(by default equal to the <code><a title="D47crunch.simulate_single_analysis" href="#D47crunch.simulate_single_analysis">simulate_single_analysis()</a></code> defaults)</li>
<li><code>R13_VPDB</code>, <code>R17_VSMOW</code>, <code>R18_VSMOW</code>, <code>lambda_17</code>, <code>R18_VPDB</code>: oxygen-17
correction parameters (by default equal to the <code><a title="D47crunch.simulate_single_analysis" href="#D47crunch.simulate_single_analysis">simulate_single_analysis()</a></code> default)</li>
<li><code>seed</code>: explicitly set to a non-zero value to achieve random but repeatable simulations</li>
</ul>
<p>Here is an example of using this method to generate an arbitrary combination of
anchors and unknowns for a bunch of sessions:</p>
<pre><code class="language-py">args = dict(
        samples = [
                dict(Sample = 'ETH-1', N = 4),
                dict(Sample = 'ETH-2', N = 5),
                dict(Sample = 'ETH-3', N = 6),
                dict(
                        Sample = 'FOO',
                        N = 2,
                        d13C_VPDB = -5.,
                        d18O_VPDB = -10.,
                        D47 = 0.3,
                        D48 = 0.15
                        ),
                ],
        rD47 = 0.010,
        rD48 = 0.030,
        )
session1 = virtual_data(session = 'Session_01', **args, seed = 123)
session2 = virtual_data(session = 'Session_02', **args, seed = 1234)
session3 = virtual_data(session = 'Session_03', **args, seed = 12345)
session4 = virtual_data(session = 'Session_04', **args, seed = 123456)
D = D47data(session1 + session2 + session3 + session4)
D.crunch()
D.standardize()
D.table_of_sessions(verbose = True, save_to_file = False)
D.table_of_samples(verbose = True, save_to_file = False)
D.table_of_analyses(verbose = True, save_to_file = False)
</code></pre>
<p>This should output something like:</p>
<pre><code>[table_of_sessions] 
––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––
Session     Na  Nu  d13Cwg_VPDB  d18Owg_VSMOW  r_d13C  r_d18O   r_D47         a ± SE    1e3 x b ± SE          c ± SE
––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––
Session_01  15   2       -4.000        26.000  0.0000  0.0000  0.0110  0.997 ± 0.017  -0.097 ± 0.244  -0.896 ± 0.006
Session_02  15   2       -4.000        26.000  0.0000  0.0000  0.0109  1.002 ± 0.017  -0.110 ± 0.244  -0.901 ± 0.006
Session_03  15   2       -4.000        26.000  0.0000  0.0000  0.0107  1.010 ± 0.017  -0.037 ± 0.244  -0.904 ± 0.006
Session_04  15   2       -4.000        26.000  0.0000  0.0000  0.0106  1.001 ± 0.017  -0.181 ± 0.244  -0.894 ± 0.006
––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––

[table_of_samples] 
––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
Sample   N  d13C_VPDB  d18O_VSMOW     D47      SE    95% CL      SD  p_Levene
––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
ETH-1   16       2.02       37.02  0.2052                    0.0079          
ETH-2   20     -10.17       19.88  0.2085                    0.0100          
ETH-3   24       1.71       37.45  0.6132                    0.0105          
FOO      8      -5.00       28.91  0.2989  0.0040  ± 0.0080  0.0101     0.638
––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––

[table_of_analyses] 
–––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
UID     Session  Sample  d13Cwg_VPDB  d18Owg_VSMOW        d45        d46         d47         d48         d49   d13C_VPDB  d18O_VSMOW     D47raw     D48raw     D49raw       D47
–––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
1    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.122986   21.273526   27.780042    2.020000   37.024281  -0.706013  -0.328878  -0.000013  0.192554
2    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.130144   21.282615   27.780042    2.020000   37.024281  -0.698974  -0.319981  -0.000013  0.199615
3    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.149219   21.299572   27.780042    2.020000   37.024281  -0.680215  -0.303383  -0.000013  0.218429
4    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.136616   21.233128   27.780042    2.020000   37.024281  -0.692609  -0.368421  -0.000013  0.205998
5    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.697171  -12.203054  -18.023381  -10.170000   19.875825  -0.680771  -0.290128  -0.000002  0.215054
6    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701124  -12.184422  -18.023381  -10.170000   19.875825  -0.684772  -0.271272  -0.000002  0.211041
7    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.715105  -12.195251  -18.023381  -10.170000   19.875825  -0.698923  -0.282232  -0.000002  0.196848
8    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701529  -12.204963  -18.023381  -10.170000   19.875825  -0.685182  -0.292061  -0.000002  0.210630
9    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.711420  -12.228478  -18.023381  -10.170000   19.875825  -0.695193  -0.315859  -0.000002  0.200589
10   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.666719   22.296486   28.306614    1.710000   37.450394  -0.290459  -0.147284  -0.000014  0.609363
11   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.671553   22.291060   28.306614    1.710000   37.450394  -0.285706  -0.152592  -0.000014  0.614130
12   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.652854   22.273271   28.306614    1.710000   37.450394  -0.304093  -0.169990  -0.000014  0.595689
13   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.684168   22.263156   28.306614    1.710000   37.450394  -0.273302  -0.179883  -0.000014  0.626572
14   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.662702   22.253578   28.306614    1.710000   37.450394  -0.294409  -0.189251  -0.000014  0.605401
15   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.681957   22.230907   28.306614    1.710000   37.450394  -0.275476  -0.211424  -0.000014  0.624391
16   Session_01     FOO       -4.000        26.000  -0.840413   2.828738    1.312044    5.395798    4.665655   -5.000000   28.907344  -0.598436  -0.268176  -0.000006  0.298996
17   Session_01     FOO       -4.000        26.000  -0.840413   2.828738    1.328123    5.307086    4.665655   -5.000000   28.907344  -0.582387  -0.356389  -0.000006  0.315092
18   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.122201   21.340606   27.780042    2.020000   37.024281  -0.706785  -0.263217  -0.000013  0.195135
19   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.134868   21.305714   27.780042    2.020000   37.024281  -0.694328  -0.297370  -0.000013  0.207564
20   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.140008   21.261931   27.780042    2.020000   37.024281  -0.689273  -0.340227  -0.000013  0.212607
21   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.135540   21.298472   27.780042    2.020000   37.024281  -0.693667  -0.304459  -0.000013  0.208224
22   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701213  -12.202602  -18.023381  -10.170000   19.875825  -0.684862  -0.289671  -0.000002  0.213842
23   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.685649  -12.190405  -18.023381  -10.170000   19.875825  -0.669108  -0.277327  -0.000002  0.229559
24   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.719003  -12.257955  -18.023381  -10.170000   19.875825  -0.702869  -0.345692  -0.000002  0.195876
25   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.700592  -12.204641  -18.023381  -10.170000   19.875825  -0.684233  -0.291735  -0.000002  0.214469
26   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.720426  -12.214561  -18.023381  -10.170000   19.875825  -0.704308  -0.301774  -0.000002  0.194439
27   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.673044   22.262090   28.306614    1.710000   37.450394  -0.284240  -0.180926  -0.000014  0.616730
28   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.666542   22.263401   28.306614    1.710000   37.450394  -0.290634  -0.179643  -0.000014  0.610350
29   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.680487   22.243486   28.306614    1.710000   37.450394  -0.276921  -0.199121  -0.000014  0.624031
30   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.663900   22.245175   28.306614    1.710000   37.450394  -0.293231  -0.197469  -0.000014  0.607759
31   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.674379   22.301309   28.306614    1.710000   37.450394  -0.282927  -0.142568  -0.000014  0.618039
32   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.660825   22.270466   28.306614    1.710000   37.450394  -0.296255  -0.172733  -0.000014  0.604742
33   Session_02     FOO       -4.000        26.000  -0.840413   2.828738    1.294076    5.349940    4.665655   -5.000000   28.907344  -0.616369  -0.313776  -0.000006  0.283707
34   Session_02     FOO       -4.000        26.000  -0.840413   2.828738    1.313775    5.292121    4.665655   -5.000000   28.907344  -0.596708  -0.371269  -0.000006  0.303323
35   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.121613   21.259909   27.780042    2.020000   37.024281  -0.707364  -0.342207  -0.000013  0.194934
36   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.145714   21.304889   27.780042    2.020000   37.024281  -0.683661  -0.298178  -0.000013  0.218401
37   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.126573   21.325093   27.780042    2.020000   37.024281  -0.702485  -0.278401  -0.000013  0.199764
38   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.132057   21.323211   27.780042    2.020000   37.024281  -0.697092  -0.280244  -0.000013  0.205104
39   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.708448  -12.232023  -18.023381  -10.170000   19.875825  -0.692185  -0.319447  -0.000002  0.208915
40   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.714417  -12.202504  -18.023381  -10.170000   19.875825  -0.698226  -0.289572  -0.000002  0.202934
41   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.720039  -12.264469  -18.023381  -10.170000   19.875825  -0.703917  -0.352285  -0.000002  0.197300
42   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701953  -12.228550  -18.023381  -10.170000   19.875825  -0.685611  -0.315932  -0.000002  0.215423
43   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.704535  -12.213634  -18.023381  -10.170000   19.875825  -0.688224  -0.300836  -0.000002  0.212837
44   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.652920   22.230043   28.306614    1.710000   37.450394  -0.304028  -0.212269  -0.000014  0.594265
45   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.691485   22.261017   28.306614    1.710000   37.450394  -0.266106  -0.181975  -0.000014  0.631810
46   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.679119   22.305357   28.306614    1.710000   37.450394  -0.278266  -0.138609  -0.000014  0.619771
47   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.663623   22.327286   28.306614    1.710000   37.450394  -0.293503  -0.117161  -0.000014  0.604685
48   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.678524   22.282103   28.306614    1.710000   37.450394  -0.278851  -0.161352  -0.000014  0.619192
49   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.666246   22.283361   28.306614    1.710000   37.450394  -0.290925  -0.160121  -0.000014  0.607238
50   Session_03     FOO       -4.000        26.000  -0.840413   2.828738    1.309929    5.340249    4.665655   -5.000000   28.907344  -0.600546  -0.323413  -0.000006  0.300148
51   Session_03     FOO       -4.000        26.000  -0.840413   2.828738    1.317548    5.334102    4.665655   -5.000000   28.907344  -0.592942  -0.329524  -0.000006  0.307676
52   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.136865   21.300298   27.780042    2.020000   37.024281  -0.692364  -0.302672  -0.000013  0.204033
53   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.133538   21.291260   27.780042    2.020000   37.024281  -0.695637  -0.311519  -0.000013  0.200762
54   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.139991   21.319865   27.780042    2.020000   37.024281  -0.689290  -0.283519  -0.000013  0.207107
55   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.145748   21.330075   27.780042    2.020000   37.024281  -0.683629  -0.273524  -0.000013  0.212766
56   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.702989  -12.202762  -18.023381  -10.170000   19.875825  -0.686660  -0.289833  -0.000002  0.204507
57   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.692830  -12.240287  -18.023381  -10.170000   19.875825  -0.676377  -0.327811  -0.000002  0.214786
58   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.702899  -12.180291  -18.023381  -10.170000   19.875825  -0.686568  -0.267091  -0.000002  0.204598
59   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.709282  -12.282257  -18.023381  -10.170000   19.875825  -0.693029  -0.370287  -0.000002  0.198140
60   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.679330  -12.235994  -18.023381  -10.170000   19.875825  -0.662712  -0.323466  -0.000002  0.228446
61   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.695594   22.238663   28.306614    1.710000   37.450394  -0.262066  -0.203838  -0.000014  0.634200
62   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.663504   22.286354   28.306614    1.710000   37.450394  -0.293620  -0.157194  -0.000014  0.602656
63   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.666457   22.254290   28.306614    1.710000   37.450394  -0.290717  -0.188555  -0.000014  0.605558
64   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.666910   22.223232   28.306614    1.710000   37.450394  -0.290271  -0.218930  -0.000014  0.606004
65   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.679662   22.257256   28.306614    1.710000   37.450394  -0.277732  -0.185653  -0.000014  0.618539
66   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.676768   22.267680   28.306614    1.710000   37.450394  -0.280578  -0.175459  -0.000014  0.615693
67   Session_04     FOO       -4.000        26.000  -0.840413   2.828738    1.307663    5.317330    4.665655   -5.000000   28.907344  -0.602808  -0.346202  -0.000006  0.290853
68   Session_04     FOO       -4.000        26.000  -0.840413   2.828738    1.308562    5.331400    4.665655   -5.000000   28.907344  -0.601911  -0.332212  -0.000006  0.291749
–––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def virtual_data(
        samples = [],
        a47 = 1., b47 = 0., c47 = -0.9,
        a48 = 1., b48 = 0., c48 = -0.45,
        rD47 = 0.015, rD48 = 0.045,
        d13Cwg_VPDB = None, d18Owg_VSMOW = None,
        session = None,
        Nominal_D47 = None, Nominal_D48 = None,
        Nominal_d13C_VPDB = None, Nominal_d18O_VPDB = None,
        ALPHA_18O_ACID_REACTION = None,
        R13_VPDB = None,
        R17_VSMOW = None,
        R18_VSMOW = None,
        lambda_17 = None,
        R18_VPDB = None,
        seed = 0,
        ):
        &#39;&#39;&#39;
        Return list with simulated analyses from a single session.
        
        __Parameters__
        
        + `samples`: a list of entries; each entry is a dictionary with the following fields:
            * `Sample`: the name of the sample
            * `d13C_VPDB`, `d18O_VPDB`: bulk composition of the carbonate sample
            * `D47`, `D48`, `D49`, `D17O` (all optional): clumped-isotope and oxygen-17 anomalies of the carbonate sample
            * `N`: how many analyses to generate for this sample
        + `a47`: scrambling factor for Δ&lt;sub&gt;47&lt;/sub&gt;
        + `b47`: compositional nonlinearity for Δ&lt;sub&gt;47&lt;/sub&gt;
        + `c47`: working gas offset for Δ&lt;sub&gt;47&lt;/sub&gt;
        + `a48`: scrambling factor for Δ&lt;sub&gt;48&lt;/sub&gt;
        + `b48`: compositional nonlinearity for Δ&lt;sub&gt;48&lt;/sub&gt;
        + `c48`: working gas offset for Δ&lt;sub&gt;48&lt;/sub&gt;
        + `rD47`: analytical repeatability of Δ&lt;sub&gt;47&lt;/sub&gt;
        + `rD48`: analytical repeatability of Δ&lt;sub&gt;48&lt;/sub&gt;
        + `d13Cwg_VPDB`, `d18Owg_VSMOW`: bulk composition of the working gas
                (by default equal to the `simulate_single_analysis` default values)
        + `session`: name of the session (no name by default)
        + `Nominal_D47`, `Nominal_D48`: where to lookup Δ&lt;sub&gt;47&lt;/sub&gt; and Δ&lt;sub&gt;48&lt;/sub&gt; values
                if `D47` or `D48` are not specified (by default equal to the `simulate_single_analysis` defaults)
        + `Nominal_d13C_VPDB`, `Nominal_d18O_VPDB`: where to lookup δ&lt;sup&gt;13&lt;/sup&gt;C and
                δ&lt;sup&gt;18&lt;/sup&gt;O values if `d13C_VPDB` or `d18O_VPDB` are not specified 
                (by default equal to the `simulate_single_analysis` defaults)
        + `ALPHA_18O_ACID_REACTION`: &lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;O acid fractionation factor
                (by default equal to the `simulate_single_analysis` defaults)
        + `R13_VPDB`, `R17_VSMOW`, `R18_VSMOW`, `lambda_17`, `R18_VPDB`: oxygen-17
                correction parameters (by default equal to the `simulate_single_analysis` default)
        + `seed`: explicitly set to a non-zero value to achieve random but repeatable simulations
        
                
        Here is an example of using this method to generate an arbitrary combination of
        anchors and unknowns for a bunch of sessions:

        ```py
        args = dict(
                samples = [
                        dict(Sample = &#39;ETH-1&#39;, N = 4),
                        dict(Sample = &#39;ETH-2&#39;, N = 5),
                        dict(Sample = &#39;ETH-3&#39;, N = 6),
                        dict(
                                Sample = &#39;FOO&#39;,
                                N = 2,
                                d13C_VPDB = -5.,
                                d18O_VPDB = -10.,
                                D47 = 0.3,
                                D48 = 0.15
                                ),
                        ],
                rD47 = 0.010,
                rD48 = 0.030,
                )
        session1 = virtual_data(session = &#39;Session_01&#39;, **args, seed = 123)
        session2 = virtual_data(session = &#39;Session_02&#39;, **args, seed = 1234)
        session3 = virtual_data(session = &#39;Session_03&#39;, **args, seed = 12345)
        session4 = virtual_data(session = &#39;Session_04&#39;, **args, seed = 123456)
        D = D47data(session1 + session2 + session3 + session4)
        D.crunch()
        D.standardize()
        D.table_of_sessions(verbose = True, save_to_file = False)
        D.table_of_samples(verbose = True, save_to_file = False)
        D.table_of_analyses(verbose = True, save_to_file = False)
        ```
        
        This should output something like:
        
        ```
        [table_of_sessions] 
        ––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––
        Session     Na  Nu  d13Cwg_VPDB  d18Owg_VSMOW  r_d13C  r_d18O   r_D47         a ± SE    1e3 x b ± SE          c ± SE
        ––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––
        Session_01  15   2       -4.000        26.000  0.0000  0.0000  0.0110  0.997 ± 0.017  -0.097 ± 0.244  -0.896 ± 0.006
        Session_02  15   2       -4.000        26.000  0.0000  0.0000  0.0109  1.002 ± 0.017  -0.110 ± 0.244  -0.901 ± 0.006
        Session_03  15   2       -4.000        26.000  0.0000  0.0000  0.0107  1.010 ± 0.017  -0.037 ± 0.244  -0.904 ± 0.006
        Session_04  15   2       -4.000        26.000  0.0000  0.0000  0.0106  1.001 ± 0.017  -0.181 ± 0.244  -0.894 ± 0.006
        ––––––––––  ––  ––  –––––––––––  ––––––––––––  ––––––  ––––––  ––––––  –––––––––––––  ––––––––––––––  ––––––––––––––

        [table_of_samples] 
        ––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
        Sample   N  d13C_VPDB  d18O_VSMOW     D47      SE    95% CL      SD  p_Levene
        ––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––
        ETH-1   16       2.02       37.02  0.2052                    0.0079          
        ETH-2   20     -10.17       19.88  0.2085                    0.0100          
        ETH-3   24       1.71       37.45  0.6132                    0.0105          
        FOO      8      -5.00       28.91  0.2989  0.0040  ± 0.0080  0.0101     0.638
        ––––––  ––  –––––––––  ––––––––––  ––––––  ––––––  ––––––––  ––––––  ––––––––

        [table_of_analyses] 
        –––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
        UID     Session  Sample  d13Cwg_VPDB  d18Owg_VSMOW        d45        d46         d47         d48         d49   d13C_VPDB  d18O_VSMOW     D47raw     D48raw     D49raw       D47
        –––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
        1    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.122986   21.273526   27.780042    2.020000   37.024281  -0.706013  -0.328878  -0.000013  0.192554
        2    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.130144   21.282615   27.780042    2.020000   37.024281  -0.698974  -0.319981  -0.000013  0.199615
        3    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.149219   21.299572   27.780042    2.020000   37.024281  -0.680215  -0.303383  -0.000013  0.218429
        4    Session_01   ETH-1       -4.000        26.000   6.018962  10.747026   16.136616   21.233128   27.780042    2.020000   37.024281  -0.692609  -0.368421  -0.000013  0.205998
        5    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.697171  -12.203054  -18.023381  -10.170000   19.875825  -0.680771  -0.290128  -0.000002  0.215054
        6    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701124  -12.184422  -18.023381  -10.170000   19.875825  -0.684772  -0.271272  -0.000002  0.211041
        7    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.715105  -12.195251  -18.023381  -10.170000   19.875825  -0.698923  -0.282232  -0.000002  0.196848
        8    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701529  -12.204963  -18.023381  -10.170000   19.875825  -0.685182  -0.292061  -0.000002  0.210630
        9    Session_01   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.711420  -12.228478  -18.023381  -10.170000   19.875825  -0.695193  -0.315859  -0.000002  0.200589
        10   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.666719   22.296486   28.306614    1.710000   37.450394  -0.290459  -0.147284  -0.000014  0.609363
        11   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.671553   22.291060   28.306614    1.710000   37.450394  -0.285706  -0.152592  -0.000014  0.614130
        12   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.652854   22.273271   28.306614    1.710000   37.450394  -0.304093  -0.169990  -0.000014  0.595689
        13   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.684168   22.263156   28.306614    1.710000   37.450394  -0.273302  -0.179883  -0.000014  0.626572
        14   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.662702   22.253578   28.306614    1.710000   37.450394  -0.294409  -0.189251  -0.000014  0.605401
        15   Session_01   ETH-3       -4.000        26.000   5.742374  11.161270   16.681957   22.230907   28.306614    1.710000   37.450394  -0.275476  -0.211424  -0.000014  0.624391
        16   Session_01     FOO       -4.000        26.000  -0.840413   2.828738    1.312044    5.395798    4.665655   -5.000000   28.907344  -0.598436  -0.268176  -0.000006  0.298996
        17   Session_01     FOO       -4.000        26.000  -0.840413   2.828738    1.328123    5.307086    4.665655   -5.000000   28.907344  -0.582387  -0.356389  -0.000006  0.315092
        18   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.122201   21.340606   27.780042    2.020000   37.024281  -0.706785  -0.263217  -0.000013  0.195135
        19   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.134868   21.305714   27.780042    2.020000   37.024281  -0.694328  -0.297370  -0.000013  0.207564
        20   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.140008   21.261931   27.780042    2.020000   37.024281  -0.689273  -0.340227  -0.000013  0.212607
        21   Session_02   ETH-1       -4.000        26.000   6.018962  10.747026   16.135540   21.298472   27.780042    2.020000   37.024281  -0.693667  -0.304459  -0.000013  0.208224
        22   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701213  -12.202602  -18.023381  -10.170000   19.875825  -0.684862  -0.289671  -0.000002  0.213842
        23   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.685649  -12.190405  -18.023381  -10.170000   19.875825  -0.669108  -0.277327  -0.000002  0.229559
        24   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.719003  -12.257955  -18.023381  -10.170000   19.875825  -0.702869  -0.345692  -0.000002  0.195876
        25   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.700592  -12.204641  -18.023381  -10.170000   19.875825  -0.684233  -0.291735  -0.000002  0.214469
        26   Session_02   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.720426  -12.214561  -18.023381  -10.170000   19.875825  -0.704308  -0.301774  -0.000002  0.194439
        27   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.673044   22.262090   28.306614    1.710000   37.450394  -0.284240  -0.180926  -0.000014  0.616730
        28   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.666542   22.263401   28.306614    1.710000   37.450394  -0.290634  -0.179643  -0.000014  0.610350
        29   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.680487   22.243486   28.306614    1.710000   37.450394  -0.276921  -0.199121  -0.000014  0.624031
        30   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.663900   22.245175   28.306614    1.710000   37.450394  -0.293231  -0.197469  -0.000014  0.607759
        31   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.674379   22.301309   28.306614    1.710000   37.450394  -0.282927  -0.142568  -0.000014  0.618039
        32   Session_02   ETH-3       -4.000        26.000   5.742374  11.161270   16.660825   22.270466   28.306614    1.710000   37.450394  -0.296255  -0.172733  -0.000014  0.604742
        33   Session_02     FOO       -4.000        26.000  -0.840413   2.828738    1.294076    5.349940    4.665655   -5.000000   28.907344  -0.616369  -0.313776  -0.000006  0.283707
        34   Session_02     FOO       -4.000        26.000  -0.840413   2.828738    1.313775    5.292121    4.665655   -5.000000   28.907344  -0.596708  -0.371269  -0.000006  0.303323
        35   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.121613   21.259909   27.780042    2.020000   37.024281  -0.707364  -0.342207  -0.000013  0.194934
        36   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.145714   21.304889   27.780042    2.020000   37.024281  -0.683661  -0.298178  -0.000013  0.218401
        37   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.126573   21.325093   27.780042    2.020000   37.024281  -0.702485  -0.278401  -0.000013  0.199764
        38   Session_03   ETH-1       -4.000        26.000   6.018962  10.747026   16.132057   21.323211   27.780042    2.020000   37.024281  -0.697092  -0.280244  -0.000013  0.205104
        39   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.708448  -12.232023  -18.023381  -10.170000   19.875825  -0.692185  -0.319447  -0.000002  0.208915
        40   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.714417  -12.202504  -18.023381  -10.170000   19.875825  -0.698226  -0.289572  -0.000002  0.202934
        41   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.720039  -12.264469  -18.023381  -10.170000   19.875825  -0.703917  -0.352285  -0.000002  0.197300
        42   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.701953  -12.228550  -18.023381  -10.170000   19.875825  -0.685611  -0.315932  -0.000002  0.215423
        43   Session_03   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.704535  -12.213634  -18.023381  -10.170000   19.875825  -0.688224  -0.300836  -0.000002  0.212837
        44   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.652920   22.230043   28.306614    1.710000   37.450394  -0.304028  -0.212269  -0.000014  0.594265
        45   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.691485   22.261017   28.306614    1.710000   37.450394  -0.266106  -0.181975  -0.000014  0.631810
        46   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.679119   22.305357   28.306614    1.710000   37.450394  -0.278266  -0.138609  -0.000014  0.619771
        47   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.663623   22.327286   28.306614    1.710000   37.450394  -0.293503  -0.117161  -0.000014  0.604685
        48   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.678524   22.282103   28.306614    1.710000   37.450394  -0.278851  -0.161352  -0.000014  0.619192
        49   Session_03   ETH-3       -4.000        26.000   5.742374  11.161270   16.666246   22.283361   28.306614    1.710000   37.450394  -0.290925  -0.160121  -0.000014  0.607238
        50   Session_03     FOO       -4.000        26.000  -0.840413   2.828738    1.309929    5.340249    4.665655   -5.000000   28.907344  -0.600546  -0.323413  -0.000006  0.300148
        51   Session_03     FOO       -4.000        26.000  -0.840413   2.828738    1.317548    5.334102    4.665655   -5.000000   28.907344  -0.592942  -0.329524  -0.000006  0.307676
        52   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.136865   21.300298   27.780042    2.020000   37.024281  -0.692364  -0.302672  -0.000013  0.204033
        53   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.133538   21.291260   27.780042    2.020000   37.024281  -0.695637  -0.311519  -0.000013  0.200762
        54   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.139991   21.319865   27.780042    2.020000   37.024281  -0.689290  -0.283519  -0.000013  0.207107
        55   Session_04   ETH-1       -4.000        26.000   6.018962  10.747026   16.145748   21.330075   27.780042    2.020000   37.024281  -0.683629  -0.273524  -0.000013  0.212766
        56   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.702989  -12.202762  -18.023381  -10.170000   19.875825  -0.686660  -0.289833  -0.000002  0.204507
        57   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.692830  -12.240287  -18.023381  -10.170000   19.875825  -0.676377  -0.327811  -0.000002  0.214786
        58   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.702899  -12.180291  -18.023381  -10.170000   19.875825  -0.686568  -0.267091  -0.000002  0.204598
        59   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.709282  -12.282257  -18.023381  -10.170000   19.875825  -0.693029  -0.370287  -0.000002  0.198140
        60   Session_04   ETH-2       -4.000        26.000  -5.995859  -5.976076  -12.679330  -12.235994  -18.023381  -10.170000   19.875825  -0.662712  -0.323466  -0.000002  0.228446
        61   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.695594   22.238663   28.306614    1.710000   37.450394  -0.262066  -0.203838  -0.000014  0.634200
        62   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.663504   22.286354   28.306614    1.710000   37.450394  -0.293620  -0.157194  -0.000014  0.602656
        63   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.666457   22.254290   28.306614    1.710000   37.450394  -0.290717  -0.188555  -0.000014  0.605558
        64   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.666910   22.223232   28.306614    1.710000   37.450394  -0.290271  -0.218930  -0.000014  0.606004
        65   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.679662   22.257256   28.306614    1.710000   37.450394  -0.277732  -0.185653  -0.000014  0.618539
        66   Session_04   ETH-3       -4.000        26.000   5.742374  11.161270   16.676768   22.267680   28.306614    1.710000   37.450394  -0.280578  -0.175459  -0.000014  0.615693
        67   Session_04     FOO       -4.000        26.000  -0.840413   2.828738    1.307663    5.317330    4.665655   -5.000000   28.907344  -0.602808  -0.346202  -0.000006  0.290853
        68   Session_04     FOO       -4.000        26.000  -0.840413   2.828738    1.308562    5.331400    4.665655   -5.000000   28.907344  -0.601911  -0.332212  -0.000006  0.291749
        –––  ––––––––––  ––––––  –––––––––––  ––––––––––––  –––––––––  –––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  ––––––––––  –––––––––  –––––––––  –––––––––  ––––––––
        ```
        &#39;&#39;&#39;
        
        kwargs = locals().copy()

        from numpy import random as nprandom
        if seed:
                rng = nprandom.default_rng(seed)
        else:
                rng = nprandom.default_rng()
        
        N = sum([s[&#39;N&#39;] for s in samples])
        errors47 = rng.normal(loc = 0, scale = 1, size = N) # generate random measurement errors
        errors47 *= rD47 / stdev(errors47) # scale errors to rD47
        errors48 = rng.normal(loc = 0, scale = 1, size = N) # generate random measurement errors
        errors48 *= rD48 / stdev(errors48) # scale errors to rD48
        
        k = 0
        out = []
        for s in samples:
                kw = {}
                kw[&#39;sample&#39;] = s[&#39;Sample&#39;]
                kw = {
                        **kw,
                        **{var: kwargs[var]
                                for var in [
                                        &#39;d13Cwg_VPDB&#39;, &#39;d18Owg_VSMOW&#39;, &#39;ALPHA_18O_ACID_REACTION&#39;,
                                        &#39;Nominal_D47&#39;, &#39;Nominal_D48&#39;, &#39;Nominal_d13C_VPDB&#39;, &#39;Nominal_d18O_VPDB&#39;,
                                        &#39;R13_VPDB&#39;, &#39;R17_VSMOW&#39;, &#39;R18_VSMOW&#39;, &#39;lambda_17&#39;, &#39;R18_VPDB&#39;,
                                        &#39;a47&#39;, &#39;b47&#39;, &#39;c47&#39;, &#39;a48&#39;, &#39;b48&#39;, &#39;c48&#39;,
                                        ]
                                if kwargs[var] is not None},
                        **{var: s[var]
                                for var in [&#39;d13C_VPDB&#39;, &#39;d18O_VPDB&#39;, &#39;D47&#39;, &#39;D48&#39;, &#39;D49&#39;, &#39;D17O&#39;]
                                if var in s},
                        }

                sN = s[&#39;N&#39;]
                while sN:
                        out.append(simulate_single_analysis(**kw))
                        out[-1][&#39;d47&#39;] += errors47[k] * a47
                        out[-1][&#39;d48&#39;] += errors48[k] * a48
                        sN -= 1
                        k += 1

                if session is not None:
                        for r in out:
                                r[&#39;Session&#39;] = session
        return out</code></pre>
</details>
</dd>
<dt id="D47crunch.w_avg"><code class="name flex">
<span>def <span class="ident">w_avg</span></span>(<span>X, sX)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute variance-weighted average</p>
<p>Returns the value and SE of the weighted average of the elements of <code>X</code>,
with relative weights equal to their inverse variances (<code>1/sX**2</code>).</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>X</code>: array-like of elements to average</li>
<li><code>sX</code>: array-like of the corresponding SE values</li>
</ul>
<p><strong>Tip</strong></p>
<p>If <code>X</code> and <code>sX</code> are initially arranged as a list of <code>(x, sx)</code> doublets,
they may be rearranged using <code>zip()</code>:</p>
<pre><code class="language-python">foo = [(0, 0.1), (1, 0.05), (2, 0.05)]
print(w_avg(*zip(*foo)))

# output:
# (1.3333333333333333, 0.03333333333333334)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def w_avg(X, sX) :
        &#39;&#39;&#39;
        Compute variance-weighted average

        Returns the value and SE of the weighted average of the elements of `X`,
        with relative weights equal to their inverse variances (`1/sX**2`).

        __Parameters__

        + `X`: array-like of elements to average
        + `sX`: array-like of the corresponding SE values

        __Tip__

        If `X` and `sX` are initially arranged as a list of `(x, sx)` doublets,
        they may be rearranged using `zip()`:

        ```python
        foo = [(0, 0.1), (1, 0.05), (2, 0.05)]
        print(w_avg(*zip(*foo)))

        # output:
        # (1.3333333333333333, 0.03333333333333334)
        ```
        &#39;&#39;&#39;
        X = [ x for x in X ]
        sX = [ sx for sx in sX ]
        W = [ sx**-2 for sx in sX ]
        W = [ w/sum(W) for w in W ]
        Xavg = sum([ w*x for w,x in zip(W,X) ])
        sXavg = sum([ w**2*sx**2 for w,sx in zip(W,sX) ])**.5
        return Xavg, sXavg</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="D47crunch.D47data"><code class="flex name class">
<span>class <span class="ident">D47data</span></span>
<span>(</span><span>l=[], **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Store and process data for a large set of Δ<sub>47</sub> analyses,
usually comprising more than one analytical session.</p>
<p><strong>Parameters:</strong> same as <code><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class D47data(D4xdata):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ&lt;sub&gt;47&lt;/sub&gt; analyses,
        usually comprising more than one analytical session.
        &#39;&#39;&#39;

        Nominal_D4x = {
                &#39;ETH-1&#39;:   0.2052,
                &#39;ETH-2&#39;:   0.2085,
                &#39;ETH-3&#39;:   0.6132,
                &#39;ETH-4&#39;:   0.4511,
                &#39;IAEA-C1&#39;: 0.3018,
                &#39;IAEA-C2&#39;: 0.6409,
                &#39;MERCK&#39;:   0.5135,
                } # I-CDES (Bernasconi et al., 2021)
        &#39;&#39;&#39;
        Nominal Δ&lt;sub&gt;47&lt;/sub&gt; values assigned to the Δ&lt;sub&gt;47&lt;/sub&gt; anchor samples, used by
        `D47data.standardize()` to normalize unknown samples to an absolute Δ&lt;sub&gt;47&lt;/sub&gt;
        reference frame.

        By default equal to (after [Bernasconi et al. (2021)]):
        ```py
        {
                &#39;ETH-1&#39;   : 0.2052,
                &#39;ETH-2&#39;   : 0.2085,
                &#39;ETH-3&#39;   : 0.6132,
                &#39;ETH-4&#39;   : 0.4511,
                &#39;IAEA-C1&#39; : 0.3018,
                &#39;IAEA-C2&#39; : 0.6409,
                &#39;MERCK&#39;   : 0.5135,
        }
        ```

        [Bernasconi et al. (2021)]: https://doi.org/10.1029/2020GC009588
        &#39;&#39;&#39;


        @property
        def Nominal_D47(self):
                return self.Nominal_D4x
        

        @Nominal_D47.setter
        def Nominal_D47(self, new):
                self.Nominal_D4x = dict(**new)
                self.refresh()


        def __init__(self, l = [], **kwargs):
                &#39;&#39;&#39;
                __Parameters:__ same as `D4xdata.__init__()`
                &#39;&#39;&#39;
                D4xdata.__init__(self, l = l, mass = &#39;47&#39;, **kwargs)


        def D47fromTeq(self, fCo2eqD47 = &#39;petersen&#39;, priority = &#39;new&#39;):
                &#39;&#39;&#39;
                Find all samples for which `Teq` is specified, compute equilibrium Δ&lt;sub&gt;47&lt;/sub&gt;
                value for that temperature, and add treat these samples as additional anchors.

                __Parameters__

                + `fCo2eqD47`: Which CO&lt;sub&gt;2&lt;/sub&gt; equilibrium law to use
                (`petersen`: [Petersen et al. (2019)];
                `wang`: [Wang et al. (2019)]).
                + `priority`: if `replace`: forget old anchors and only use the new ones;
                if `new`: keep pre-existing anchors but update them in case of conflict
                between old and new Δ&lt;sub&gt;47&lt;/sub&gt; values;
                if `old`: keep pre-existing anchors but preserve their original Δ&lt;sub&gt;47&lt;/sub&gt;
                values in case of conflict.

                [Petersen et al. (2019)]: https://doi.org/10.1029/2018GC008127
                [Wang et al. (2019)]: https://doi.org/10.1016/j.gca.2004.05.039
                &#39;&#39;&#39;
                f = {
                        &#39;petersen&#39;: fCO2eqD47_Petersen,
                        &#39;wang&#39;: fCO2eqD47_Wang,
                        }[fCo2eqD47]
                foo = {}
                for r in self:
                        if &#39;Teq&#39; in r:
                                if r[&#39;Sample&#39;] in foo:
                                        assert foo[r[&#39;Sample&#39;]] == f(r[&#39;Teq&#39;]), f&#39;Different values of `Teq` provided for sample `{r[&#34;Sample&#34;]}`.&#39;
                                else:
                                        foo[r[&#39;Sample&#39;]] = f(r[&#39;Teq&#39;])
                        else:
                                        assert r[&#39;Sample&#39;] not in foo, f&#39;`Teq` is inconsistently specified for sample `{r[&#34;Sample&#34;]}`.&#39;

                if priority == &#39;replace&#39;:
                        self.Nominal_D47 = {}
                for s in foo:
                        if priority != &#39;old&#39; or s not in self.Nominal_D47:
                                self.Nominal_D47[s] = foo[s]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></li>
<li>builtins.list</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="D47crunch.D47data.Nominal_D4x"><code class="name">var <span class="ident">Nominal_D4x</span></code></dt>
<dd>
<div class="desc"><p>Nominal Δ<sub>47</sub> values assigned to the Δ<sub>47</sub> anchor samples, used by
<code><a title="D47crunch.D47data.standardize" href="#D47crunch.D4xdata.standardize">D4xdata.standardize()</a></code> to normalize unknown samples to an absolute Δ<sub>47</sub>
reference frame.</p>
<p>By default equal to (after <a href="https://doi.org/10.1029/2020GC009588">Bernasconi et al. (2021)</a>):</p>
<pre><code class="language-py">{
        'ETH-1'   : 0.2052,
        'ETH-2'   : 0.2085,
        'ETH-3'   : 0.6132,
        'ETH-4'   : 0.4511,
        'IAEA-C1' : 0.3018,
        'IAEA-C2' : 0.6409,
        'MERCK'   : 0.5135,
}
</code></pre></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="D47crunch.D47data.Nominal_D47"><code class="name">var <span class="ident">Nominal_D47</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def Nominal_D47(self):
        return self.Nominal_D4x</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="D47crunch.D47data.D47fromTeq"><code class="name flex">
<span>def <span class="ident">D47fromTeq</span></span>(<span>self, fCo2eqD47='petersen', priority='new')</span>
</code></dt>
<dd>
<div class="desc"><p>Find all samples for which <code>Teq</code> is specified, compute equilibrium Δ<sub>47</sub>
value for that temperature, and add treat these samples as additional anchors.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fCo2eqD47</code>: Which CO<sub>2</sub> equilibrium law to use
(<code>petersen</code>: <a href="https://doi.org/10.1029/2018GC008127">Petersen et al. (2019)</a>;
<code>wang</code>: <a href="https://doi.org/10.1016/j.gca.2004.05.039">Wang et al. (2019)</a>).</li>
<li><code>priority</code>: if <code>replace</code>: forget old anchors and only use the new ones;
if <code>new</code>: keep pre-existing anchors but update them in case of conflict
between old and new Δ<sub>47</sub> values;
if <code>old</code>: keep pre-existing anchors but preserve their original Δ<sub>47</sub>
values in case of conflict.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def D47fromTeq(self, fCo2eqD47 = &#39;petersen&#39;, priority = &#39;new&#39;):
        &#39;&#39;&#39;
        Find all samples for which `Teq` is specified, compute equilibrium Δ&lt;sub&gt;47&lt;/sub&gt;
        value for that temperature, and add treat these samples as additional anchors.

        __Parameters__

        + `fCo2eqD47`: Which CO&lt;sub&gt;2&lt;/sub&gt; equilibrium law to use
        (`petersen`: [Petersen et al. (2019)];
        `wang`: [Wang et al. (2019)]).
        + `priority`: if `replace`: forget old anchors and only use the new ones;
        if `new`: keep pre-existing anchors but update them in case of conflict
        between old and new Δ&lt;sub&gt;47&lt;/sub&gt; values;
        if `old`: keep pre-existing anchors but preserve their original Δ&lt;sub&gt;47&lt;/sub&gt;
        values in case of conflict.

        [Petersen et al. (2019)]: https://doi.org/10.1029/2018GC008127
        [Wang et al. (2019)]: https://doi.org/10.1016/j.gca.2004.05.039
        &#39;&#39;&#39;
        f = {
                &#39;petersen&#39;: fCO2eqD47_Petersen,
                &#39;wang&#39;: fCO2eqD47_Wang,
                }[fCo2eqD47]
        foo = {}
        for r in self:
                if &#39;Teq&#39; in r:
                        if r[&#39;Sample&#39;] in foo:
                                assert foo[r[&#39;Sample&#39;]] == f(r[&#39;Teq&#39;]), f&#39;Different values of `Teq` provided for sample `{r[&#34;Sample&#34;]}`.&#39;
                        else:
                                foo[r[&#39;Sample&#39;]] = f(r[&#39;Teq&#39;])
                else:
                                assert r[&#39;Sample&#39;] not in foo, f&#39;`Teq` is inconsistently specified for sample `{r[&#34;Sample&#34;]}`.&#39;

        if priority == &#39;replace&#39;:
                self.Nominal_D47 = {}
        for s in foo:
                if priority != &#39;old&#39; or s not in self.Nominal_D47:
                        self.Nominal_D47[s] = foo[s]</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></b></code>:
<ul class="hlist">
<li><code><a title="D47crunch.D4xdata.ALPHA_18O_ACID_REACTION" href="#D47crunch.D4xdata.ALPHA_18O_ACID_REACTION">ALPHA_18O_ACID_REACTION</a></code></li>
<li><code><a title="D47crunch.D4xdata.LEVENE_REF_SAMPLE" href="#D47crunch.D4xdata.LEVENE_REF_SAMPLE">LEVENE_REF_SAMPLE</a></code></li>
<li><code><a title="D47crunch.D4xdata.Nominal_d13C_VPDB" href="#D47crunch.D4xdata.Nominal_d13C_VPDB">Nominal_d13C_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.Nominal_d18O_VPDB" href="#D47crunch.D4xdata.Nominal_d18O_VPDB">Nominal_d18O_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R13_VPDB" href="#D47crunch.D4xdata.R13_VPDB">R13_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R17_VPDB" href="#D47crunch.D4xdata.R17_VPDB">R17_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R17_VSMOW" href="#D47crunch.D4xdata.R17_VSMOW">R17_VSMOW</a></code></li>
<li><code><a title="D47crunch.D4xdata.R18_VPDB" href="#D47crunch.D4xdata.R18_VPDB">R18_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R18_VSMOW" href="#D47crunch.D4xdata.R18_VSMOW">R18_VSMOW</a></code></li>
<li><code><a title="D47crunch.D4xdata.assign_timestamps" href="#D47crunch.D4xdata.assign_timestamps">assign_timestamps</a></code></li>
<li><code><a title="D47crunch.D4xdata.combine_samples" href="#D47crunch.D4xdata.combine_samples">combine_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_bulk_and_clumping_deltas" href="#D47crunch.D4xdata.compute_bulk_and_clumping_deltas">compute_bulk_and_clumping_deltas</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_bulk_delta" href="#D47crunch.D4xdata.compute_bulk_delta">compute_bulk_delta</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_isobar_ratios" href="#D47crunch.D4xdata.compute_isobar_ratios">compute_isobar_ratios</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_r" href="#D47crunch.D4xdata.compute_r">compute_r</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate" href="#D47crunch.D4xdata.consolidate">consolidate</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate_samples" href="#D47crunch.D4xdata.consolidate_samples">consolidate_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate_sessions" href="#D47crunch.D4xdata.consolidate_sessions">consolidate_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.crunch" href="#D47crunch.D4xdata.crunch">crunch</a></code></li>
<li><code><a title="D47crunch.D4xdata.d13C_STANDARDIZATION_METHOD" href="#D47crunch.D4xdata.d13C_STANDARDIZATION_METHOD">d13C_STANDARDIZATION_METHOD</a></code></li>
<li><code><a title="D47crunch.D4xdata.d18O_STANDARDIZATION_METHOD" href="#D47crunch.D4xdata.d18O_STANDARDIZATION_METHOD">d18O_STANDARDIZATION_METHOD</a></code></li>
<li><code><a title="D47crunch.D4xdata.fill_in_missing_info" href="#D47crunch.D4xdata.fill_in_missing_info">fill_in_missing_info</a></code></li>
<li><code><a title="D47crunch.D4xdata.input" href="#D47crunch.D4xdata.input">input</a></code></li>
<li><code><a title="D47crunch.D4xdata.lambda_17" href="#D47crunch.D4xdata.lambda_17">lambda_17</a></code></li>
<li><code><a title="D47crunch.D4xdata.log" href="#D47crunch.D4xdata.log">log</a></code></li>
<li><code><a title="D47crunch.D4xdata.make_verbal" href="#D47crunch.D4xdata.make_verbal">make_verbal</a></code></li>
<li><code><a title="D47crunch.D4xdata.msg" href="#D47crunch.D4xdata.msg">msg</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_distribution_of_analyses" href="#D47crunch.D4xdata.plot_distribution_of_analyses">plot_distribution_of_analyses</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_residuals" href="#D47crunch.D4xdata.plot_residuals">plot_residuals</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_sessions" href="#D47crunch.D4xdata.plot_sessions">plot_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_single_session" href="#D47crunch.D4xdata.plot_single_session">plot_single_session</a></code></li>
<li><code><a title="D47crunch.D4xdata.read" href="#D47crunch.D4xdata.read">read</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh" href="#D47crunch.D4xdata.refresh">refresh</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh_samples" href="#D47crunch.D4xdata.refresh_samples">refresh_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh_sessions" href="#D47crunch.D4xdata.refresh_sessions">refresh_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.repeatabilities" href="#D47crunch.D4xdata.repeatabilities">repeatabilities</a></code></li>
<li><code><a title="D47crunch.D4xdata.report" href="#D47crunch.D4xdata.report">report</a></code></li>
<li><code><a title="D47crunch.D4xdata.rmswd" href="#D47crunch.D4xdata.rmswd">rmswd</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_D4x_correl" href="#D47crunch.D4xdata.sample_D4x_correl">sample_D4x_correl</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_D4x_covar" href="#D47crunch.D4xdata.sample_D4x_covar">sample_D4x_covar</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_average" href="#D47crunch.D4xdata.sample_average">sample_average</a></code></li>
<li><code><a title="D47crunch.D4xdata.simulate" href="#D47crunch.D4xdata.simulate">simulate</a></code></li>
<li><code><a title="D47crunch.D4xdata.split_samples" href="#D47crunch.D4xdata.split_samples">split_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardization_error" href="#D47crunch.D4xdata.standardization_error">standardization_error</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize" href="#D47crunch.D4xdata.standardize">standardize</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize_d13C" href="#D47crunch.D4xdata.standardize_d13C">standardize_d13C</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize_d18O" href="#D47crunch.D4xdata.standardize_d18O">standardize_d18O</a></code></li>
<li><code><a title="D47crunch.D4xdata.summary" href="#D47crunch.D4xdata.summary">summary</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_analyses" href="#D47crunch.D4xdata.table_of_analyses">table_of_analyses</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_samples" href="#D47crunch.D4xdata.table_of_samples">table_of_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_sessions" href="#D47crunch.D4xdata.table_of_sessions">table_of_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.unsplit_samples" href="#D47crunch.D4xdata.unsplit_samples">unsplit_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.vmsg" href="#D47crunch.D4xdata.vmsg">vmsg</a></code></li>
<li><code><a title="D47crunch.D4xdata.wg" href="#D47crunch.D4xdata.wg">wg</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="D47crunch.D48data"><code class="flex name class">
<span>class <span class="ident">D48data</span></span>
<span>(</span><span>l=[], **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Store and process data for a large set of Δ<sub>48</sub> analyses,
usually comprising more than one analytical session.</p>
<p><strong>Parameters:</strong> same as <code><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class D48data(D4xdata):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ&lt;sub&gt;48&lt;/sub&gt; analyses,
        usually comprising more than one analytical session.
        &#39;&#39;&#39;

        Nominal_D4x = {
                &#39;ETH-1&#39;:  0.138,
                &#39;ETH-2&#39;:  0.138,
                &#39;ETH-3&#39;:  0.270,
                &#39;ETH-4&#39;:  0.223,
                &#39;GU-1&#39;:  -0.419,
                } # (Fiebig et al., 2019, 2021)
        &#39;&#39;&#39;
        Nominal Δ&lt;sub&gt;48&lt;/sub&gt; values assigned to the Δ&lt;sub&gt;48&lt;/sub&gt; anchor samples, used by
        `D48data.standardize()` to normalize unknown samples to an absolute Δ&lt;sub&gt;48&lt;/sub&gt;
        reference frame.

        By default equal to (after [Fiebig et al. (2019)], Fiebig et al. (in press)):
        ```py
        {
                &#39;ETH-1&#39; :  0.138,
                &#39;ETH-2&#39; :  0.138,
                &#39;ETH-3&#39; :  0.270,
                &#39;ETH-4&#39; :  0.223,
                &#39;GU-1&#39;  : -0.419,
        }
        ```

        [Fiebig et al. (2019)]: https://doi.org/10.1016/j.chemgeo.2019.05.019
        &#39;&#39;&#39;


        @property
        def Nominal_D48(self):
                return self.Nominal_D4x

        
        @Nominal_D48.setter
        def Nominal_D48(self, new):
                self.Nominal_D4x = dict(**new)
                self.refresh()


        def __init__(self, l = [], **kwargs):
                &#39;&#39;&#39;
                __Parameters:__ same as `D4xdata.__init__()`
                &#39;&#39;&#39;
                D4xdata.__init__(self, l = l, mass = &#39;48&#39;, **kwargs)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></li>
<li>builtins.list</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="D47crunch.D48data.Nominal_D4x"><code class="name">var <span class="ident">Nominal_D4x</span></code></dt>
<dd>
<div class="desc"><p>Nominal Δ<sub>48</sub> values assigned to the Δ<sub>48</sub> anchor samples, used by
<code><a title="D47crunch.D48data.standardize" href="#D47crunch.D4xdata.standardize">D4xdata.standardize()</a></code> to normalize unknown samples to an absolute Δ<sub>48</sub>
reference frame.</p>
<p>By default equal to (after <a href="https://doi.org/10.1016/j.chemgeo.2019.05.019">Fiebig et al. (2019)</a>, Fiebig et al. (in press)):</p>
<pre><code class="language-py">{
        'ETH-1' :  0.138,
        'ETH-2' :  0.138,
        'ETH-3' :  0.270,
        'ETH-4' :  0.223,
        'GU-1'  : -0.419,
}
</code></pre></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="D47crunch.D48data.Nominal_D48"><code class="name">var <span class="ident">Nominal_D48</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def Nominal_D48(self):
        return self.Nominal_D4x</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></b></code>:
<ul class="hlist">
<li><code><a title="D47crunch.D4xdata.ALPHA_18O_ACID_REACTION" href="#D47crunch.D4xdata.ALPHA_18O_ACID_REACTION">ALPHA_18O_ACID_REACTION</a></code></li>
<li><code><a title="D47crunch.D4xdata.LEVENE_REF_SAMPLE" href="#D47crunch.D4xdata.LEVENE_REF_SAMPLE">LEVENE_REF_SAMPLE</a></code></li>
<li><code><a title="D47crunch.D4xdata.Nominal_d13C_VPDB" href="#D47crunch.D4xdata.Nominal_d13C_VPDB">Nominal_d13C_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.Nominal_d18O_VPDB" href="#D47crunch.D4xdata.Nominal_d18O_VPDB">Nominal_d18O_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R13_VPDB" href="#D47crunch.D4xdata.R13_VPDB">R13_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R17_VPDB" href="#D47crunch.D4xdata.R17_VPDB">R17_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R17_VSMOW" href="#D47crunch.D4xdata.R17_VSMOW">R17_VSMOW</a></code></li>
<li><code><a title="D47crunch.D4xdata.R18_VPDB" href="#D47crunch.D4xdata.R18_VPDB">R18_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R18_VSMOW" href="#D47crunch.D4xdata.R18_VSMOW">R18_VSMOW</a></code></li>
<li><code><a title="D47crunch.D4xdata.assign_timestamps" href="#D47crunch.D4xdata.assign_timestamps">assign_timestamps</a></code></li>
<li><code><a title="D47crunch.D4xdata.combine_samples" href="#D47crunch.D4xdata.combine_samples">combine_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_bulk_and_clumping_deltas" href="#D47crunch.D4xdata.compute_bulk_and_clumping_deltas">compute_bulk_and_clumping_deltas</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_bulk_delta" href="#D47crunch.D4xdata.compute_bulk_delta">compute_bulk_delta</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_isobar_ratios" href="#D47crunch.D4xdata.compute_isobar_ratios">compute_isobar_ratios</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_r" href="#D47crunch.D4xdata.compute_r">compute_r</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate" href="#D47crunch.D4xdata.consolidate">consolidate</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate_samples" href="#D47crunch.D4xdata.consolidate_samples">consolidate_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate_sessions" href="#D47crunch.D4xdata.consolidate_sessions">consolidate_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.crunch" href="#D47crunch.D4xdata.crunch">crunch</a></code></li>
<li><code><a title="D47crunch.D4xdata.d13C_STANDARDIZATION_METHOD" href="#D47crunch.D4xdata.d13C_STANDARDIZATION_METHOD">d13C_STANDARDIZATION_METHOD</a></code></li>
<li><code><a title="D47crunch.D4xdata.d18O_STANDARDIZATION_METHOD" href="#D47crunch.D4xdata.d18O_STANDARDIZATION_METHOD">d18O_STANDARDIZATION_METHOD</a></code></li>
<li><code><a title="D47crunch.D4xdata.fill_in_missing_info" href="#D47crunch.D4xdata.fill_in_missing_info">fill_in_missing_info</a></code></li>
<li><code><a title="D47crunch.D4xdata.input" href="#D47crunch.D4xdata.input">input</a></code></li>
<li><code><a title="D47crunch.D4xdata.lambda_17" href="#D47crunch.D4xdata.lambda_17">lambda_17</a></code></li>
<li><code><a title="D47crunch.D4xdata.log" href="#D47crunch.D4xdata.log">log</a></code></li>
<li><code><a title="D47crunch.D4xdata.make_verbal" href="#D47crunch.D4xdata.make_verbal">make_verbal</a></code></li>
<li><code><a title="D47crunch.D4xdata.msg" href="#D47crunch.D4xdata.msg">msg</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_distribution_of_analyses" href="#D47crunch.D4xdata.plot_distribution_of_analyses">plot_distribution_of_analyses</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_residuals" href="#D47crunch.D4xdata.plot_residuals">plot_residuals</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_sessions" href="#D47crunch.D4xdata.plot_sessions">plot_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_single_session" href="#D47crunch.D4xdata.plot_single_session">plot_single_session</a></code></li>
<li><code><a title="D47crunch.D4xdata.read" href="#D47crunch.D4xdata.read">read</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh" href="#D47crunch.D4xdata.refresh">refresh</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh_samples" href="#D47crunch.D4xdata.refresh_samples">refresh_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh_sessions" href="#D47crunch.D4xdata.refresh_sessions">refresh_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.repeatabilities" href="#D47crunch.D4xdata.repeatabilities">repeatabilities</a></code></li>
<li><code><a title="D47crunch.D4xdata.report" href="#D47crunch.D4xdata.report">report</a></code></li>
<li><code><a title="D47crunch.D4xdata.rmswd" href="#D47crunch.D4xdata.rmswd">rmswd</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_D4x_correl" href="#D47crunch.D4xdata.sample_D4x_correl">sample_D4x_correl</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_D4x_covar" href="#D47crunch.D4xdata.sample_D4x_covar">sample_D4x_covar</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_average" href="#D47crunch.D4xdata.sample_average">sample_average</a></code></li>
<li><code><a title="D47crunch.D4xdata.simulate" href="#D47crunch.D4xdata.simulate">simulate</a></code></li>
<li><code><a title="D47crunch.D4xdata.split_samples" href="#D47crunch.D4xdata.split_samples">split_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardization_error" href="#D47crunch.D4xdata.standardization_error">standardization_error</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize" href="#D47crunch.D4xdata.standardize">standardize</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize_d13C" href="#D47crunch.D4xdata.standardize_d13C">standardize_d13C</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize_d18O" href="#D47crunch.D4xdata.standardize_d18O">standardize_d18O</a></code></li>
<li><code><a title="D47crunch.D4xdata.summary" href="#D47crunch.D4xdata.summary">summary</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_analyses" href="#D47crunch.D4xdata.table_of_analyses">table_of_analyses</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_samples" href="#D47crunch.D4xdata.table_of_samples">table_of_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_sessions" href="#D47crunch.D4xdata.table_of_sessions">table_of_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.unsplit_samples" href="#D47crunch.D4xdata.unsplit_samples">unsplit_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.vmsg" href="#D47crunch.D4xdata.vmsg">vmsg</a></code></li>
<li><code><a title="D47crunch.D4xdata.wg" href="#D47crunch.D4xdata.wg">wg</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="D47crunch.D4xdata"><code class="flex name class">
<span>class <span class="ident">D4xdata</span></span>
<span>(</span><span>l=[], mass='47', logfile='', session='mySession', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Store and process data for a large set of Δ<sub>47</sub> and/or Δ<sub>48</sub>
analyses, usually comprising more than one analytical session.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>l</code>: a list of dictionaries, with each dictionary including at least the keys
<code>Sample</code>, <code>d45</code>, <code>d46</code>, and <code>d47</code> or <code>d48</code>.</li>
<li><code>logfile</code>: if specified, write detailed logs to this file path when calling <code><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></code> methods.</li>
<li><code>session</code>: define session name for analyses without a <code>Session</code> key</li>
<li><code>verbose</code>: if <code>True</code>, print out detailed logs when calling <code><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></code> methods.</li>
</ul>
<p>Returns a <code><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></code> object derived from <code>list</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class D4xdata(list):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ&lt;sub&gt;47&lt;/sub&gt; and/or Δ&lt;sub&gt;48&lt;/sub&gt;
        analyses, usually comprising more than one analytical session.
        &#39;&#39;&#39;

        ### 17O CORRECTION PARAMETERS
        R13_VPDB = 0.01118  # (Chang &amp; Li, 1990)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;13&lt;/sup&gt;C/&lt;sup&gt;12&lt;/sup&gt;C) ratio of VPDB.
        By default equal to 0.01118 ([Chang &amp; Li, 1990])

        [Chang &amp; Li, 1990]: http://www.cnki.com.cn/Article/CJFDTotal-JXTW199004006.htm
        &#39;&#39;&#39;

        R18_VSMOW = 0.0020052  # (Baertschi, 1976)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VSMOW.
        By default equal to 0.0020052 ([Baertschi, 1976])

        [Baertschi, 1976]: https://doi.org/10.1016/0012-821X(76)90115-1
        &#39;&#39;&#39;

        lambda_17 = 0.528  # (Barkan &amp; Luz, 2005)
        &#39;&#39;&#39;
        Mass-dependent exponent for triple oxygen isotopes.
        By default equal to 0.528 ([Barkan &amp; Luz, 2005])

        [Barkan &amp; Luz, 2005]: https://doi.org/10.1002/rcm.2250
        &#39;&#39;&#39;

        R17_VSMOW = 0.00038475  # (Assonov &amp; Brenninkmeijer, 2003, rescaled to R13_VPDB)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;17&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VSMOW.
        By default equal to 0.00038475
        ([Assonov &amp; Brenninkmeijer, 2003], rescaled to `R13_VPDB`)

        [Assonov &amp; Brenninkmeijer, 2003]: https://dx.doi.org/10.1002/rcm.1011
        &#39;&#39;&#39;

        R18_VPDB = R18_VSMOW * 1.03092
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VPDB.
        By definition equal to `R18_VSMOW * 1.03092`.
        &#39;&#39;&#39;

        R17_VPDB = R17_VSMOW * 1.03092 ** lambda_17
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;17&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VPDB.
        By definition equal to `R17_VSMOW * 1.03092 ** lambda_17`.
        &#39;&#39;&#39;

        LEVENE_REF_SAMPLE = &#39;ETH-3&#39;
        &#39;&#39;&#39;
        After the Δ&lt;sub&gt;4x&lt;/sub&gt; standardization step, each sample is tested to
        assess whether the Δ&lt;sub&gt;4x&lt;/sub&gt; variance within all analyses for that
        sample differs significantly from that observed for a given reference
        sample (using [Levene&#39;s test], which yields a p-value corresponding to
        the null hypothesis that the underlying variances are equal).

        `LEVENE_REF_SAMPLE` (by default equal to `&#39;ETH-3&#39;`) specifies which
        sample should be used as a reference for this test.

        [Levene&#39;s test]: https://en.wikipedia.org/wiki/Levene%27s_test
        &#39;&#39;&#39;

        ALPHA_18O_ACID_REACTION = round(np.exp(3.59 / (90 + 273.15) - 1.79e-3), 6)  # (Kim et al., 2007, calcite)
        &#39;&#39;&#39;
        Specifies the &lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;O fractionation factor generally applicable
        to acid reactions in the dataset. Currently used by `D4xdata.wg()`,
        `D4xdata.standardize_d13C`, and `D4xdata.standardize_d18O`.

        By default equal to 1.008129 (calcite reacted at 90 °C, [Kim et al., 2007]).

        [Kim et al., 2007]: https://dx.doi.org/10.1016/j.chemgeo.2007.08.005
        &#39;&#39;&#39;

        Nominal_d13C_VPDB = {
                &#39;ETH-1&#39;: 2.02,
                &#39;ETH-2&#39;: -10.17,
                &#39;ETH-3&#39;: 1.71,
                }       # (Bernasconi et al., 2018)
        &#39;&#39;&#39;
        Nominal δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; values assigned to carbonate standards, used by
        `D4xdata.standardize_d13C()`.

        By default equal to `{&#39;ETH-1&#39;: 2.02, &#39;ETH-2&#39;: -10.17, &#39;ETH-3&#39;: 1.71}` after
        [Bernasconi et al. (2018)].

        [Bernasconi et al. (2018)]: https://doi.org/10.1029/2017GC007385
        &#39;&#39;&#39;

        Nominal_d18O_VPDB = {
                &#39;ETH-1&#39;: -2.19,
                &#39;ETH-2&#39;: -18.69,
                &#39;ETH-3&#39;: -1.78,
                }       # (Bernasconi et al., 2018)
        &#39;&#39;&#39;
        Nominal δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VPDB&lt;/sub&gt; values assigned to carbonate standards, used by
        `D4xdata.standardize_d18O()`.

        By default equal to `{&#39;ETH-1&#39;: -2.19, &#39;ETH-2&#39;: -18.69, &#39;ETH-3&#39;: -1.78}` after
        [Bernasconi et al. (2018)].

        [Bernasconi et al. (2018)]: https://doi.org/10.1029/2017GC007385
        &#39;&#39;&#39;

        d13C_STANDARDIZATION_METHOD = &#39;2pt&#39;
        &#39;&#39;&#39;
        Method by which to standardize δ&lt;sup&gt;13&lt;/sup&gt;C values:
        
        + `none`: do not apply any δ&lt;sup&gt;13&lt;/sup&gt;C standardization.
        + `&#39;1pt&#39;`: within each session, offset all initial δ&lt;sup&gt;13&lt;/sup&gt;C values so as to
        minimize the difference between final δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; values and
        `Nominal_d13C_VPDB` (averaged over all analyses for which `Nominal_d13C_VPDB` is defined).
        + `&#39;2pt&#39;`: within each session, apply a affine trasformation to all δ&lt;sup&gt;13&lt;/sup&gt;C
        values so as to minimize the difference between final δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt;
        values and `Nominal_d13C_VPDB` (averaged over all analyses for which `Nominal_d13C_VPDB`
        is defined).
        &#39;&#39;&#39;

        d18O_STANDARDIZATION_METHOD = &#39;2pt&#39;
        &#39;&#39;&#39;
        Method by which to standardize δ&lt;sup&gt;18&lt;/sup&gt;O values:
        
        + `none`: do not apply any δ&lt;sup&gt;18&lt;/sup&gt;O standardization.
        + `&#39;1pt&#39;`: within each session, offset all initial δ&lt;sup&gt;18&lt;/sup&gt;O values so as to
        minimize the difference between final δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VPDB&lt;/sub&gt; values and
        `Nominal_d18O_VPDB` (averaged over all analyses for which `Nominal_d18O_VPDB` is defined).
        + `&#39;2pt&#39;`: within each session, apply a affine trasformation to all δ&lt;sup&gt;18&lt;/sup&gt;O
        values so as to minimize the difference between final δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VPDB&lt;/sub&gt;
        values and `Nominal_d18O_VPDB` (averaged over all analyses for which `Nominal_d18O_VPDB`
        is defined).
        &#39;&#39;&#39;

        def __init__(self, l = [], mass = &#39;47&#39;, logfile = &#39;&#39;, session = &#39;mySession&#39;, verbose = False):
                &#39;&#39;&#39;
                __Parameters__

                + `l`: a list of dictionaries, with each dictionary including at least the keys
                `Sample`, `d45`, `d46`, and `d47` or `d48`.
                + `logfile`: if specified, write detailed logs to this file path when calling `D4xdata` methods.
                + `session`: define session name for analyses without a `Session` key
                + `verbose`: if `True`, print out detailed logs when calling `D4xdata` methods.

                Returns a `D4xdata` object derived from `list`.
                &#39;&#39;&#39;
                self._4x = mass
                self.verbose = verbose
                self.prefix = &#39;D4xdata&#39;
                self.logfile = logfile
                list.__init__(self, l)
                self.Nf = None
                self.repeatability = {}
                self.refresh(session = session)


        def make_verbal(oldfun):
                &#39;&#39;&#39;
                Decorator: allow temporarily changing `self.prefix` and overriding `self.verbose`.
                &#39;&#39;&#39;
                @wraps(oldfun)
                def newfun(*args, verbose = &#39;&#39;, **kwargs):
                        myself = args[0]
                        oldprefix = myself.prefix
                        myself.prefix = oldfun.__name__
                        if verbose != &#39;&#39;:
                                oldverbose = myself.verbose
                                myself.verbose = verbose
                        out = oldfun(*args, **kwargs)
                        myself.prefix = oldprefix
                        if verbose != &#39;&#39;:
                                myself.verbose = oldverbose
                        return out
                return newfun


        def msg(self, txt):
                &#39;&#39;&#39;
                Log a message to `self.logfile`, and print it out if `verbose = True`
                &#39;&#39;&#39;
                self.log(txt)
                if self.verbose:
                        print(f&#39;{f&#34;[{self.prefix}]&#34;:&lt;16} {txt}&#39;)


        def vmsg(self, txt):
                &#39;&#39;&#39;
                Log a message to `self.logfile` and print it out
                &#39;&#39;&#39;
                self.log(txt)
                print(txt)


        def log(self, *txts):
                &#39;&#39;&#39;
                Log a message to `self.logfile`
                &#39;&#39;&#39;
                if self.logfile:
                        with open(self.logfile, &#39;a&#39;) as fid:
                                for txt in txts:
                                        fid.write(f&#39;\n{dt.now().strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)} {f&#34;[{self.prefix}]&#34;:&lt;16} {txt}&#39;)


        def refresh(self, session = &#39;mySession&#39;):
                &#39;&#39;&#39;
                Update `self.sessions`, `self.samples`, `self.anchors`, and `self.unknowns`.
                &#39;&#39;&#39;
                self.fill_in_missing_info(session = session)
                self.refresh_sessions()
                self.refresh_samples()


        def refresh_sessions(self):
                &#39;&#39;&#39;
                Update `self.sessions` and set `scrambling_drift`, `slope_drift`, and `wg_drift`
                to `False` for all sessions.
                &#39;&#39;&#39;
                self.sessions = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                        for s in sorted({r[&#39;Session&#39;] for r in self})
                        }
                for s in self.sessions:
                        self.sessions[s][&#39;scrambling_drift&#39;] = False
                        self.sessions[s][&#39;slope_drift&#39;] = False
                        self.sessions[s][&#39;wg_drift&#39;] = False
                        self.sessions[s][&#39;d13C_standardization_method&#39;] = self.d13C_STANDARDIZATION_METHOD
                        self.sessions[s][&#39;d18O_standardization_method&#39;] = self.d18O_STANDARDIZATION_METHOD


        def refresh_samples(self):
                &#39;&#39;&#39;
                Define `self.samples`, `self.anchors`, and `self.unknowns`.
                &#39;&#39;&#39;
                self.samples = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                        for s in sorted({r[&#39;Sample&#39;] for r in self})
                        }
                self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D4x}
                self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D4x}


        def read(self, filename, sep = &#39;&#39;, session = &#39;&#39;):
                &#39;&#39;&#39;
                Read file in csv format to load data into a `D47data` object.

                In the csv file, spaces before and after field separators (`&#39;,&#39;` by default)
                are optional. Each line corresponds to a single analysis.

                The required fields are:

                + `UID`: a unique identifier
                + `Session`: an identifier for the analytical session
                + `Sample`: a sample identifier
                + `d45`, `d46`, and at least one of `d47` or `d48`: the working-gas delta values

                Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
                VSMOW, λ = `self.lambda_17`), and are otherwise assumed to be zero. Working-gas deltas `d47`, `d48`
                and `d49` are optional, and set to NaN by default.

                __Parameters__

                + `fileneme`: the path of the file to read
                + `sep`: csv separator delimiting the fields
                + `session`: set `Session` field to this string for all analyses
                &#39;&#39;&#39;
                with open(filename) as fid:
                        self.input(fid.read(), sep = sep, session = session)


        def input(self, txt, sep = &#39;&#39;, session = &#39;&#39;):
                &#39;&#39;&#39;
                Read `txt` string in csv format to load analysis data into a `D47data` object.

                In the csv string, spaces before and after field separators (`&#39;,&#39;` by default)
                are optional. Each line corresponds to a single analysis.

                The required fields are:

                + `UID`: a unique identifier
                + `Session`: an identifier for the analytical session
                + `Sample`: a sample identifier
                + `d45`, `d46`, and at least one of `d47` or `d48`: the working-gas delta values

                Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
                VSMOW, λ = `self.lambda_17`), and are otherwise assumed to be zero. Working-gas deltas `d47`, `d48`
                and `d49` are optional, and set to NaN by default.

                __Parameters__

                + `txt`: the csv string to read
                + `sep`: csv separator delimiting the fields. By default, use `,`, `;`, or `\t`,
                whichever appers most often in `txt`.
                + `session`: set `Session` field to this string for all analyses
                &#39;&#39;&#39;
                if sep == &#39;&#39;:
                        sep = sorted(&#39;,;\t&#39;, key = lambda x: - txt.count(x))[0]
                txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
                data = [{k: v if k in [&#39;UID&#39;, &#39;Session&#39;, &#39;Sample&#39;] else smart_type(v) for k,v in zip(txt[0], l) if v != &#39;&#39;} for l in txt[1:]]

                if session != &#39;&#39;:
                        for r in data:
                                r[&#39;Session&#39;] = session

                self += data
                self.refresh()


        @make_verbal
        def wg(self, samples = None, a18_acid = None):
                &#39;&#39;&#39;
                Compute bulk composition of the working gas for each session based on
                the carbonate standards defined in both `self.Nominal_d13C_VPDB` and
                `self.Nominal_d18O_VPDB`.
                &#39;&#39;&#39;

                self.msg(&#39;Computing WG composition:&#39;)

                if a18_acid is None:
                        a18_acid = self.ALPHA_18O_ACID_REACTION
                if samples is None:
                        samples = [s for s in self.Nominal_d13C_VPDB if s in self.Nominal_d18O_VPDB]

                assert a18_acid, f&#39;Acid fractionation factor should not be zero.&#39;

                samples = [s for s in samples if s in self.Nominal_d13C_VPDB and s in self.Nominal_d18O_VPDB]
                R45R46_standards = {}
                for sample in samples:
                        d13C_vpdb = self.Nominal_d13C_VPDB[sample]
                        d18O_vpdb = self.Nominal_d18O_VPDB[sample]
                        R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
                        R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
                        R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

                        C12_s = 1 / (1 + R13_s)
                        C13_s = R13_s / (1 + R13_s)
                        C16_s = 1 / (1 + R17_s + R18_s)
                        C17_s = R17_s / (1 + R17_s + R18_s)
                        C18_s = R18_s / (1 + R17_s + R18_s)

                        C626_s = C12_s * C16_s ** 2
                        C627_s = 2 * C12_s * C16_s * C17_s
                        C628_s = 2 * C12_s * C16_s * C18_s
                        C636_s = C13_s * C16_s ** 2
                        C637_s = 2 * C13_s * C16_s * C17_s
                        C727_s = C12_s * C17_s ** 2

                        R45_s = (C627_s + C636_s) / C626_s
                        R46_s = (C628_s + C637_s + C727_s) / C626_s
                        R45R46_standards[sample] = (R45_s, R46_s)
                
                for s in self.sessions:
                        db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in samples]
                        assert db, f&#39;No sample from {samples} found in session &#34;{s}&#34;.&#39;
#                       dbsamples = sorted({r[&#39;Sample&#39;] for r in db})

                        X = [r[&#39;d45&#39;] for r in db]
                        Y = [R45R46_standards[r[&#39;Sample&#39;]][0] for r in db]
                        x1, x2 = np.min(X), np.max(X)

                        if x1 &lt; x2:
                                wgcoord = x1/(x1-x2)
                        else:
                                wgcoord = 999

                        if wgcoord &lt; -.5 or wgcoord &gt; 1.5:
                                # unreasonable to extrapolate to d45 = 0
                                R45_wg = np.mean([y/(1+x/1000) for x,y in zip(X,Y)])
                        else :
                                # d45 = 0 is reasonably well bracketed
                                R45_wg = np.polyfit(X, Y, 1)[1]

                        X = [r[&#39;d46&#39;] for r in db]
                        Y = [R45R46_standards[r[&#39;Sample&#39;]][1] for r in db]
                        x1, x2 = np.min(X), np.max(X)

                        if x1 &lt; x2:
                                wgcoord = x1/(x1-x2)
                        else:
                                wgcoord = 999

                        if wgcoord &lt; -.5 or wgcoord &gt; 1.5:
                                # unreasonable to extrapolate to d46 = 0
                                R46_wg = np.mean([y/(1+x/1000) for x,y in zip(X,Y)])
                        else :
                                # d46 = 0 is reasonably well bracketed
                                R46_wg = np.polyfit(X, Y, 1)[1]

                        d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_delta(R45_wg, R46_wg)

                        self.msg(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                        self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                        for r in self.sessions[s][&#39;data&#39;]:
                                r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                                r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW


        def compute_bulk_delta(self, R45, R46, D17O = 0):
                &#39;&#39;&#39;
                Compute δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; and δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;,
                by solving the generalized form of equation (17) from [Brand et al. (2010)],
                assuming that δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; is not too big (0 ± 50 ‰) and
                solving the corresponding second-order Taylor polynomial.
                (Appendix A of [Daëron et al., 2016])

                [Brand et al. (2010)]: https://doi.org/10.1351/PAC-REP-09-01-05
                [Daëron et al., 2016]: https://doi.org/10.1016/j.chemgeo.2016.08.014
                &#39;&#39;&#39;

                K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

                A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
                B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
                C = 2 * self.R18_VSMOW
                D = -R46

                aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
                bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
                cc = A + B + C + D

                d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

                R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
                R17 = K * R18 ** self.lambda_17
                R13 = R45 - 2 * R17

                d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

                return d13C_VPDB, d18O_VSMOW


        @make_verbal
        def crunch(self, verbose = &#39;&#39;):
                &#39;&#39;&#39;
                Compute bulk composition and raw clumped isotope anomalies for all analyses.
                &#39;&#39;&#39;
                for r in self:
                        self.compute_bulk_and_clumping_deltas(r)
                self.standardize_d13C()
                self.standardize_d18O()
                self.msg(f&#34;Crunched {len(self)} analyses.&#34;)


        def fill_in_missing_info(self, session = &#39;mySession&#39;):
                &#39;&#39;&#39;
                Fill in optional fields with default values
                &#39;&#39;&#39;
                for i,r in enumerate(self):
                        if &#39;D17O&#39; not in r:
                                r[&#39;D17O&#39;] = 0.
                        if &#39;UID&#39; not in r:
                                r[&#39;UID&#39;] = f&#39;{i+1}&#39;
                        if &#39;Session&#39; not in r:
                                r[&#39;Session&#39;] = session
                        for k in [&#39;d47&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                                if k not in r:
                                        r[k] = np.nan


        def standardize_d13C(self):
                &#39;&#39;&#39;
                Perform δ&lt;sup&gt;13&lt;/sup&gt;C standadization within each session `s` according to
                `self.sessions[s][&#39;d13C_standardization_method&#39;]`, which is defined by default
                by `D47data.refresh_sessions()`as equal to `self.d13C_STANDARDIZATION_METHOD`, but
                may be redefined abitrarily at a later stage.
                &#39;&#39;&#39;
                for s in self.sessions:
                        if self.sessions[s][&#39;d13C_standardization_method&#39;] in [&#39;1pt&#39;, &#39;2pt&#39;]:
                                XY = [(r[&#39;d13C_VPDB&#39;], self.Nominal_d13C_VPDB[r[&#39;Sample&#39;]]) for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in self.Nominal_d13C_VPDB]
                                X,Y = zip(*XY)
                                if self.sessions[s][&#39;d13C_standardization_method&#39;] == &#39;1pt&#39;:
                                        offset = np.mean(Y) - np.mean(X)
                                        for r in self.sessions[s][&#39;data&#39;]:
                                                r[&#39;d13C_VPDB&#39;] += offset                                
                                elif self.sessions[s][&#39;d13C_standardization_method&#39;] == &#39;2pt&#39;:
                                        a,b = np.polyfit(X,Y,1)
                                        for r in self.sessions[s][&#39;data&#39;]:
                                                r[&#39;d13C_VPDB&#39;] = a * r[&#39;d13C_VPDB&#39;] + b

        def standardize_d18O(self):
                &#39;&#39;&#39;
                Perform δ&lt;sup&gt;18&lt;/sup&gt;O standadization within each session `s` according to
                `self.ALPHA_18O_ACID_REACTION` and `self.sessions[s][&#39;d18O_standardization_method&#39;]`,
                which is defined by default by `D47data.refresh_sessions()`as equal to
                `self.d18O_STANDARDIZATION_METHOD`, but may be redefined abitrarily at a later stage.
                &#39;&#39;&#39;
                for s in self.sessions:
                        if self.sessions[s][&#39;d18O_standardization_method&#39;] in [&#39;1pt&#39;, &#39;2pt&#39;]:
                                XY = [(r[&#39;d18O_VSMOW&#39;], self.Nominal_d18O_VPDB[r[&#39;Sample&#39;]]) for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in self.Nominal_d18O_VPDB]
                                X,Y = zip(*XY)
                                Y = [(1000+y) * self.R18_VPDB * self.ALPHA_18O_ACID_REACTION / self.R18_VSMOW - 1000 for y in Y]
                                if self.sessions[s][&#39;d18O_standardization_method&#39;] == &#39;1pt&#39;:
                                        offset = np.mean(Y) - np.mean(X)
                                        for r in self.sessions[s][&#39;data&#39;]:
                                                r[&#39;d18O_VSMOW&#39;] += offset                               
                                elif self.sessions[s][&#39;d18O_standardization_method&#39;] == &#39;2pt&#39;:
                                        a,b = np.polyfit(X,Y,1)
                                        for r in self.sessions[s][&#39;data&#39;]:
                                                r[&#39;d18O_VSMOW&#39;] = a * r[&#39;d18O_VSMOW&#39;] + b
        

        def compute_bulk_and_clumping_deltas(self, r):
                &#39;&#39;&#39;
                Compute δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt;, δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;, and
                raw Δ&lt;sub&gt;47&lt;/sub&gt;, Δ&lt;sub&gt;48&lt;/sub&gt;, Δ&lt;sub&gt;49&lt;/sub&gt; values for an analysis `r`.
                &#39;&#39;&#39;

                # Compute working gas R13, R18, and isobar ratios
                R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
                R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
                R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

                # Compute analyte isobar ratios
                R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
                R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
                R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
                R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
                R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

                r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_delta(R45, R46, D17O = r[&#39;D17O&#39;])
                R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
                R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

                # Compute stochastic isobar ratios of the analyte
                R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                        R13, R18, D17O = r[&#39;D17O&#39;]
                )

                # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
                # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
                if (R45 / R45stoch - 1) &gt; 5e-8:
                        self.vmsg(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):.3f} ppm&#39;)
                if (R46 / R46stoch - 1) &gt; 5e-8:
                        self.vmsg(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):.3f} ppm&#39;)

                # Compute raw clumped isotope anomalies
                r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
                r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
                r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)


        def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
                &#39;&#39;&#39;
                Compute isobar ratios for a sample with isotopic ratios `R13` and `R18`,
                optionally accounting for non-zero values of Δ&lt;sup&gt;17&lt;/sup&gt;O (`D17O`) and clumped isotope
                anomalies (`D47`, `D48`, `D49`), all expressed in permil.
                &#39;&#39;&#39;

                # Compute R17
                R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

                # Compute isotope concentrations
                C12 = (1 + R13) ** -1
                C13 = C12 * R13
                C16 = (1 + R17 + R18) ** -1
                C17 = C16 * R17
                C18 = C16 * R18

                # Compute stochastic isotopologue concentrations
                C626 = C16 * C12 * C16
                C627 = C16 * C12 * C17 * 2
                C628 = C16 * C12 * C18 * 2
                C636 = C16 * C13 * C16
                C637 = C16 * C13 * C17 * 2
                C638 = C16 * C13 * C18 * 2
                C727 = C17 * C12 * C17
                C728 = C17 * C12 * C18 * 2
                C737 = C17 * C13 * C17
                C738 = C17 * C13 * C18 * 2
                C828 = C18 * C12 * C18
                C838 = C18 * C13 * C18

                # Compute stochastic isobar ratios
                R45 = (C636 + C627) / C626
                R46 = (C628 + C637 + C727) / C626
                R47 = (C638 + C728 + C737) / C626
                R48 = (C738 + C828) / C626
                R49 = C838 / C626

                # Account for stochastic anomalies
                R47 *= 1 + D47 / 1000
                R48 *= 1 + D48 / 1000
                R49 *= 1 + D49 / 1000

                # Return isobar ratios
                return R45, R46, R47, R48, R49


        def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_session&#39;):
                &#39;&#39;&#39;
                Split unknown samples by UID (treat all analyses as different samples)
                or by session (treat analyses of a given sample in different sessions as
                different samples).

                __Parameters__

                + `samples_to_split`: a list of samples to split, e.g., `[&#39;IAEA-C1&#39;, &#39;IAEA-C2&#39;]`
                + `grouping`: `by_uid` | `by_session`
                &#39;&#39;&#39;
                if samples_to_split == &#39;all&#39;:
                        samples_to_split = [s for s in self.unknowns]
                gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
                self.grouping = grouping.lower()
                if self.grouping in gkeys:
                        gkey = gkeys[self.grouping]
                for r in self:
                        if r[&#39;Sample&#39;] in samples_to_split:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                        elif r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                self.refresh_samples()


        def unsplit_samples(self, tables = False):
                &#39;&#39;&#39;
                Reverse the effects of `D47data.split_samples()`.
                
                This should only be used after `D4xdata.standardize()` with `method=&#39;pooled&#39;`.
                
                After `D4xdata.standardize()` with `method=&#39;indep_sessions&#39;`, one should
                probably use `D4xdata.combine_samples()` instead to reverse the effects of
                `D47data.split_samples()` with `grouping=&#39;by_uid&#39;`, or `w_avg()` to reverse the
                effects of `D47data.split_samples()` with `grouping=&#39;by_sessions&#39;` (because in
                that case session-averaged Δ&lt;sub&gt;4x&lt;/sub&gt; values are statistically independent).
                &#39;&#39;&#39;
                unknowns_old = sorted({s for s in self.unknowns})
                CM_old = self.standardization.covar[:,:]
                VD_old = self.standardization.params.valuesdict().copy()
                vars_old = self.standardization.var_names

                unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})

                Ns = len(vars_old) - len(unknowns_old)
                vars_new = vars_old[:Ns] + [f&#39;D{self._4x}_{pf(u)}&#39; for u in unknowns_new]
                VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

                W = np.zeros((len(vars_new), len(vars_old)))
                W[:Ns,:Ns] = np.eye(Ns)
                for u in unknowns_new:
                        splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                        if self.grouping == &#39;by_session&#39;:
                                weights = [self.samples[s][f&#39;SE_D{self._4x}&#39;]**-2 for s in splits]
                        elif self.grouping == &#39;by_uid&#39;:
                                weights = [1 for s in splits]
                        sw = sum(weights)
                        weights = [w/sw for w in weights]
                        W[vars_new.index(f&#39;D{self._4x}_{pf(u)}&#39;),[vars_old.index(f&#39;D{self._4x}_{pf(s)}&#39;) for s in splits]] = weights[:]

                CM_new = W @ CM_old @ W.T
                V = W @ np.array([[VD_old[k]] for k in vars_old])
                VD_new = {k:v[0] for k,v in zip(vars_new, V)}

                self.standardization.covar = CM_new
                self.standardization.params.valuesdict = lambda : VD_new
                self.standardization.var_names = vars_new

                for r in self:
                        if r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]

                self.refresh_samples()
                self.consolidate_samples()
                self.repeatabilities()

                if tables:
                        self.table_of_analyses()
                        self.table_of_samples()

        def assign_timestamps(self):
                &#39;&#39;&#39;
                Assign a time field `t` of type `float` to each analysis.

                If `TimeTag` is one of the data fields, `t` is equal within a given session
                to `TimeTag` minus the mean value of `TimeTag` for that session.
                Otherwise, `TimeTag` is by default equal to the index of each analysis
                in the dataset and `t` is defined as above.
                &#39;&#39;&#39;
                for session in self.sessions:
                        sdata = self.sessions[session][&#39;data&#39;]
                        try:
                                t0 = np.mean([r[&#39;TimeTag&#39;] for r in sdata])
                                for r in sdata:
                                        r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
#                               print(&#39;DEBUG - USING TimeTag        &lt;-----------------------------------&#39;)
                        except KeyError:
                                t0 = (len(sdata)-1)/2
                                for t,r in enumerate(sdata):
                                        r[&#39;t&#39;] = t - t0


        def report(self):
                &#39;&#39;&#39;
                Prints a report on the standardization fit.
                Only applicable after `D4xdata.standardize(method=&#39;pooled&#39;)`.
                &#39;&#39;&#39;
                report_fit(self.standardization)


        def combine_samples(self, sample_groups):
                &#39;&#39;&#39;
                Combine analyses of different samples to compute weighted average Δ&lt;sub&gt;4x&lt;/sub&gt;
                and new error (co)variances corresponding to the groups defined by the `sample_groups`
                dictionary.
                
                Caution: samples are weighted by number of replicate analyses, which is a
                reasonable default behavior but is not always optimal (e.g., in the case of strongly
                correlated analytical errors for one or more samples).
                
                Returns a tuplet of:
                
                + the list of group names
                + an array of the corresponding Δ&lt;sub&gt;4x&lt;/sub&gt; values
                + the corresponding (co)variance matrix
                
                __Parameters__

                + `sample_groups`: a dictionary of the form:
                ```py
                {&#39;group1&#39;: [&#39;sample_1&#39;, &#39;sample_2&#39;],
                 &#39;group2&#39;: [&#39;sample_3&#39;, &#39;sample_4&#39;, &#39;sample_5&#39;]}
                ```
                &#39;&#39;&#39;
                
                samples = [s for k in sorted(sample_groups.keys()) for s in sorted(sample_groups[k])]
                groups = sorted(sample_groups.keys())
                group_total_weights = {k: sum([self.samples[s][&#39;N&#39;] for s in sample_groups[k]]) for k in groups}
                D4x_old = np.array([[self.samples[x][f&#39;D{self._4x}&#39;]] for x in samples])
                CM_old = np.array([[self.sample_D4x_covar(x,y) for x in samples] for y in samples])
                W = np.array([
                        [self.samples[i][&#39;N&#39;]/group_total_weights[j] if i in sample_groups[j] else 0 for i in samples]
                        for j in groups])
                D4x_new = W @ D4x_old
                CM_new = W @ CM_old @ W.T

                return groups, D4x_new[:,0], CM_new
                

        @make_verbal
        def standardize(self,
                method = &#39;pooled&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = False,
                consolidate_plots = False,
                constraints = {},
                ):
                &#39;&#39;&#39;
                Compute absolute Δ&lt;sub&gt;4x&lt;/sub&gt; values for all replicate analyses and for sample averages.
                If `method` argument is set to `&#39;pooled&#39;`, the standardization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous, i.e. that their true Δ&lt;sub&gt;4x&lt;/sub&gt; value does not change between sessions,
                ([Daëron, 2021]).
                If `method` argument is set to `&#39;indep_sessions&#39;`, the standardization processes each
                session independently, based only on anchors analyses.
                
                [Daëron, 2021]: https://doi.org/10.1029/2020GC009592
                &#39;&#39;&#39;

                self.standardization_method = method
                self.assign_timestamps()

                if method == &#39;pooled&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D4xdata([r for r in self if r[&#39;Session&#39;] in session_group], mass = self._4x)
                                        X.Nominal_D4x = self.Nominal_D4x.copy()
                                        X.refresh()
                                        result = X.standardize(method = &#39;pooled&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.msg(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[f&#39;wD{self._4x}raw&#39;] *= w
                        else:
                                self.msg(f&#39;All D{self._4x}raw weights set to 1 ‰&#39;)
                                for r in self:
                                        r[f&#39;wD{self._4x}raw&#39;] = 1.

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.msg(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.msg(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.msg(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D{self._4x}_{pf(sample)}&#39;, value = 0.5)

                        for k in constraints:
                                params[k].expr = constraints[k]

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D4x:
                                                R += [ (
                                                        r[f&#39;D{self._4x}raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D4x[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D4x[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[f&#39;wD{self._4x}raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[f&#39;D{self._4x}raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D{self._4x}_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D{self._4x}_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[f&#39;wD{self._4x}raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.least_squares()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[f&#39;D{self._4x}&#39;] = (r[f&#39;D{self._4x}raw&#39;] - c - b * r[f&#39;d{self._4x}&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[f&#39;d{self._4x}&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.standardization = result

                        for session in self.sessions:
                                self.sessions[session][&#39;Np&#39;] = 3
                                for k in [&#39;scrambling&#39;, &#39;slope&#39;, &#39;wg&#39;]:
                                        if self.sessions[session][f&#39;{k}_drift&#39;]:
                                                self.sessions[session][&#39;Np&#39;] += 1

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result


                elif method == &#39;indep_sessions&#39;:

                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D4xdata([r for r in self if r[&#39;Session&#39;] in session_group], mass = self._4x)
                                        X.Nominal_D4x = self.Nominal_D4x.copy()
                                        X.refresh()
                                        # This is only done to assign r[&#39;wD47raw&#39;] for r in X:
                                        X.standardize(method = method, weighted_sessions = [], consolidate = False)
                                        self.msg(f&#39;D{self._4x}raw weights set to {1000*X[0][f&#34;wD{self._4x}raw&#34;]:.1f} ppm for sessions in {session_group}&#39;)
                        else:
                                self.msg(&#39;All weights set to 1 ‰&#39;)
                                for r in self:
                                        r[f&#39;wD{self._4x}raw&#39;] = 1

                        for session in self.sessions:
                                s = self.sessions[session]
                                p_names = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;a2&#39;, &#39;b2&#39;, &#39;c2&#39;]
                                p_active = [True, True, True, s[&#39;scrambling_drift&#39;], s[&#39;slope_drift&#39;], s[&#39;wg_drift&#39;]]
                                s[&#39;Np&#39;] = sum(p_active)
                                sdata = s[&#39;data&#39;]

                                A = np.array([
                                        [
                                                self.Nominal_D4x[r[&#39;Sample&#39;]] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[f&#39;d{self._4x}&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                1 / r[f&#39;wD{self._4x}raw&#39;],
                                                self.Nominal_D4x[r[&#39;Sample&#39;]] * r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[f&#39;d{self._4x}&#39;] * r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;]
                                                ]
                                        for r in sdata if r[&#39;Sample&#39;] in self.anchors
                                        ])[:,p_active] # only keep columns for the active parameters
                                Y = np.array([[r[f&#39;D{self._4x}raw&#39;] / r[f&#39;wD{self._4x}raw&#39;]] for r in sdata if r[&#39;Sample&#39;] in self.anchors])
                                s[&#39;Na&#39;] = Y.size
                                CM = linalg.inv(A.T @ A)
                                bf = (CM @ A.T @ Y).T[0,:]
                                k = 0
                                for n,a in zip(p_names, p_active):
                                        if a:
                                                s[n] = bf[k]
#                                               self.msg(f&#39;{n} = {bf[k]}&#39;)
                                                k += 1
                                        else:
                                                s[n] = 0.
#                                               self.msg(f&#39;{n} = 0.0&#39;)

                                for r in sdata :
                                        a, b, c, a2, b2, c2 = s[&#39;a&#39;], s[&#39;b&#39;], s[&#39;c&#39;], s[&#39;a2&#39;], s[&#39;b2&#39;], s[&#39;c2&#39;]
                                        r[f&#39;D{self._4x}&#39;] = (r[f&#39;D{self._4x}raw&#39;] - c - b * r[f&#39;d{self._4x}&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[f&#39;d{self._4x}&#39;]) / (a + a2 * r[&#39;t&#39;])
                                        r[f&#39;wD{self._4x}&#39;] = r[f&#39;wD{self._4x}raw&#39;] / (a + a2 * r[&#39;t&#39;])

                                s[&#39;CM&#39;] = np.zeros((6,6))
                                i = 0
                                k_active = [j for j,a in enumerate(p_active) if a]
                                for j,a in enumerate(p_active):
                                        if a:
                                                s[&#39;CM&#39;][j,k_active] = CM[i,:]
                                                i += 1

                        if not weighted_sessions:
                                w = self.rmswd()[&#39;rmswd&#39;]
                                for r in self:
                                                r[f&#39;wD{self._4x}&#39;] *= w
                                                r[f&#39;wD{self._4x}raw&#39;] *= w
                                for session in self.sessions:
                                        self.sessions[session][&#39;CM&#39;] *= w**2

                        for session in self.sessions:
                                s = self.sessions[session]
                                s[&#39;SE_a&#39;] = s[&#39;CM&#39;][0,0]**.5
                                s[&#39;SE_b&#39;] = s[&#39;CM&#39;][1,1]**.5
                                s[&#39;SE_c&#39;] = s[&#39;CM&#39;][2,2]**.5
                                s[&#39;SE_a2&#39;] = s[&#39;CM&#39;][3,3]**.5
                                s[&#39;SE_b2&#39;] = s[&#39;CM&#39;][4,4]**.5
                                s[&#39;SE_c2&#39;] = s[&#39;CM&#39;][5,5]**.5

                        if not weighted_sessions:
                                self.Nf = len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        else:
                                self.Nf = 0
                                for sg in weighted_sessions:
                                        self.Nf += self.rmswd(sessions = sg)[&#39;Nf&#39;]

                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)

                        avgD4x = {
                                sample: np.mean([r[f&#39;D{self._4x}&#39;] for r in self if r[&#39;Sample&#39;] == sample])
                                for sample in self.samples
                                }
                        chi2 = np.sum([(r[f&#39;D{self._4x}&#39;] - avgD4x[r[&#39;Sample&#39;]])**2 for r in self])
                        rD4x = (chi2/self.Nf)**.5
                        self.repeatability[f&#39;sigma_{self._4x}&#39;] = rD4x

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)


        def standardization_error(self, session, d4x, D4x, t = 0):
                &#39;&#39;&#39;
                Compute standardization error for a given session and
                (δ&lt;sub&gt;47&lt;/sub&gt;, Δ&lt;sub&gt;47&lt;/sub&gt;) composition.
                &#39;&#39;&#39;
                a = self.sessions[session][&#39;a&#39;]
                b = self.sessions[session][&#39;b&#39;]
                c = self.sessions[session][&#39;c&#39;]
                a2 = self.sessions[session][&#39;a2&#39;]
                b2 = self.sessions[session][&#39;b2&#39;]
                c2 = self.sessions[session][&#39;c2&#39;]
                CM = self.sessions[session][&#39;CM&#39;]

                x, y = D4x, d4x
                z = a * x + b * y + c + a2 * x * t + b2 * y * t + c2 * t
#               x = (z - b*y - b2*y*t - c - c2*t) / (a+a2*t)
                dxdy = -(b+b2*t) / (a+a2*t)
                dxdz = 1. / (a+a2*t)
                dxda = -x / (a+a2*t)
                dxdb = -y / (a+a2*t)
                dxdc = -1. / (a+a2*t)
                dxda2 = -x * a2 / (a+a2*t)
                dxdb2 = -y * t / (a+a2*t)
                dxdc2 = -t / (a+a2*t)
                V = np.array([dxda, dxdb, dxdc, dxda2, dxdb2, dxdc2])
                sx = (V @ CM @ V.T) ** .5
                return sx


        @make_verbal
        def summary(self,
                dir = &#39;output&#39;,
                filename = None,
                save_to_file = True,
                print_out = True,
                ):
                &#39;&#39;&#39;
                Print out an/or save to disk a summary of the standardization results.

                __Parameters__

                + `dir`: the directory in which to save the table
                + `filename`: the name to the csv file to write to
                + `save_to_file`: whether to save the table to disk
                + `print_out`: whether to print out the table
                &#39;&#39;&#39;

                out = []
                out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
                out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
                out += [[&#39;Repeatability of δ13C_VPDB&#39;, f&#34;{1000 * self.repeatability[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
                out += [[&#39;Repeatability of δ18O_VSMOW&#39;, f&#34;{1000 * self.repeatability[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
                out += [[f&#39;Repeatability of Δ{self._4x} (anchors)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}a&#39;]:.1f} ppm&#34;]]
                out += [[f&#39;Repeatability of Δ{self._4x} (unknowns)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}u&#39;]:.1f} ppm&#34;]]
                out += [[f&#39;Repeatability of Δ{self._4x} (all)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}&#39;]:.1f} ppm&#34;]]
                out += [[&#39;Model degrees of freedom&#39;, f&#34;{self.Nf}&#34;]]
                out += [[&#39;Student\&#39;s 95% t-factor&#39;, f&#34;{self.t95:.2f}&#34;]]
                out += [[&#39;Standardization method&#39;, self.standardization_method]]

                if save_to_file:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename is None:
                                filename = f&#39;D{self._4x}_summary.csv&#39;
                        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                fid.write(make_csv(out))
                if print_out:
                        self.msg(&#39;\n&#39; + pretty_table(out, header = 0))


        @make_verbal
        def table_of_sessions(self,
                dir = &#39;output&#39;,
                filename = None,
                save_to_file = True,
                print_out = True,
                output = None,
                ):
                &#39;&#39;&#39;
                Print out an/or save to disk a table of sessions.

                __Parameters__

                + `dir`: the directory in which to save the table
                + `filename`: the name to the csv file to write to
                + `save_to_file`: whether to save the table to disk
                + `print_out`: whether to print out the table
                + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                    if set to `&#39;raw&#39;`: return a list of list of strings
                    (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
                &#39;&#39;&#39;
                include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
                include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
                include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])

                out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,f&#39;r_D{self._4x}&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
                if include_a2:
                        out[-1] += [&#39;a2 ± SE&#39;]
                if include_b2:
                        out[-1] += [&#39;b2 ± SE&#39;]
                if include_c2:
                        out[-1] += [&#39;c2 ± SE&#39;]
                for session in self.sessions:
                        out += [[
                                session,
                                f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][f&#39;r_D{self._4x}&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                                f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                                ]]
                        if include_a2:
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_b2:
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_c2:
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]

                if save_to_file:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename is None:
                                filename = f&#39;D{self._4x}_sessions.csv&#39;
                        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                fid.write(make_csv(out))
                if print_out:
                        self.msg(&#39;\n&#39; + pretty_table(out))
                if output == &#39;raw&#39;:
                        return out
                elif output == &#39;pretty&#39;:
                        return pretty_table(out)


        @make_verbal
        def table_of_analyses(
                self,
                dir = &#39;output&#39;,
                filename = None,
                save_to_file = True,
                print_out = True,
                output = None,
                ):
                &#39;&#39;&#39;
                Print out an/or save to disk a table of analyses.

                __Parameters__

                + `dir`: the directory in which to save the table
                + `filename`: the name to the csv file to write to
                + `save_to_file`: whether to save the table to disk
                + `print_out`: whether to print out the table
                + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                    if set to `&#39;raw&#39;`: return a list of list of strings
                    (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
                &#39;&#39;&#39;

                out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
                extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
                for f in extra_fields:
                        out[-1] += [f[0]]
                out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,f&#39;D{self._4x}&#39;]
                for r in self:
                        out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                        for f in extra_fields:
                                out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                        out[-1] += [
                                f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d13C_VPDB&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d18O_VSMOW&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                                f&#34;{r[f&#39;D{self._4x}&#39;]:.6f}&#34;
                                ]
                if save_to_file:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename is None:
                                filename = f&#39;D{self._4x}_analyses.csv&#39;
                        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                fid.write(make_csv(out))
                if print_out:
                        self.msg(&#39;\n&#39; + pretty_table(out))
                return out


        @make_verbal
        def table_of_samples(
                self,
                dir = &#39;output&#39;,
                filename = None,
                save_to_file = True,
                print_out = True,
                output = None,
                ):
                &#39;&#39;&#39;
                Print out, save to disk and/or return a table of samples.

                __Parameters__

                + `dir`: the directory in which to save the table
                + `filename`: the name to the csv file to write to
                + `save_to_file`: whether to save the table to disk
                + `print_out`: whether to print out the table
                + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
                    if set to `&#39;raw&#39;`: return a list of list of strings
                    (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
                &#39;&#39;&#39;

                out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,f&#39;D{self._4x}&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
                for sample in self.anchors:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][f&#39;D{self._4x}&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                                f&#34;{self.samples[sample][f&#39;SD_D{self._4x}&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                                ]]
                for sample in self.unknowns:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][f&#39;D{self._4x}&#39;]:.4f}&#34;,
                                f&#34;{self.samples[sample][f&#39;SE_D{self._4x}&#39;]:.4f}&#34;,
                                f&#34;± {self.samples[sample][f&#39;SE_D{self._4x}&#39;] * self.t95:.4f}&#34;,
                                f&#34;{self.samples[sample][f&#39;SD_D{self._4x}&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                                f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 2 else &#39;&#39;
                                ]]
                if save_to_file:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename is None:
                                filename = f&#39;D{self._4x}_samples.csv&#39;
                        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                                fid.write(make_csv(out))
                if print_out:
                        self.msg(&#39;\n&#39;+pretty_table(out))
                if output == &#39;raw&#39;:
                        return out
                elif output == &#39;pretty&#39;:
                        return pretty_table(out)


        def plot_sessions(self, dir = &#39;output&#39;, figsize = (8,8)):
                &#39;&#39;&#39;
                Generate session plots and save them to disk.

                __Parameters__

                + `dir`: the directory in which to save the plots
                + `figsize`: the width and height (in inches) of each plot
                &#39;&#39;&#39;
                if not os.path.exists(dir):
                        os.makedirs(dir)

                for session in self.sessions:
                        sp = self.plot_single_session(session, xylimits = &#39;constant&#39;)
                        ppl.savefig(f&#39;{dir}/D{self._4x}_plot_{session}.pdf&#39;)
                        ppl.close(sp.fig)


        @make_verbal
        def consolidate_samples(self):
                &#39;&#39;&#39;
                Compile various statistics for each sample.

                For each anchor sample:

                + `D47` or `D48`: the nominal Δ&lt;sub&gt;4x&lt;/sub&gt; value for this anchor, specified by `self.Nominal_D4x`
                + `SE_D47` or `SE_D48`: set to zero by definition

                For each unknown sample:

                + `D47` or `D48`: the standardized Δ&lt;sub&gt;4x&lt;/sub&gt; value for this unknown
                + `SE_D47` or `SE_D48`: the standard error of Δ&lt;sub&gt;4x&lt;/sub&gt; for this unknown

                For each anchor and unknown:

                + `N`: the total number of analyses of this sample
                + `SD_D47` or `SD_D48`: the “sample” (in the statistical sense) standard deviation for this sample
                + `d13C_VPDB`: the average δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; value for this sample
                + `d18O_VSMOW`: the average δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; value for this sample (as CO&lt;sub&gt;2&lt;/sub&gt;)
                + `p_Levene`: the p-value from a [Levene test] of equal variance, indicating whether
                the Δ&lt;sub&gt;4x&lt;/sub&gt; repeatability this sample differs significantly from that observed
                for the reference sample specified by `self.LEVENE_REF_SAMPLE`.

                [Levene test]: https://en.wikipedia.org/wiki/Levene%27s_test
                &#39;&#39;&#39;
                D4x_ref_pop = [r[f&#39;D{self._4x}&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]
                for sample in self.samples:
                        self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                        if self.samples[sample][&#39;N&#39;] &gt; 1:
                                self.samples[sample][f&#39;SD_D{self._4x}&#39;] = stdev([r[f&#39;D{self._4x}&#39;] for r in self.samples[sample][&#39;data&#39;]])

                        self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                        self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

                        D4x_pop = [r[f&#39;D{self._4x}&#39;] for r in self.samples[sample][&#39;data&#39;]]
                        if len(D4x_pop) &gt; 2:
                                self.samples[sample][&#39;p_Levene&#39;] = levene(D4x_ref_pop, D4x_pop, center = &#39;median&#39;)[1]

                if self.standardization_method == &#39;pooled&#39;:
                        for sample in self.anchors:
                                self.samples[sample][f&#39;D{self._4x}&#39;] = self.Nominal_D4x[sample]
                                self.samples[sample][f&#39;SE_D{self._4x}&#39;] = 0.
                        for sample in self.unknowns:
                                self.samples[sample][f&#39;D{self._4x}&#39;] = self.standardization.params.valuesdict()[f&#39;D{self._4x}_{pf(sample)}&#39;]
                                try:
                                        self.samples[sample][f&#39;SE_D{self._4x}&#39;] = self.sample_D4x_covar(sample)**.5
                                except ValueError:
                                        # when `sample` is constrained by self.standardize(constraints = {...}),
                                        # it is no longer listed in self.standardization.var_names.
                                        # Temporary fix: define SE as zero for now
                                        self.samples[sample][f&#39;SE_D4{self._4x}&#39;] = 0.

                elif self.standardization_method == &#39;indep_sessions&#39;:
                        for sample in self.anchors:
                                self.samples[sample][f&#39;D{self._4x}&#39;] = self.Nominal_D4x[sample]
                                self.samples[sample][f&#39;SE_D{self._4x}&#39;] = 0.
                        for sample in self.unknowns:
                                self.msg(f&#39;Consolidating sample {sample}&#39;)
                                self.unknowns[sample][f&#39;session_D{self._4x}&#39;] = {}
                                session_avg = []
                                for session in self.sessions:
                                        sdata = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                                        if sdata:
                                                self.msg(f&#39;{sample} found in session {session}&#39;)
                                                avg_D4x = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata])
                                                avg_d4x = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata])
                                                # !! TODO: sigma_s below does not account for temporal changes in standardization error
                                                sigma_s = self.standardization_error(session, avg_d4x, avg_D4x)
                                                sigma_u = sdata[0][f&#39;wD{self._4x}raw&#39;] / self.sessions[session][&#39;a&#39;] / len(sdata)**.5
                                                session_avg.append([avg_D4x, (sigma_u**2 + sigma_s**2)**.5])
                                                self.unknowns[sample][f&#39;session_D{self._4x}&#39;][session] = session_avg[-1]
                                self.samples[sample][f&#39;D{self._4x}&#39;], self.samples[sample][f&#39;SE_D{self._4x}&#39;] = w_avg(*zip(*session_avg))
                                weights = {s: self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s][1]**-2 for s in self.unknowns[sample][f&#39;session_D{self._4x}&#39;]}
                                wsum = sum([weights[s] for s in weights])
                                for s in weights:
                                        self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s] += [self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s][1]**-2 / wsum]


        def consolidate_sessions(self):
                &#39;&#39;&#39;
                Compute various statistics for each session.

                + `Na`: Number of anchor analyses in the session
                + `Nu`: Number of unknown analyses in the session
                + `r_d13C_VPDB`: δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; repeatability of analyses within the session
                + `r_d18O_VSMOW`: δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; repeatability of analyses within the session
                + `r_D47` or `r_D48`: Δ&lt;sub&gt;4x&lt;/sub&gt; repeatability of analyses within the session
                + `a`: scrambling factor
                + `b`: compositional slope
                + `c`: WG offset
                + `SE_a`: Model stadard erorr of `a`
                + `SE_b`: Model stadard erorr of `b`
                + `SE_c`: Model stadard erorr of `c`
                + `scrambling_drift` (boolean): whether to allow a temporal drift in the scrambling factor (`a`)
                + `slope_drift` (boolean): whether to allow a temporal drift in the compositional slope (`b`)
                + `wg_drift` (boolean): whether to allow a temporal drift in the WG offset (`c`)
                + `a2`: scrambling factor drift
                + `b2`: compositional slope drift
                + `c2`: WG offset drift
                + `Np`: Number of standardization parameters to fit
                + `CM`: model covariance matrix for (`a`, `b`, `c`, `a2`, `b2`, `c2`)
                + `d13Cwg_VPDB`: δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; of WG
                + `d18Owg_VSMOW`: δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; of WG
                &#39;&#39;&#39;
                for session in self.sessions:
                        if &#39;d13Cwg_VPDB&#39; not in self.sessions[session]:
                                self.sessions[session][&#39;d13Cwg_VPDB&#39;] = self.sessions[session][&#39;data&#39;][0][&#39;d13Cwg_VPDB&#39;]
                        if &#39;d18Owg_VSMOW&#39; not in self.sessions[session]:
                                self.sessions[session][&#39;d18Owg_VSMOW&#39;] = self.sessions[session][&#39;data&#39;][0][&#39;d18Owg_VSMOW&#39;]
                        self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                        self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])

                        self.msg(f&#39;Computing repeatabilities for session {session}&#39;)
                        self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_r(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_r(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][f&#39;r_D{self._4x}&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, sessions = [session])

                if self.standardization_method == &#39;pooled&#39;:
                        for session in self.sessions:

                                self.sessions[session][&#39;a&#39;] = self.standardization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                                i = self.standardization.var_names.index(f&#39;a_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_a&#39;] = self.standardization.covar[i,i]**.5

                                self.sessions[session][&#39;b&#39;] = self.standardization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                                i = self.standardization.var_names.index(f&#39;b_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_b&#39;] = self.standardization.covar[i,i]**.5

                                self.sessions[session][&#39;c&#39;] = self.standardization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                                i = self.standardization.var_names.index(f&#39;c_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_c&#39;] = self.standardization.covar[i,i]**.5

                                self.sessions[session][&#39;a2&#39;] = self.standardization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        i = self.standardization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_a2&#39;] = self.standardization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_a2&#39;] = 0.

                                self.sessions[session][&#39;b2&#39;] = self.standardization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        i = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_b2&#39;] = self.standardization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_b2&#39;] = 0.

                                self.sessions[session][&#39;c2&#39;] = self.standardization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        i = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_c2&#39;] = self.standardization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_c2&#39;] = 0.

                                i = self.standardization.var_names.index(f&#39;a_{pf(session)}&#39;)
                                j = self.standardization.var_names.index(f&#39;b_{pf(session)}&#39;)
                                k = self.standardization.var_names.index(f&#39;c_{pf(session)}&#39;)
                                CM = np.zeros((6,6))
                                CM[:3,:3] = self.standardization.covar[[i,j,k],:][:,[i,j,k]]
                                try:
                                        i2 = self.standardization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                        CM[3,[0,1,2,3]] = self.standardization.covar[i2,[i,j,k,i2]]
                                        CM[[0,1,2,3],3] = self.standardization.covar[[i,j,k,i2],i2]
                                        try:
                                                j2 = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                                CM[3,4] = self.standardization.covar[i2,j2]
                                                CM[4,3] = self.standardization.covar[j2,i2]
                                        except ValueError:
                                                pass
                                        try:
                                                k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                                CM[3,5] = self.standardization.covar[i2,k2]
                                                CM[5,3] = self.standardization.covar[k2,i2]
                                        except ValueError:
                                                pass
                                except ValueError:
                                        pass
                                try:
                                        j2 = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                        CM[4,[0,1,2,4]] = self.standardization.covar[j2,[i,j,k,j2]]
                                        CM[[0,1,2,4],4] = self.standardization.covar[[i,j,k,j2],j2]
                                        try:
                                                k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                                CM[4,5] = self.standardization.covar[j2,k2]
                                                CM[5,4] = self.standardization.covar[k2,j2]
                                        except ValueError:
                                                pass
                                except ValueError:
                                        pass
                                try:
                                        k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                        CM[5,[0,1,2,5]] = self.standardization.covar[k2,[i,j,k,k2]]
                                        CM[[0,1,2,5],5] = self.standardization.covar[[i,j,k,k2],k2]
                                except ValueError:
                                        pass

                                self.sessions[session][&#39;CM&#39;] = CM

                elif self.standardization_method == &#39;indep_sessions&#39;:
                        pass # Not implemented yet


        @make_verbal
        def repeatabilities(self):
                &#39;&#39;&#39;
                Compute analytical repeatabilities for δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt;,
                δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;, Δ&lt;sub&gt;4x&lt;/sub&gt; (for all samples, for anchors,
                and for unknowns).
                &#39;&#39;&#39;
                self.msg(&#39;Computing reproducibilities for all sessions&#39;)

                self.repeatability[&#39;r_d13C_VPDB&#39;] = self.compute_r(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
                self.repeatability[&#39;r_d18O_VSMOW&#39;] = self.compute_r(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)
                self.repeatability[f&#39;r_D{self._4x}a&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;anchors&#39;)
                self.repeatability[f&#39;r_D{self._4x}u&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;unknowns&#39;)
                self.repeatability[f&#39;r_D{self._4x}&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;all samples&#39;)


        @make_verbal
        def consolidate(self, tables = True, plots = True):
                &#39;&#39;&#39;
                Collect information about samples, sessions and repeatabilities.
                &#39;&#39;&#39;
                self.consolidate_samples()
                self.consolidate_sessions()
                self.repeatabilities()

                if tables:
                        self.summary()
                        self.table_of_sessions()
                        self.table_of_analyses()
                        self.table_of_samples()

                if plots:
                        self.plot_sessions()


        @make_verbal
        def rmswd(self,
                samples = &#39;all samples&#39;,
                sessions = &#39;all sessions&#39;,
                ):
                &#39;&#39;&#39;
                Compute the χ&lt;sup&gt;2&lt;/sup&gt;, root mean squared weighted deviation
                (i.e. reduced χ&lt;sup&gt;2&lt;/sup&gt;), and corresponding degrees of freedom of the
                Δ&lt;sub&gt;4x&lt;/sub&gt; values for samples in `samples` and sessions in `sessions`.
                
                Only used in `D4xdata.standardize()` with `method=&#39;indep_sessions&#39;`.
                &#39;&#39;&#39;
                if samples == &#39;all samples&#39;:
                        mysamples = [k for k in self.samples]
                elif samples == &#39;anchors&#39;:
                        mysamples = [k for k in self.anchors]
                elif samples == &#39;unknowns&#39;:
                        mysamples = [k for k in self.unknowns]
                else:
                        mysamples = samples

                if sessions == &#39;all sessions&#39;:
                        sessions = [k for k in self.sessions]

                chisq, Nf = 0, 0
                for sample in mysamples :
                        G = [ r for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                        if len(G) &gt; 1 :
                                X, sX = w_avg([r[f&#39;D{self._4x}&#39;] for r in G], [r[f&#39;wD{self._4x}&#39;] for r in G])
                                Nf += (len(G) - 1)
                                chisq += np.sum([ ((r[f&#39;D{self._4x}&#39;]-X)/r[f&#39;wD{self._4x}&#39;])**2 for r in G])
                r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
                self.msg(f&#39;RMSWD of r[&#34;D{self._4x}&#34;] is {r:.6f} for {samples}.&#39;)
                return {&#39;rmswd&#39;: r, &#39;chisq&#39;: chisq, &#39;Nf&#39;: Nf}

        
        @make_verbal
        def compute_r(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
                &#39;&#39;&#39;
                Compute the repeatability of `[r[key] for r in self]`
                &#39;&#39;&#39;
                # NB: it&#39;s debatable whether rD47 should be computed
                # with Nf = len(self)-len(self.samples) instead of
                # Nf = len(self) - len(self.unknwons) - 3*len(self.sessions)

                if samples == &#39;all samples&#39;:
                        mysamples = [k for k in self.samples]
                elif samples == &#39;anchors&#39;:
                        mysamples = [k for k in self.anchors]
                elif samples == &#39;unknowns&#39;:
                        mysamples = [k for k in self.unknowns]
                else:
                        mysamples = samples

                if sessions == &#39;all sessions&#39;:
                        sessions = [k for k in self.sessions]

                if key in [&#39;D47&#39;, &#39;D48&#39;]:
                        chisq, Nf = 0, 0
                        for sample in mysamples :
                                X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                                if len(X) &gt; 1 :
                                        chisq += np.sum([ (x-self.samples[sample][key])**2 for x in X ])
                                        if sample in self.unknowns:
                                                Nf += len(X) - 1
                                        else:
                                                Nf += len(X)
                        if samples in [&#39;anchors&#39;, &#39;all samples&#39;]:
                                Nf -= sum([self.sessions[s][&#39;Np&#39;] for s in sessions])
                        r = (chisq / Nf)**.5 if Nf &gt; 0 else 0

                else: # if key not in [&#39;D47&#39;, &#39;D48&#39;]
                        chisq, Nf = 0, 0
                        for sample in mysamples :
                                X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                                if len(X) &gt; 1 :
                                        Nf += len(X) - 1
                                        chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
                        r = (chisq / Nf)**.5 if Nf &gt; 0 else 0

                self.msg(f&#39;Repeatability of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
                return r

        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Weighted average Δ&lt;sub&gt;4x&lt;/sub&gt; value of a group of samples, accounting for covariance.

                Returns the weighed average Δ&lt;sub&gt;4x&lt;/sub&gt; value and associated SE
                of a group of samples. Weights are equal by default. If `normalize` is
                true, `weights` will be rescaled so that their sum equals 1.

                __Examples__

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])
                ```

                returns the value and SE of [Δ&lt;sub&gt;4x&lt;/sub&gt;(X) + 2 Δ&lt;sub&gt;4x&lt;/sub&gt;(Y)]/3,
                where Δ&lt;sub&gt;4x&lt;/sub&gt;(X) and Δ&lt;sub&gt;4x&lt;/sub&gt;(Y) are the average Δ&lt;sub&gt;4x&lt;/sub&gt;
                values of samples X and Y, respectively.

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                ```

                returns the value and SE of the difference Δ&lt;sub&gt;4x&lt;/sub&gt;(X) - Δ&lt;sub&gt;4x&lt;/sub&gt;(Y).
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        if s:
                                weights = [w/s for w in weights]

                try:
#                       indices = [self.standardization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.standardization.covar[indices,:][:,indices]
                        C = np.array([[self.sample_D4x_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][f&#39;D{self._4x}&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)


        def sample_D4x_covar(self, sample1, sample2 = None):
                &#39;&#39;&#39;
                Covariance between Δ&lt;sub&gt;4x&lt;/sub&gt; values of samples

                Returns the error covariance between the average Δ&lt;sub&gt;4x&lt;/sub&gt; values of two
                samples. If if only `sample_1` is specified, or if `sample_1 == sample_2`),
                returns the Δ&lt;sub&gt;4x&lt;/sub&gt; variance for that sample.
                &#39;&#39;&#39;
                if sample2 is None:
                        sample2 = sample1
                if self.standardization_method == &#39;pooled&#39;:
                        i = self.standardization.var_names.index(f&#39;D{self._4x}_{pf(sample1)}&#39;)
                        j = self.standardization.var_names.index(f&#39;D{self._4x}_{pf(sample2)}&#39;)
                        return self.standardization.covar[i, j]
                elif self.standardization_method == &#39;indep_sessions&#39;:
                        if sample1 == sample2:
                                return self.samples[sample1][f&#39;SE_D{self._4x}&#39;]**2
                        else:
                                c = 0
                                for session in self.sessions:
                                        sdata1 = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample1]
                                        sdata2 = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample2]
                                        if sdata1 and sdata2:
                                                a = self.sessions[session][&#39;a&#39;]
                                                # !! TODO: CM below does not account for temporal changes in standardization parameters
                                                CM = self.sessions[session][&#39;CM&#39;][:3,:3]
                                                avg_D4x_1 = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata1])
                                                avg_d4x_1 = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata1])
                                                avg_D4x_2 = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata2])
                                                avg_d4x_2 = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata2])
                                                c += (
                                                        self.unknowns[sample1][f&#39;session_D{self._4x}&#39;][session][2]
                                                        * self.unknowns[sample2][f&#39;session_D{self._4x}&#39;][session][2]
                                                        * np.array([[avg_D4x_1, avg_d4x_1, 1]])
                                                        @ CM
                                                        @ np.array([[avg_D4x_2, avg_d4x_2, 1]]).T
                                                        ) / a**2
                                return float(c)

        def sample_D4x_correl(self, sample1, sample2 = None):
                &#39;&#39;&#39;
                Correlation between Δ&lt;sub&gt;4x&lt;/sub&gt; errors of samples

                Returns the error correlation between the average Δ4x values of two samples.
                &#39;&#39;&#39;
                if sample2 is None or sample2 == sample1:
                        return 1.
                return (
                        self.sample_D4x_covar(sample1, sample2)
                        / self.unknowns[sample1][f&#39;SE_D{self._4x}&#39;]
                        / self.unknowns[sample2][f&#39;SE_D{self._4x}&#39;]
                        )

        def plot_single_session(self,
                session,
                kw_plot_anchors = dict(ls=&#39;None&#39;, marker=&#39;x&#39;, mec=(.75, 0, 0), mew = .75, ms = 4),
                kw_plot_unknowns = dict(ls=&#39;None&#39;, marker=&#39;x&#39;, mec=(0, 0, .75), mew = .75, ms = 4),
                kw_plot_anchor_avg = dict(ls=&#39;-&#39;, marker=&#39;None&#39;, color=(.75, 0, 0), lw = .75),
                kw_plot_unknown_avg = dict(ls=&#39;-&#39;, marker=&#39;None&#39;, color=(0, 0, .75), lw = .75),
                kw_contour_error = dict(colors = [[0, 0, 0]], alpha = .5, linewidths = 0.75),
                xylimits = &#39;free&#39;, # | &#39;constant&#39;
                x_label = None,
                y_label = None,
                error_contour_interval = &#39;auto&#39;,
                fig = &#39;new&#39;,
                ):
                &#39;&#39;&#39;
                Generate plot for a single session
                &#39;&#39;&#39;
                if x_label is None:
                        x_label = f&#39;δ$_{{{self._4x}}}$ (‰)&#39;
                if y_label is None:
                        y_label = f&#39;Δ$_{{{self._4x}}}$ (‰)&#39;

                out = _SessionPlot()
                anchors = [a for a in self.anchors if [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == a]]
                unknowns = [u for u in self.unknowns if [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == u]]
                
                if fig == &#39;new&#39;:
                        out.fig = ppl.figure(figsize = (6,6))
                        ppl.subplots_adjust(.1,.1,.9,.9)

                out.anchor_analyses, = ppl.plot(
                        [r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors],
                        [r[f&#39;D{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors],
                        **kw_plot_anchors)
                out.unknown_analyses, = ppl.plot(
                        [r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns],
                        [r[f&#39;D{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns],
                        **kw_plot_unknowns)
                out.anchor_avg = ppl.plot(
                        np.array([ np.array([
                                np.min([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) - 1,
                                np.max([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) + 1
                                ]) for sample in anchors]).T,
                        np.array([ np.array([0, 0]) + self.Nominal_D4x[sample] for sample in anchors]).T,
                        **kw_plot_anchor_avg)
                out.unknown_avg = ppl.plot(
                        np.array([ np.array([
                                np.min([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) - 1,
                                np.max([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) + 1
                                ]) for sample in unknowns]).T,
                        np.array([ np.array([0, 0]) + self.unknowns[sample][f&#39;D{self._4x}&#39;] for sample in unknowns]).T,
                        **kw_plot_unknown_avg)
                if xylimits == &#39;constant&#39;:
                        x = [r[f&#39;d{self._4x}&#39;] for r in self]
                        y = [r[f&#39;D{self._4x}&#39;] for r in self]
                        x1, x2, y1, y2 = np.min(x), np.max(x), np.min(y), np.max(y)
                        w, h = x2-x1, y2-y1
                        x1 -= w/20
                        x2 += w/20
                        y1 -= h/20
                        y2 += h/20
                        ppl.axis([x1, x2, y1, y2])
                elif xylimits == &#39;free&#39;:
                        x1, x2, y1, y2 = ppl.axis()
                else:
                        x1, x2, y1, y2 = ppl.axis(xylimits)
                                
                if error_contour_interval != &#39;none&#39;:
                        xi, yi = np.linspace(x1, x2), np.linspace(y1, y2)
                        XI,YI = np.meshgrid(xi, yi)
                        SI = np.array([[self.standardization_error(session, x, y) for x in xi] for y in yi])
                        if error_contour_interval == &#39;auto&#39;:
                                rng = np.max(SI) - np.min(SI)
                                if rng &lt;= 0.01:
                                        cinterval = 0.001
                                elif rng &lt;= 0.03:
                                        cinterval = 0.004
                                elif rng &lt;= 0.1:
                                        cinterval = 0.01
                                elif rng &lt;= 0.3:
                                        cinterval = 0.03
                                elif rng &lt;= 1.:
                                        cinterval = 0.1
                                else:
                                        cinterval = 0.5
                        else:
                                cinterval = error_contour_interval

                        cval = np.arange(np.ceil(SI.min() / .001) * .001, np.ceil(SI.max() / .001 + 1) * .001, cinterval)
                        out.contour = ppl.contour(XI, YI, SI, cval, **kw_contour_error)
                        out.clabel = ppl.clabel(out.contour)

                ppl.xlabel(x_label)
                ppl.ylabel(y_label)
                ppl.title(session, weight = &#39;bold&#39;)
                ppl.grid(alpha = .2)
                out.ax = ppl.gca()              

                return out

        def plot_residuals(self, dir = &#39;output&#39;, filename = None, highlight = [], colors = None):
                &#39;&#39;&#39;
                Plot residuals of each analysis as a function of time (actually, as a function of
                the order of analyses in the D4xdata() object)

                + `dir`: the directory in which to save the plot
                + `highlight`: a list of samples to highlight
                + `colors`: a dict of {&lt;sample&gt;: &lt;color&gt;} for all samples
                &#39;&#39;&#39;
                fig = ppl.figure(figsize = (8,4))
                ppl.subplots_adjust(.1,.05,.78,.8)
                N = len(self.anchors)
                if colors is None:
                        if len(highlight) &gt; 0:
                                Nh = len(highlight)
                                if Nh == 1:
                                        colors = {highlight[0]: (0,0,0)}
                                elif Nh == 3:
                                        colors = {a: c for a,c in zip(highlight, [(0,0,1), (1,0,0), (0,2/3,0)])}
                                elif Nh == 4:
                                        colors = {a: c for a,c in zip(highlight, [(0,0,1), (1,0,0), (0,2/3,0), (.75,0,.75)])}
                                else:
                                        colors = {a: hls_to_rgb(k/Nh, .4, 1) for k,a in enumerate(highlight)}
                        else:
                                if N == 3:
                                        colors = {a: c for a,c in zip(self.anchors, [(0,0,1), (1,0,0), (0,2/3,0)])}
                                elif N == 4:
                                        colors = {a: c for a,c in zip(self.anchors, [(0,0,1), (1,0,0), (0,2/3,0), (.75,0,.75)])}
                                else:
                                        colors = {a: hls_to_rgb(k/N, .4, 1) for k,a in enumerate(self.anchors)}
                session = self[0][&#39;Session&#39;]
                x1 = 0
#               ymax = np.max([1e3 * (r[&#39;D47&#39;] - self.samples[r[&#39;Sample&#39;]][&#39;D47&#39;]) for r in self])
                x_sessions = {}
                one_or_more_singlets = False
                one_or_more_multiplets = False
                for k,r in enumerate(self):
                        if r[&#39;Session&#39;] != session:
                                x2 = k-1
                                x_sessions[session] = (x1+x2)/2
                                ppl.axvline(k - 0.5, color = &#39;k&#39;, lw = .5)
                                session = r[&#39;Session&#39;]
                                x1 = k
                        singlet = len(self.samples[r[&#39;Sample&#39;]][&#39;data&#39;]) == 1
                        if r[&#39;Sample&#39;] in self.unknowns:
                                if singlet:
                                        one_or_more_singlets = True
                                else:
                                        one_or_more_multiplets = True
                        kw = dict(
                                marker = &#39;x&#39; if singlet else &#39;+&#39;,
                                ms = 4 if singlet else 5,
                                ls = &#39;None&#39;,
                                mec = colors[r[&#39;Sample&#39;]] if r[&#39;Sample&#39;] in colors else (0,0,0),
                                mew = 1,
                                alpha = 0.2 if singlet else 1,
                                )
                        if highlight and r[&#39;Sample&#39;] not in highlight:
                                kw[&#39;alpha&#39;] = 0.2
                        ppl.plot(k, 1e3 * (r[&#39;D47&#39;] - self.samples[r[&#39;Sample&#39;]][&#39;D47&#39;]), **kw)
                x2 = k
                x_sessions[session] = (x1+x2)/2

                ppl.axhspan(-self.repeatability[&#39;r_D47&#39;]*1000, self.repeatability[&#39;r_D47&#39;]*1000, color = &#39;k&#39;, alpha = .05, lw = 1)
                ppl.text(len(self), self.repeatability[&#39;r_D47&#39;]*1000, f&#34;   SD = {self.repeatability[&#39;r_D47&#39;]*1000:.1f} ppm&#34;, size = 9, alpha = .75, va = &#39;center&#39;)
                ppl.axhspan(-self.repeatability[&#39;r_D47&#39;]*1000*self.t95, self.repeatability[&#39;r_D47&#39;]*1000*self.t95, color = &#39;k&#39;, alpha = .05, lw = 1)
                ppl.text(len(self), self.repeatability[&#39;r_D47&#39;]*1000*self.t95, f&#34;   95% CL: ± {self.repeatability[&#39;r_D47&#39;]*1000*self.t95:.1f} ppm&#34;, size = 9, alpha = .75, va = &#39;center&#39;)

                ymax = ppl.axis()[3]
                for s in x_sessions:
                        ppl.text(
                                x_sessions[s],
                                ymax +1,
                                s,
                                va = &#39;bottom&#39;,
                                **(
                                        dict(ha = &#39;center&#39;)
                                        if len(self.sessions[s][&#39;data&#39;]) &gt; (0.15 * len(self))
                                        else dict(ha = &#39;left&#39;, rotation = 45)
                                        )
                                )

                for s in colors:
                        kw[&#39;marker&#39;] = &#39;+&#39;
                        kw[&#39;ms&#39;] = 5
                        kw[&#39;mec&#39;] = colors[s]
                        kw[&#39;label&#39;] = s
                        kw[&#39;alpha&#39;] = 1
                        ppl.plot([], [], **kw)

                kw[&#39;mec&#39;] = (0,0,0)

                if one_or_more_singlets:
                        kw[&#39;marker&#39;] = &#39;x&#39;
                        kw[&#39;ms&#39;] = 4
                        kw[&#39;alpha&#39;] = .2
                        kw[&#39;label&#39;] = &#39;other (N$\\,$=$\\,$1)&#39; if one_or_more_multiplets else &#39;other&#39;
                        ppl.plot([], [], **kw)

                if one_or_more_multiplets:
                        kw[&#39;marker&#39;] = &#39;+&#39;
                        kw[&#39;ms&#39;] = 4
                        kw[&#39;alpha&#39;] = 1
                        kw[&#39;label&#39;] = &#39;other (N$\\,$&gt;$\\,$1)&#39; if one_or_more_singlets else &#39;other&#39;
                        ppl.plot([], [], **kw)

                ppl.legend(loc = &#39;lower left&#39;, bbox_to_anchor = (1.03, 0), borderaxespad = 0)
                ppl.xticks([])
                ppl.ylabel(&#39;Δ$_{47}$ residuals (ppm)&#39;)
                ppl.axis([-1, len(self), None, None])

                if not os.path.exists(dir):
                        os.makedirs(dir)
                if filename is None:
                        return fig
                elif filename == &#39;&#39;:
                        filename = f&#39;D{self._4x}_residuals.pdf&#39;
                ppl.savefig(f&#39;{dir}/{filename}&#39;)
                ppl.close(fig)
                                

        def simulate(self, *args, **kwargs):
                &#39;&#39;&#39;
                Legacy function with warning message pointing to `virtual_data()`
                &#39;&#39;&#39;
                raise DeprecationWarning(&#39;D4xdata.simulate is deprecated and has been replaced by virtual_data()&#39;)

        def plot_distribution_of_analyses(self, dir = &#39;output&#39;, filename = None, vs_time = False, output = None):
                &#39;&#39;&#39;
                Plot temporal distribution of all analyses in the data set.
                
                __Parameters__

                + `vs_time`: if `True`, plot as a function of `TimeTag` rather than sequentially.
                &#39;&#39;&#39;

                asamples = [s for s in self.anchors]
                usamples = [s for s in self.unknowns]
                if output is None or output == &#39;fig&#39;:
                        fig = ppl.figure(figsize = (6,4))
                        ppl.subplots_adjust(0.02, 0.03, 0.9, 0.8)
                Xmax = max([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self)])
                for k, s in enumerate(asamples + usamples):
                        if vs_time:
                                X = [r[&#39;TimeTag&#39;] for r in self if r[&#39;Sample&#39;] == s]
                        else:
                                X = [x for x,r in enumerate(self) if r[&#39;Sample&#39;] == s]
                        Y = [k for x in X]
                        ppl.plot(X, Y, &#39;o&#39;, mec = None, mew = 0, mfc = &#39;b&#39; if s in usamples else &#39;r&#39;, ms = 3, alpha = .5)
                        ppl.axhline(k, color = &#39;b&#39; if s in usamples else &#39;r&#39;, lw = .5, alpha = .25)
                        ppl.text(Xmax, k, f&#39;  {s}&#39;, va = &#39;center&#39;, ha = &#39;left&#39;, size = 7)
                if vs_time:
                        t = [r[&#39;TimeTag&#39;] for r in self]
                        t1, t2 = min(t), max(t)
                        tspan = t2 - t1
                        t1 -= tspan / len(self)
                        t2 += tspan / len(self)
                        ppl.axis([t1, t2, -1, k+1])
                else:
                        ppl.axis([-1, len(self), -1, k+1])
                        

                x2 = 0
                for session in self.sessions:
                        x1 = min([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self) if r[&#39;Session&#39;] == session])
                        if vs_time:
                                ppl.axvline(x1, color = &#39;k&#39;, lw = .75)
                        if k:
                                if vs_time:
                                        ppl.axvspan(x1,x2,color = &#39;k&#39;, zorder = -100, alpha = .2)
                                else:
                                        ppl.axvline((x1+x2)/2, color = &#39;k&#39;, lw = .75)
                        x2 = max([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self) if r[&#39;Session&#39;] == session])
#                       from xlrd import xldate_as_datetime
#                       print(session, xldate_as_datetime(x1, 0), xldate_as_datetime(x2, 0))
                        if vs_time:
                                ppl.axvline(x2, color = &#39;k&#39;, lw = .75)
                        ppl.text((2*x1+x2)/3, k+1, session, ha = &#39;left&#39;, va = &#39;bottom&#39;, rotation = 45, size = 8)

                ppl.xticks([])
                ppl.yticks([])

                if output is None:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename == None:
                                filename = f&#39;D{self._4x}_distribution_of_analyses.pdf&#39;
                        ppl.savefig(f&#39;{dir}/{filename}&#39;)
                        ppl.close(fig)
                elif output == &#39;ax&#39;:
                        return ppl.gca()
                elif output == &#39;fig&#39;:
                        return fig</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.list</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></li>
<li><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="D47crunch.D4xdata.ALPHA_18O_ACID_REACTION"><code class="name">var <span class="ident">ALPHA_18O_ACID_REACTION</span></code></dt>
<dd>
<div class="desc"><p>Specifies the <sup>18</sup>O/<sup>16</sup>O fractionation factor generally applicable
to acid reactions in the dataset. Currently used by <code><a title="D47crunch.D4xdata.wg" href="#D47crunch.D4xdata.wg">D4xdata.wg()</a></code>,
<code><a title="D47crunch.D4xdata.standardize_d13C" href="#D47crunch.D4xdata.standardize_d13C">D4xdata.standardize_d13C()</a></code>, and <code><a title="D47crunch.D4xdata.standardize_d18O" href="#D47crunch.D4xdata.standardize_d18O">D4xdata.standardize_d18O()</a></code>.</p>
<p>By default equal to 1.008129 (calcite reacted at 90 °C, <a href="https://dx.doi.org/10.1016/j.chemgeo.2007.08.005">Kim et al., 2007</a>).</p></div>
</dd>
<dt id="D47crunch.D4xdata.LEVENE_REF_SAMPLE"><code class="name">var <span class="ident">LEVENE_REF_SAMPLE</span></code></dt>
<dd>
<div class="desc"><p>After the Δ<sub>4x</sub> standardization step, each sample is tested to
assess whether the Δ<sub>4x</sub> variance within all analyses for that
sample differs significantly from that observed for a given reference
sample (using <a href="https://en.wikipedia.org/wiki/Levene%27s_test">Levene's test</a>, which yields a p-value corresponding to
the null hypothesis that the underlying variances are equal).</p>
<p><code>LEVENE_REF_SAMPLE</code> (by default equal to <code>'ETH-3'</code>) specifies which
sample should be used as a reference for this test.</p></div>
</dd>
<dt id="D47crunch.D4xdata.Nominal_d13C_VPDB"><code class="name">var <span class="ident">Nominal_d13C_VPDB</span></code></dt>
<dd>
<div class="desc"><p>Nominal δ<sup>13</sup>C<sub>VPDB</sub> values assigned to carbonate standards, used by
<code><a title="D47crunch.D4xdata.standardize_d13C" href="#D47crunch.D4xdata.standardize_d13C">D4xdata.standardize_d13C()</a></code>.</p>
<p>By default equal to <code>{'ETH-1': 2.02, 'ETH-2': -10.17, 'ETH-3': 1.71}</code> after
<a href="https://doi.org/10.1029/2017GC007385">Bernasconi et al. (2018)</a>.</p></div>
</dd>
<dt id="D47crunch.D4xdata.Nominal_d18O_VPDB"><code class="name">var <span class="ident">Nominal_d18O_VPDB</span></code></dt>
<dd>
<div class="desc"><p>Nominal δ<sup>18</sup>O<sub>VPDB</sub> values assigned to carbonate standards, used by
<code><a title="D47crunch.D4xdata.standardize_d18O" href="#D47crunch.D4xdata.standardize_d18O">D4xdata.standardize_d18O()</a></code>.</p>
<p>By default equal to <code>{'ETH-1': -2.19, 'ETH-2': -18.69, 'ETH-3': -1.78}</code> after
<a href="https://doi.org/10.1029/2017GC007385">Bernasconi et al. (2018)</a>.</p></div>
</dd>
<dt id="D47crunch.D4xdata.R13_VPDB"><code class="name">var <span class="ident">R13_VPDB</span></code></dt>
<dd>
<div class="desc"><p>Absolute (<sup>13</sup>C/<sup>12</sup>C) ratio of VPDB.
By default equal to 0.01118 (<a href="http://www.cnki.com.cn/Article/CJFDTotal-JXTW199004006.htm">Chang &amp; Li, 1990</a>)</p></div>
</dd>
<dt id="D47crunch.D4xdata.R17_VPDB"><code class="name">var <span class="ident">R17_VPDB</span></code></dt>
<dd>
<div class="desc"><p>Absolute (<sup>17</sup>O/<sup>16</sup>C) ratio of VPDB.
By definition equal to <code>R17_VSMOW * 1.03092 ** lambda_17</code>.</p></div>
</dd>
<dt id="D47crunch.D4xdata.R17_VSMOW"><code class="name">var <span class="ident">R17_VSMOW</span></code></dt>
<dd>
<div class="desc"><p>Absolute (<sup>17</sup>O/<sup>16</sup>C) ratio of VSMOW.
By default equal to 0.00038475
(<a href="https://dx.doi.org/10.1002/rcm.1011">Assonov &amp; Brenninkmeijer, 2003</a>, rescaled to <code>R13_VPDB</code>)</p></div>
</dd>
<dt id="D47crunch.D4xdata.R18_VPDB"><code class="name">var <span class="ident">R18_VPDB</span></code></dt>
<dd>
<div class="desc"><p>Absolute (<sup>18</sup>O/<sup>16</sup>C) ratio of VPDB.
By definition equal to <code>R18_VSMOW * 1.03092</code>.</p></div>
</dd>
<dt id="D47crunch.D4xdata.R18_VSMOW"><code class="name">var <span class="ident">R18_VSMOW</span></code></dt>
<dd>
<div class="desc"><p>Absolute (<sup>18</sup>O/<sup>16</sup>C) ratio of VSMOW.
By default equal to 0.0020052 (<a href="https://doi.org/10.1016/0012-821X(76)90115-1">Baertschi, 1976</a>)</p></div>
</dd>
<dt id="D47crunch.D4xdata.d13C_STANDARDIZATION_METHOD"><code class="name">var <span class="ident">d13C_STANDARDIZATION_METHOD</span></code></dt>
<dd>
<div class="desc"><p>Method by which to standardize δ<sup>13</sup>C values:</p>
<ul>
<li><code>none</code>: do not apply any δ<sup>13</sup>C standardization.</li>
<li><code>'1pt'</code>: within each session, offset all initial δ<sup>13</sup>C values so as to
minimize the difference between final δ<sup>13</sup>C<sub>VPDB</sub> values and
<code>Nominal_d13C_VPDB</code> (averaged over all analyses for which <code>Nominal_d13C_VPDB</code> is defined).</li>
<li><code>'2pt'</code>: within each session, apply a affine trasformation to all δ<sup>13</sup>C
values so as to minimize the difference between final δ<sup>13</sup>C<sub>VPDB</sub>
values and <code>Nominal_d13C_VPDB</code> (averaged over all analyses for which <code>Nominal_d13C_VPDB</code>
is defined).</li>
</ul></div>
</dd>
<dt id="D47crunch.D4xdata.d18O_STANDARDIZATION_METHOD"><code class="name">var <span class="ident">d18O_STANDARDIZATION_METHOD</span></code></dt>
<dd>
<div class="desc"><p>Method by which to standardize δ<sup>18</sup>O values:</p>
<ul>
<li><code>none</code>: do not apply any δ<sup>18</sup>O standardization.</li>
<li><code>'1pt'</code>: within each session, offset all initial δ<sup>18</sup>O values so as to
minimize the difference between final δ<sup>18</sup>O<sub>VPDB</sub> values and
<code>Nominal_d18O_VPDB</code> (averaged over all analyses for which <code>Nominal_d18O_VPDB</code> is defined).</li>
<li><code>'2pt'</code>: within each session, apply a affine trasformation to all δ<sup>18</sup>O
values so as to minimize the difference between final δ<sup>18</sup>O<sub>VPDB</sub>
values and <code>Nominal_d18O_VPDB</code> (averaged over all analyses for which <code>Nominal_d18O_VPDB</code>
is defined).</li>
</ul></div>
</dd>
<dt id="D47crunch.D4xdata.lambda_17"><code class="name">var <span class="ident">lambda_17</span></code></dt>
<dd>
<div class="desc"><p>Mass-dependent exponent for triple oxygen isotopes.
By default equal to 0.528 (<a href="https://doi.org/10.1002/rcm.2250">Barkan &amp; Luz, 2005</a>)</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="D47crunch.D4xdata.assign_timestamps"><code class="name flex">
<span>def <span class="ident">assign_timestamps</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Assign a time field <code>t</code> of type <code>float</code> to each analysis.</p>
<p>If <code>TimeTag</code> is one of the data fields, <code>t</code> is equal within a given session
to <code>TimeTag</code> minus the mean value of <code>TimeTag</code> for that session.
Otherwise, <code>TimeTag</code> is by default equal to the index of each analysis
in the dataset and <code>t</code> is defined as above.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def assign_timestamps(self):
                &#39;&#39;&#39;
                Assign a time field `t` of type `float` to each analysis.

                If `TimeTag` is one of the data fields, `t` is equal within a given session
                to `TimeTag` minus the mean value of `TimeTag` for that session.
                Otherwise, `TimeTag` is by default equal to the index of each analysis
                in the dataset and `t` is defined as above.
                &#39;&#39;&#39;
                for session in self.sessions:
                        sdata = self.sessions[session][&#39;data&#39;]
                        try:
                                t0 = np.mean([r[&#39;TimeTag&#39;] for r in sdata])
                                for r in sdata:
                                        r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
#                               print(&#39;DEBUG - USING TimeTag        &lt;-----------------------------------&#39;)
                        except KeyError:
                                t0 = (len(sdata)-1)/2
                                for t,r in enumerate(sdata):
                                        r[&#39;t&#39;] = t - t0</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.combine_samples"><code class="name flex">
<span>def <span class="ident">combine_samples</span></span>(<span>self, sample_groups)</span>
</code></dt>
<dd>
<div class="desc"><p>Combine analyses of different samples to compute weighted average Δ<sub>4x</sub>
and new error (co)variances corresponding to the groups defined by the <code>sample_groups</code>
dictionary.</p>
<p>Caution: samples are weighted by number of replicate analyses, which is a
reasonable default behavior but is not always optimal (e.g., in the case of strongly
correlated analytical errors for one or more samples).</p>
<p>Returns a tuplet of:</p>
<ul>
<li>the list of group names</li>
<li>an array of the corresponding Δ<sub>4x</sub> values</li>
<li>the corresponding (co)variance matrix</li>
</ul>
<p><strong>Parameters</strong></p>
<ul>
<li><code>sample_groups</code>: a dictionary of the form:</li>
</ul>
<pre><code class="language-py">{'group1': ['sample_1', 'sample_2'],
 'group2': ['sample_3', 'sample_4', 'sample_5']}
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def combine_samples(self, sample_groups):
        &#39;&#39;&#39;
        Combine analyses of different samples to compute weighted average Δ&lt;sub&gt;4x&lt;/sub&gt;
        and new error (co)variances corresponding to the groups defined by the `sample_groups`
        dictionary.
        
        Caution: samples are weighted by number of replicate analyses, which is a
        reasonable default behavior but is not always optimal (e.g., in the case of strongly
        correlated analytical errors for one or more samples).
        
        Returns a tuplet of:
        
        + the list of group names
        + an array of the corresponding Δ&lt;sub&gt;4x&lt;/sub&gt; values
        + the corresponding (co)variance matrix
        
        __Parameters__

        + `sample_groups`: a dictionary of the form:
        ```py
        {&#39;group1&#39;: [&#39;sample_1&#39;, &#39;sample_2&#39;],
         &#39;group2&#39;: [&#39;sample_3&#39;, &#39;sample_4&#39;, &#39;sample_5&#39;]}
        ```
        &#39;&#39;&#39;
        
        samples = [s for k in sorted(sample_groups.keys()) for s in sorted(sample_groups[k])]
        groups = sorted(sample_groups.keys())
        group_total_weights = {k: sum([self.samples[s][&#39;N&#39;] for s in sample_groups[k]]) for k in groups}
        D4x_old = np.array([[self.samples[x][f&#39;D{self._4x}&#39;]] for x in samples])
        CM_old = np.array([[self.sample_D4x_covar(x,y) for x in samples] for y in samples])
        W = np.array([
                [self.samples[i][&#39;N&#39;]/group_total_weights[j] if i in sample_groups[j] else 0 for i in samples]
                for j in groups])
        D4x_new = W @ D4x_old
        CM_new = W @ CM_old @ W.T

        return groups, D4x_new[:,0], CM_new</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.compute_bulk_and_clumping_deltas"><code class="name flex">
<span>def <span class="ident">compute_bulk_and_clumping_deltas</span></span>(<span>self, r)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute δ<sup>13</sup>C<sub>VPDB</sub>, δ<sup>18</sup>O<sub>VSMOW</sub>, and
raw Δ<sub>47</sub>, Δ<sub>48</sub>, Δ<sub>49</sub> values for an analysis <code>r</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_bulk_and_clumping_deltas(self, r):
        &#39;&#39;&#39;
        Compute δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt;, δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;, and
        raw Δ&lt;sub&gt;47&lt;/sub&gt;, Δ&lt;sub&gt;48&lt;/sub&gt;, Δ&lt;sub&gt;49&lt;/sub&gt; values for an analysis `r`.
        &#39;&#39;&#39;

        # Compute working gas R13, R18, and isobar ratios
        R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
        R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
        R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

        # Compute analyte isobar ratios
        R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
        R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
        R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
        R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
        R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

        r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_delta(R45, R46, D17O = r[&#39;D17O&#39;])
        R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
        R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

        # Compute stochastic isobar ratios of the analyte
        R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                R13, R18, D17O = r[&#39;D17O&#39;]
        )

        # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
        # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
        if (R45 / R45stoch - 1) &gt; 5e-8:
                self.vmsg(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):.3f} ppm&#39;)
        if (R46 / R46stoch - 1) &gt; 5e-8:
                self.vmsg(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):.3f} ppm&#39;)

        # Compute raw clumped isotope anomalies
        r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
        r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
        r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.compute_bulk_delta"><code class="name flex">
<span>def <span class="ident">compute_bulk_delta</span></span>(<span>self, R45, R46, D17O=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute δ<sup>13</sup>C<sub>VPDB</sub> and δ<sup>18</sup>O<sub>VSMOW</sub>,
by solving the generalized form of equation (17) from <a href="https://doi.org/10.1351/PAC-REP-09-01-05">Brand et al. (2010)</a>,
assuming that δ<sup>18</sup>O<sub>VSMOW</sub> is not too big (0 ± 50 ‰) and
solving the corresponding second-order Taylor polynomial.
(Appendix A of <a href="https://doi.org/10.1016/j.chemgeo.2016.08.014">Daëron et al., 2016</a>)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_bulk_delta(self, R45, R46, D17O = 0):
        &#39;&#39;&#39;
        Compute δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; and δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;,
        by solving the generalized form of equation (17) from [Brand et al. (2010)],
        assuming that δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; is not too big (0 ± 50 ‰) and
        solving the corresponding second-order Taylor polynomial.
        (Appendix A of [Daëron et al., 2016])

        [Brand et al. (2010)]: https://doi.org/10.1351/PAC-REP-09-01-05
        [Daëron et al., 2016]: https://doi.org/10.1016/j.chemgeo.2016.08.014
        &#39;&#39;&#39;

        K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

        A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
        B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
        C = 2 * self.R18_VSMOW
        D = -R46

        aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
        bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
        cc = A + B + C + D

        d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

        R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
        R17 = K * R18 ** self.lambda_17
        R13 = R45 - 2 * R17

        d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

        return d13C_VPDB, d18O_VSMOW</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.compute_isobar_ratios"><code class="name flex">
<span>def <span class="ident">compute_isobar_ratios</span></span>(<span>self, R13, R18, D17O=0, D47=0, D48=0, D49=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute isobar ratios for a sample with isotopic ratios <code>R13</code> and <code>R18</code>,
optionally accounting for non-zero values of Δ<sup>17</sup>O (<code>D17O</code>) and clumped isotope
anomalies (<code>D47</code>, <code>D48</code>, <code>D49</code>), all expressed in permil.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
        &#39;&#39;&#39;
        Compute isobar ratios for a sample with isotopic ratios `R13` and `R18`,
        optionally accounting for non-zero values of Δ&lt;sup&gt;17&lt;/sup&gt;O (`D17O`) and clumped isotope
        anomalies (`D47`, `D48`, `D49`), all expressed in permil.
        &#39;&#39;&#39;

        # Compute R17
        R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

        # Compute isotope concentrations
        C12 = (1 + R13) ** -1
        C13 = C12 * R13
        C16 = (1 + R17 + R18) ** -1
        C17 = C16 * R17
        C18 = C16 * R18

        # Compute stochastic isotopologue concentrations
        C626 = C16 * C12 * C16
        C627 = C16 * C12 * C17 * 2
        C628 = C16 * C12 * C18 * 2
        C636 = C16 * C13 * C16
        C637 = C16 * C13 * C17 * 2
        C638 = C16 * C13 * C18 * 2
        C727 = C17 * C12 * C17
        C728 = C17 * C12 * C18 * 2
        C737 = C17 * C13 * C17
        C738 = C17 * C13 * C18 * 2
        C828 = C18 * C12 * C18
        C838 = C18 * C13 * C18

        # Compute stochastic isobar ratios
        R45 = (C636 + C627) / C626
        R46 = (C628 + C637 + C727) / C626
        R47 = (C638 + C728 + C737) / C626
        R48 = (C738 + C828) / C626
        R49 = C838 / C626

        # Account for stochastic anomalies
        R47 *= 1 + D47 / 1000
        R48 *= 1 + D48 / 1000
        R49 *= 1 + D49 / 1000

        # Return isobar ratios
        return R45, R46, R47, R48, R49</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.compute_r"><code class="name flex">
<span>def <span class="ident">compute_r</span></span>(<span>self, key, samples='all samples', sessions='all sessions')</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the repeatability of <code>[r[key] for r in self]</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def compute_r(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
        &#39;&#39;&#39;
        Compute the repeatability of `[r[key] for r in self]`
        &#39;&#39;&#39;
        # NB: it&#39;s debatable whether rD47 should be computed
        # with Nf = len(self)-len(self.samples) instead of
        # Nf = len(self) - len(self.unknwons) - 3*len(self.sessions)

        if samples == &#39;all samples&#39;:
                mysamples = [k for k in self.samples]
        elif samples == &#39;anchors&#39;:
                mysamples = [k for k in self.anchors]
        elif samples == &#39;unknowns&#39;:
                mysamples = [k for k in self.unknowns]
        else:
                mysamples = samples

        if sessions == &#39;all sessions&#39;:
                sessions = [k for k in self.sessions]

        if key in [&#39;D47&#39;, &#39;D48&#39;]:
                chisq, Nf = 0, 0
                for sample in mysamples :
                        X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                        if len(X) &gt; 1 :
                                chisq += np.sum([ (x-self.samples[sample][key])**2 for x in X ])
                                if sample in self.unknowns:
                                        Nf += len(X) - 1
                                else:
                                        Nf += len(X)
                if samples in [&#39;anchors&#39;, &#39;all samples&#39;]:
                        Nf -= sum([self.sessions[s][&#39;Np&#39;] for s in sessions])
                r = (chisq / Nf)**.5 if Nf &gt; 0 else 0

        else: # if key not in [&#39;D47&#39;, &#39;D48&#39;]
                chisq, Nf = 0, 0
                for sample in mysamples :
                        X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                        if len(X) &gt; 1 :
                                Nf += len(X) - 1
                                chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
                r = (chisq / Nf)**.5 if Nf &gt; 0 else 0

        self.msg(f&#39;Repeatability of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
        return r</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.consolidate"><code class="name flex">
<span>def <span class="ident">consolidate</span></span>(<span>self, tables=True, plots=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Collect information about samples, sessions and repeatabilities.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def consolidate(self, tables = True, plots = True):
        &#39;&#39;&#39;
        Collect information about samples, sessions and repeatabilities.
        &#39;&#39;&#39;
        self.consolidate_samples()
        self.consolidate_sessions()
        self.repeatabilities()

        if tables:
                self.summary()
                self.table_of_sessions()
                self.table_of_analyses()
                self.table_of_samples()

        if plots:
                self.plot_sessions()</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.consolidate_samples"><code class="name flex">
<span>def <span class="ident">consolidate_samples</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compile various statistics for each sample.</p>
<p>For each anchor sample:</p>
<ul>
<li><code>D47</code> or <code>D48</code>: the nominal Δ<sub>4x</sub> value for this anchor, specified by <code>self.Nominal_D4x</code></li>
<li><code>SE_D47</code> or <code>SE_D48</code>: set to zero by definition</li>
</ul>
<p>For each unknown sample:</p>
<ul>
<li><code>D47</code> or <code>D48</code>: the standardized Δ<sub>4x</sub> value for this unknown</li>
<li><code>SE_D47</code> or <code>SE_D48</code>: the standard error of Δ<sub>4x</sub> for this unknown</li>
</ul>
<p>For each anchor and unknown:</p>
<ul>
<li><code>N</code>: the total number of analyses of this sample</li>
<li><code>SD_D47</code> or <code>SD_D48</code>: the “sample” (in the statistical sense) standard deviation for this sample</li>
<li><code>d13C_VPDB</code>: the average δ<sup>13</sup>C<sub>VPDB</sub> value for this sample</li>
<li><code>d18O_VSMOW</code>: the average δ<sup>18</sup>O<sub>VSMOW</sub> value for this sample (as CO<sub>2</sub>)</li>
<li><code>p_Levene</code>: the p-value from a <a href="https://en.wikipedia.org/wiki/Levene%27s_test">Levene test</a> of equal variance, indicating whether
the Δ<sub>4x</sub> repeatability this sample differs significantly from that observed
for the reference sample specified by <code>self.LEVENE_REF_SAMPLE</code>.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def consolidate_samples(self):
        &#39;&#39;&#39;
        Compile various statistics for each sample.

        For each anchor sample:

        + `D47` or `D48`: the nominal Δ&lt;sub&gt;4x&lt;/sub&gt; value for this anchor, specified by `self.Nominal_D4x`
        + `SE_D47` or `SE_D48`: set to zero by definition

        For each unknown sample:

        + `D47` or `D48`: the standardized Δ&lt;sub&gt;4x&lt;/sub&gt; value for this unknown
        + `SE_D47` or `SE_D48`: the standard error of Δ&lt;sub&gt;4x&lt;/sub&gt; for this unknown

        For each anchor and unknown:

        + `N`: the total number of analyses of this sample
        + `SD_D47` or `SD_D48`: the “sample” (in the statistical sense) standard deviation for this sample
        + `d13C_VPDB`: the average δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; value for this sample
        + `d18O_VSMOW`: the average δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; value for this sample (as CO&lt;sub&gt;2&lt;/sub&gt;)
        + `p_Levene`: the p-value from a [Levene test] of equal variance, indicating whether
        the Δ&lt;sub&gt;4x&lt;/sub&gt; repeatability this sample differs significantly from that observed
        for the reference sample specified by `self.LEVENE_REF_SAMPLE`.

        [Levene test]: https://en.wikipedia.org/wiki/Levene%27s_test
        &#39;&#39;&#39;
        D4x_ref_pop = [r[f&#39;D{self._4x}&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]
        for sample in self.samples:
                self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                if self.samples[sample][&#39;N&#39;] &gt; 1:
                        self.samples[sample][f&#39;SD_D{self._4x}&#39;] = stdev([r[f&#39;D{self._4x}&#39;] for r in self.samples[sample][&#39;data&#39;]])

                self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

                D4x_pop = [r[f&#39;D{self._4x}&#39;] for r in self.samples[sample][&#39;data&#39;]]
                if len(D4x_pop) &gt; 2:
                        self.samples[sample][&#39;p_Levene&#39;] = levene(D4x_ref_pop, D4x_pop, center = &#39;median&#39;)[1]

        if self.standardization_method == &#39;pooled&#39;:
                for sample in self.anchors:
                        self.samples[sample][f&#39;D{self._4x}&#39;] = self.Nominal_D4x[sample]
                        self.samples[sample][f&#39;SE_D{self._4x}&#39;] = 0.
                for sample in self.unknowns:
                        self.samples[sample][f&#39;D{self._4x}&#39;] = self.standardization.params.valuesdict()[f&#39;D{self._4x}_{pf(sample)}&#39;]
                        try:
                                self.samples[sample][f&#39;SE_D{self._4x}&#39;] = self.sample_D4x_covar(sample)**.5
                        except ValueError:
                                # when `sample` is constrained by self.standardize(constraints = {...}),
                                # it is no longer listed in self.standardization.var_names.
                                # Temporary fix: define SE as zero for now
                                self.samples[sample][f&#39;SE_D4{self._4x}&#39;] = 0.

        elif self.standardization_method == &#39;indep_sessions&#39;:
                for sample in self.anchors:
                        self.samples[sample][f&#39;D{self._4x}&#39;] = self.Nominal_D4x[sample]
                        self.samples[sample][f&#39;SE_D{self._4x}&#39;] = 0.
                for sample in self.unknowns:
                        self.msg(f&#39;Consolidating sample {sample}&#39;)
                        self.unknowns[sample][f&#39;session_D{self._4x}&#39;] = {}
                        session_avg = []
                        for session in self.sessions:
                                sdata = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                                if sdata:
                                        self.msg(f&#39;{sample} found in session {session}&#39;)
                                        avg_D4x = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata])
                                        avg_d4x = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata])
                                        # !! TODO: sigma_s below does not account for temporal changes in standardization error
                                        sigma_s = self.standardization_error(session, avg_d4x, avg_D4x)
                                        sigma_u = sdata[0][f&#39;wD{self._4x}raw&#39;] / self.sessions[session][&#39;a&#39;] / len(sdata)**.5
                                        session_avg.append([avg_D4x, (sigma_u**2 + sigma_s**2)**.5])
                                        self.unknowns[sample][f&#39;session_D{self._4x}&#39;][session] = session_avg[-1]
                        self.samples[sample][f&#39;D{self._4x}&#39;], self.samples[sample][f&#39;SE_D{self._4x}&#39;] = w_avg(*zip(*session_avg))
                        weights = {s: self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s][1]**-2 for s in self.unknowns[sample][f&#39;session_D{self._4x}&#39;]}
                        wsum = sum([weights[s] for s in weights])
                        for s in weights:
                                self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s] += [self.unknowns[sample][f&#39;session_D{self._4x}&#39;][s][1]**-2 / wsum]</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.consolidate_sessions"><code class="name flex">
<span>def <span class="ident">consolidate_sessions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute various statistics for each session.</p>
<ul>
<li><code>Na</code>: Number of anchor analyses in the session</li>
<li><code>Nu</code>: Number of unknown analyses in the session</li>
<li><code>r_d13C_VPDB</code>: δ<sup>13</sup>C<sub>VPDB</sub> repeatability of analyses within the session</li>
<li><code>r_d18O_VSMOW</code>: δ<sup>18</sup>O<sub>VSMOW</sub> repeatability of analyses within the session</li>
<li><code>r_D47</code> or <code>r_D48</code>: Δ<sub>4x</sub> repeatability of analyses within the session</li>
<li><code>a</code>: scrambling factor</li>
<li><code>b</code>: compositional slope</li>
<li><code>c</code>: WG offset</li>
<li><code>SE_a</code>: Model stadard erorr of <code>a</code></li>
<li><code>SE_b</code>: Model stadard erorr of <code>b</code></li>
<li><code>SE_c</code>: Model stadard erorr of <code>c</code></li>
<li><code>scrambling_drift</code> (boolean): whether to allow a temporal drift in the scrambling factor (<code>a</code>)</li>
<li><code>slope_drift</code> (boolean): whether to allow a temporal drift in the compositional slope (<code>b</code>)</li>
<li><code>wg_drift</code> (boolean): whether to allow a temporal drift in the WG offset (<code>c</code>)</li>
<li><code>a2</code>: scrambling factor drift</li>
<li><code>b2</code>: compositional slope drift</li>
<li><code>c2</code>: WG offset drift</li>
<li><code>Np</code>: Number of standardization parameters to fit</li>
<li><code>CM</code>: model covariance matrix for (<code>a</code>, <code>b</code>, <code>c</code>, <code>a2</code>, <code>b2</code>, <code>c2</code>)</li>
<li><code>d13Cwg_VPDB</code>: δ<sup>13</sup>C<sub>VPDB</sub> of WG</li>
<li><code>d18Owg_VSMOW</code>: δ<sup>18</sup>O<sub>VSMOW</sub> of WG</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate_sessions(self):
        &#39;&#39;&#39;
        Compute various statistics for each session.

        + `Na`: Number of anchor analyses in the session
        + `Nu`: Number of unknown analyses in the session
        + `r_d13C_VPDB`: δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; repeatability of analyses within the session
        + `r_d18O_VSMOW`: δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; repeatability of analyses within the session
        + `r_D47` or `r_D48`: Δ&lt;sub&gt;4x&lt;/sub&gt; repeatability of analyses within the session
        + `a`: scrambling factor
        + `b`: compositional slope
        + `c`: WG offset
        + `SE_a`: Model stadard erorr of `a`
        + `SE_b`: Model stadard erorr of `b`
        + `SE_c`: Model stadard erorr of `c`
        + `scrambling_drift` (boolean): whether to allow a temporal drift in the scrambling factor (`a`)
        + `slope_drift` (boolean): whether to allow a temporal drift in the compositional slope (`b`)
        + `wg_drift` (boolean): whether to allow a temporal drift in the WG offset (`c`)
        + `a2`: scrambling factor drift
        + `b2`: compositional slope drift
        + `c2`: WG offset drift
        + `Np`: Number of standardization parameters to fit
        + `CM`: model covariance matrix for (`a`, `b`, `c`, `a2`, `b2`, `c2`)
        + `d13Cwg_VPDB`: δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; of WG
        + `d18Owg_VSMOW`: δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt; of WG
        &#39;&#39;&#39;
        for session in self.sessions:
                if &#39;d13Cwg_VPDB&#39; not in self.sessions[session]:
                        self.sessions[session][&#39;d13Cwg_VPDB&#39;] = self.sessions[session][&#39;data&#39;][0][&#39;d13Cwg_VPDB&#39;]
                if &#39;d18Owg_VSMOW&#39; not in self.sessions[session]:
                        self.sessions[session][&#39;d18Owg_VSMOW&#39;] = self.sessions[session][&#39;data&#39;][0][&#39;d18Owg_VSMOW&#39;]
                self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])

                self.msg(f&#39;Computing repeatabilities for session {session}&#39;)
                self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_r(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_r(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                self.sessions[session][f&#39;r_D{self._4x}&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, sessions = [session])

        if self.standardization_method == &#39;pooled&#39;:
                for session in self.sessions:

                        self.sessions[session][&#39;a&#39;] = self.standardization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                        i = self.standardization.var_names.index(f&#39;a_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_a&#39;] = self.standardization.covar[i,i]**.5

                        self.sessions[session][&#39;b&#39;] = self.standardization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                        i = self.standardization.var_names.index(f&#39;b_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_b&#39;] = self.standardization.covar[i,i]**.5

                        self.sessions[session][&#39;c&#39;] = self.standardization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                        i = self.standardization.var_names.index(f&#39;c_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_c&#39;] = self.standardization.covar[i,i]**.5

                        self.sessions[session][&#39;a2&#39;] = self.standardization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;scrambling_drift&#39;]:
                                i = self.standardization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_a2&#39;] = self.standardization.covar[i,i]**.5
                        else:
                                self.sessions[session][&#39;SE_a2&#39;] = 0.

                        self.sessions[session][&#39;b2&#39;] = self.standardization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;slope_drift&#39;]:
                                i = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_b2&#39;] = self.standardization.covar[i,i]**.5
                        else:
                                self.sessions[session][&#39;SE_b2&#39;] = 0.

                        self.sessions[session][&#39;c2&#39;] = self.standardization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;wg_drift&#39;]:
                                i = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_c2&#39;] = self.standardization.covar[i,i]**.5
                        else:
                                self.sessions[session][&#39;SE_c2&#39;] = 0.

                        i = self.standardization.var_names.index(f&#39;a_{pf(session)}&#39;)
                        j = self.standardization.var_names.index(f&#39;b_{pf(session)}&#39;)
                        k = self.standardization.var_names.index(f&#39;c_{pf(session)}&#39;)
                        CM = np.zeros((6,6))
                        CM[:3,:3] = self.standardization.covar[[i,j,k],:][:,[i,j,k]]
                        try:
                                i2 = self.standardization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                CM[3,[0,1,2,3]] = self.standardization.covar[i2,[i,j,k,i2]]
                                CM[[0,1,2,3],3] = self.standardization.covar[[i,j,k,i2],i2]
                                try:
                                        j2 = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                        CM[3,4] = self.standardization.covar[i2,j2]
                                        CM[4,3] = self.standardization.covar[j2,i2]
                                except ValueError:
                                        pass
                                try:
                                        k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                        CM[3,5] = self.standardization.covar[i2,k2]
                                        CM[5,3] = self.standardization.covar[k2,i2]
                                except ValueError:
                                        pass
                        except ValueError:
                                pass
                        try:
                                j2 = self.standardization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                CM[4,[0,1,2,4]] = self.standardization.covar[j2,[i,j,k,j2]]
                                CM[[0,1,2,4],4] = self.standardization.covar[[i,j,k,j2],j2]
                                try:
                                        k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                        CM[4,5] = self.standardization.covar[j2,k2]
                                        CM[5,4] = self.standardization.covar[k2,j2]
                                except ValueError:
                                        pass
                        except ValueError:
                                pass
                        try:
                                k2 = self.standardization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                CM[5,[0,1,2,5]] = self.standardization.covar[k2,[i,j,k,k2]]
                                CM[[0,1,2,5],5] = self.standardization.covar[[i,j,k,k2],k2]
                        except ValueError:
                                pass

                        self.sessions[session][&#39;CM&#39;] = CM

        elif self.standardization_method == &#39;indep_sessions&#39;:
                pass # Not implemented yet</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.crunch"><code class="name flex">
<span>def <span class="ident">crunch</span></span>(<span>self, verbose='')</span>
</code></dt>
<dd>
<div class="desc"><p>Compute bulk composition and raw clumped isotope anomalies for all analyses.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def crunch(self, verbose = &#39;&#39;):
        &#39;&#39;&#39;
        Compute bulk composition and raw clumped isotope anomalies for all analyses.
        &#39;&#39;&#39;
        for r in self:
                self.compute_bulk_and_clumping_deltas(r)
        self.standardize_d13C()
        self.standardize_d18O()
        self.msg(f&#34;Crunched {len(self)} analyses.&#34;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.fill_in_missing_info"><code class="name flex">
<span>def <span class="ident">fill_in_missing_info</span></span>(<span>self, session='mySession')</span>
</code></dt>
<dd>
<div class="desc"><p>Fill in optional fields with default values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fill_in_missing_info(self, session = &#39;mySession&#39;):
        &#39;&#39;&#39;
        Fill in optional fields with default values
        &#39;&#39;&#39;
        for i,r in enumerate(self):
                if &#39;D17O&#39; not in r:
                        r[&#39;D17O&#39;] = 0.
                if &#39;UID&#39; not in r:
                        r[&#39;UID&#39;] = f&#39;{i+1}&#39;
                if &#39;Session&#39; not in r:
                        r[&#39;Session&#39;] = session
                for k in [&#39;d47&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                        if k not in r:
                                r[k] = np.nan</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.input"><code class="name flex">
<span>def <span class="ident">input</span></span>(<span>self, txt, sep='', session='')</span>
</code></dt>
<dd>
<div class="desc"><p>Read <code>txt</code> string in csv format to load analysis data into a <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> object.</p>
<p>In the csv string, spaces before and after field separators (<code>','</code> by default)
are optional. Each line corresponds to a single analysis.</p>
<p>The required fields are:</p>
<ul>
<li><code>UID</code>: a unique identifier</li>
<li><code>Session</code>: an identifier for the analytical session</li>
<li><code>Sample</code>: a sample identifier</li>
<li><code>d45</code>, <code>d46</code>, and at least one of <code>d47</code> or <code>d48</code>: the working-gas delta values</li>
</ul>
<p>Independently known oxygen-17 anomalies may be provided as <code>D17O</code> (in ‰ relative to
VSMOW, λ = <code>self.lambda_17</code>), and are otherwise assumed to be zero. Working-gas deltas <code>d47</code>, <code>d48</code>
and <code>d49</code> are optional, and set to NaN by default.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>txt</code>: the csv string to read</li>
<li><code>sep</code>: csv separator delimiting the fields. By default, use <code>,</code>, <code>;</code>, or <code>
</code>,
whichever appers most often in <code>txt</code>.</li>
<li><code>session</code>: set <code>Session</code> field to this string for all analyses</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def input(self, txt, sep = &#39;&#39;, session = &#39;&#39;):
        &#39;&#39;&#39;
        Read `txt` string in csv format to load analysis data into a `D47data` object.

        In the csv string, spaces before and after field separators (`&#39;,&#39;` by default)
        are optional. Each line corresponds to a single analysis.

        The required fields are:

        + `UID`: a unique identifier
        + `Session`: an identifier for the analytical session
        + `Sample`: a sample identifier
        + `d45`, `d46`, and at least one of `d47` or `d48`: the working-gas delta values

        Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
        VSMOW, λ = `self.lambda_17`), and are otherwise assumed to be zero. Working-gas deltas `d47`, `d48`
        and `d49` are optional, and set to NaN by default.

        __Parameters__

        + `txt`: the csv string to read
        + `sep`: csv separator delimiting the fields. By default, use `,`, `;`, or `\t`,
        whichever appers most often in `txt`.
        + `session`: set `Session` field to this string for all analyses
        &#39;&#39;&#39;
        if sep == &#39;&#39;:
                sep = sorted(&#39;,;\t&#39;, key = lambda x: - txt.count(x))[0]
        txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
        data = [{k: v if k in [&#39;UID&#39;, &#39;Session&#39;, &#39;Sample&#39;] else smart_type(v) for k,v in zip(txt[0], l) if v != &#39;&#39;} for l in txt[1:]]

        if session != &#39;&#39;:
                for r in data:
                        r[&#39;Session&#39;] = session

        self += data
        self.refresh()</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.log"><code class="name flex">
<span>def <span class="ident">log</span></span>(<span>self, *txts)</span>
</code></dt>
<dd>
<div class="desc"><p>Log a message to <code>self.logfile</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log(self, *txts):
        &#39;&#39;&#39;
        Log a message to `self.logfile`
        &#39;&#39;&#39;
        if self.logfile:
                with open(self.logfile, &#39;a&#39;) as fid:
                        for txt in txts:
                                fid.write(f&#39;\n{dt.now().strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)} {f&#34;[{self.prefix}]&#34;:&lt;16} {txt}&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.make_verbal"><code class="name flex">
<span>def <span class="ident">make_verbal</span></span>(<span>oldfun)</span>
</code></dt>
<dd>
<div class="desc"><p>Decorator: allow temporarily changing <code>self.prefix</code> and overriding <code>self.verbose</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_verbal(oldfun):
        &#39;&#39;&#39;
        Decorator: allow temporarily changing `self.prefix` and overriding `self.verbose`.
        &#39;&#39;&#39;
        @wraps(oldfun)
        def newfun(*args, verbose = &#39;&#39;, **kwargs):
                myself = args[0]
                oldprefix = myself.prefix
                myself.prefix = oldfun.__name__
                if verbose != &#39;&#39;:
                        oldverbose = myself.verbose
                        myself.verbose = verbose
                out = oldfun(*args, **kwargs)
                myself.prefix = oldprefix
                if verbose != &#39;&#39;:
                        myself.verbose = oldverbose
                return out
        return newfun</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.msg"><code class="name flex">
<span>def <span class="ident">msg</span></span>(<span>self, txt)</span>
</code></dt>
<dd>
<div class="desc"><p>Log a message to <code>self.logfile</code>, and print it out if <code>verbose = True</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def msg(self, txt):
        &#39;&#39;&#39;
        Log a message to `self.logfile`, and print it out if `verbose = True`
        &#39;&#39;&#39;
        self.log(txt)
        if self.verbose:
                print(f&#39;{f&#34;[{self.prefix}]&#34;:&lt;16} {txt}&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.plot_distribution_of_analyses"><code class="name flex">
<span>def <span class="ident">plot_distribution_of_analyses</span></span>(<span>self, dir='output', filename=None, vs_time=False, output=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot temporal distribution of all analyses in the data set.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>vs_time</code>: if <code>True</code>, plot as a function of <code>TimeTag</code> rather than sequentially.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def plot_distribution_of_analyses(self, dir = &#39;output&#39;, filename = None, vs_time = False, output = None):
                &#39;&#39;&#39;
                Plot temporal distribution of all analyses in the data set.
                
                __Parameters__

                + `vs_time`: if `True`, plot as a function of `TimeTag` rather than sequentially.
                &#39;&#39;&#39;

                asamples = [s for s in self.anchors]
                usamples = [s for s in self.unknowns]
                if output is None or output == &#39;fig&#39;:
                        fig = ppl.figure(figsize = (6,4))
                        ppl.subplots_adjust(0.02, 0.03, 0.9, 0.8)
                Xmax = max([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self)])
                for k, s in enumerate(asamples + usamples):
                        if vs_time:
                                X = [r[&#39;TimeTag&#39;] for r in self if r[&#39;Sample&#39;] == s]
                        else:
                                X = [x for x,r in enumerate(self) if r[&#39;Sample&#39;] == s]
                        Y = [k for x in X]
                        ppl.plot(X, Y, &#39;o&#39;, mec = None, mew = 0, mfc = &#39;b&#39; if s in usamples else &#39;r&#39;, ms = 3, alpha = .5)
                        ppl.axhline(k, color = &#39;b&#39; if s in usamples else &#39;r&#39;, lw = .5, alpha = .25)
                        ppl.text(Xmax, k, f&#39;  {s}&#39;, va = &#39;center&#39;, ha = &#39;left&#39;, size = 7)
                if vs_time:
                        t = [r[&#39;TimeTag&#39;] for r in self]
                        t1, t2 = min(t), max(t)
                        tspan = t2 - t1
                        t1 -= tspan / len(self)
                        t2 += tspan / len(self)
                        ppl.axis([t1, t2, -1, k+1])
                else:
                        ppl.axis([-1, len(self), -1, k+1])
                        

                x2 = 0
                for session in self.sessions:
                        x1 = min([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self) if r[&#39;Session&#39;] == session])
                        if vs_time:
                                ppl.axvline(x1, color = &#39;k&#39;, lw = .75)
                        if k:
                                if vs_time:
                                        ppl.axvspan(x1,x2,color = &#39;k&#39;, zorder = -100, alpha = .2)
                                else:
                                        ppl.axvline((x1+x2)/2, color = &#39;k&#39;, lw = .75)
                        x2 = max([r[&#39;TimeTag&#39;] if vs_time else j for j,r in enumerate(self) if r[&#39;Session&#39;] == session])
#                       from xlrd import xldate_as_datetime
#                       print(session, xldate_as_datetime(x1, 0), xldate_as_datetime(x2, 0))
                        if vs_time:
                                ppl.axvline(x2, color = &#39;k&#39;, lw = .75)
                        ppl.text((2*x1+x2)/3, k+1, session, ha = &#39;left&#39;, va = &#39;bottom&#39;, rotation = 45, size = 8)

                ppl.xticks([])
                ppl.yticks([])

                if output is None:
                        if not os.path.exists(dir):
                                os.makedirs(dir)
                        if filename == None:
                                filename = f&#39;D{self._4x}_distribution_of_analyses.pdf&#39;
                        ppl.savefig(f&#39;{dir}/{filename}&#39;)
                        ppl.close(fig)
                elif output == &#39;ax&#39;:
                        return ppl.gca()
                elif output == &#39;fig&#39;:
                        return fig</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.plot_residuals"><code class="name flex">
<span>def <span class="ident">plot_residuals</span></span>(<span>self, dir='output', filename=None, highlight=[], colors=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot residuals of each analysis as a function of time (actually, as a function of
the order of analyses in the D4xdata() object)</p>
<ul>
<li><code>dir</code>: the directory in which to save the plot</li>
<li><code>highlight</code>: a list of samples to highlight</li>
<li><code>colors</code>: a dict of {<sample>: <color>} for all samples</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def plot_residuals(self, dir = &#39;output&#39;, filename = None, highlight = [], colors = None):
                &#39;&#39;&#39;
                Plot residuals of each analysis as a function of time (actually, as a function of
                the order of analyses in the D4xdata() object)

                + `dir`: the directory in which to save the plot
                + `highlight`: a list of samples to highlight
                + `colors`: a dict of {&lt;sample&gt;: &lt;color&gt;} for all samples
                &#39;&#39;&#39;
                fig = ppl.figure(figsize = (8,4))
                ppl.subplots_adjust(.1,.05,.78,.8)
                N = len(self.anchors)
                if colors is None:
                        if len(highlight) &gt; 0:
                                Nh = len(highlight)
                                if Nh == 1:
                                        colors = {highlight[0]: (0,0,0)}
                                elif Nh == 3:
                                        colors = {a: c for a,c in zip(highlight, [(0,0,1), (1,0,0), (0,2/3,0)])}
                                elif Nh == 4:
                                        colors = {a: c for a,c in zip(highlight, [(0,0,1), (1,0,0), (0,2/3,0), (.75,0,.75)])}
                                else:
                                        colors = {a: hls_to_rgb(k/Nh, .4, 1) for k,a in enumerate(highlight)}
                        else:
                                if N == 3:
                                        colors = {a: c for a,c in zip(self.anchors, [(0,0,1), (1,0,0), (0,2/3,0)])}
                                elif N == 4:
                                        colors = {a: c for a,c in zip(self.anchors, [(0,0,1), (1,0,0), (0,2/3,0), (.75,0,.75)])}
                                else:
                                        colors = {a: hls_to_rgb(k/N, .4, 1) for k,a in enumerate(self.anchors)}
                session = self[0][&#39;Session&#39;]
                x1 = 0
#               ymax = np.max([1e3 * (r[&#39;D47&#39;] - self.samples[r[&#39;Sample&#39;]][&#39;D47&#39;]) for r in self])
                x_sessions = {}
                one_or_more_singlets = False
                one_or_more_multiplets = False
                for k,r in enumerate(self):
                        if r[&#39;Session&#39;] != session:
                                x2 = k-1
                                x_sessions[session] = (x1+x2)/2
                                ppl.axvline(k - 0.5, color = &#39;k&#39;, lw = .5)
                                session = r[&#39;Session&#39;]
                                x1 = k
                        singlet = len(self.samples[r[&#39;Sample&#39;]][&#39;data&#39;]) == 1
                        if r[&#39;Sample&#39;] in self.unknowns:
                                if singlet:
                                        one_or_more_singlets = True
                                else:
                                        one_or_more_multiplets = True
                        kw = dict(
                                marker = &#39;x&#39; if singlet else &#39;+&#39;,
                                ms = 4 if singlet else 5,
                                ls = &#39;None&#39;,
                                mec = colors[r[&#39;Sample&#39;]] if r[&#39;Sample&#39;] in colors else (0,0,0),
                                mew = 1,
                                alpha = 0.2 if singlet else 1,
                                )
                        if highlight and r[&#39;Sample&#39;] not in highlight:
                                kw[&#39;alpha&#39;] = 0.2
                        ppl.plot(k, 1e3 * (r[&#39;D47&#39;] - self.samples[r[&#39;Sample&#39;]][&#39;D47&#39;]), **kw)
                x2 = k
                x_sessions[session] = (x1+x2)/2

                ppl.axhspan(-self.repeatability[&#39;r_D47&#39;]*1000, self.repeatability[&#39;r_D47&#39;]*1000, color = &#39;k&#39;, alpha = .05, lw = 1)
                ppl.text(len(self), self.repeatability[&#39;r_D47&#39;]*1000, f&#34;   SD = {self.repeatability[&#39;r_D47&#39;]*1000:.1f} ppm&#34;, size = 9, alpha = .75, va = &#39;center&#39;)
                ppl.axhspan(-self.repeatability[&#39;r_D47&#39;]*1000*self.t95, self.repeatability[&#39;r_D47&#39;]*1000*self.t95, color = &#39;k&#39;, alpha = .05, lw = 1)
                ppl.text(len(self), self.repeatability[&#39;r_D47&#39;]*1000*self.t95, f&#34;   95% CL: ± {self.repeatability[&#39;r_D47&#39;]*1000*self.t95:.1f} ppm&#34;, size = 9, alpha = .75, va = &#39;center&#39;)

                ymax = ppl.axis()[3]
                for s in x_sessions:
                        ppl.text(
                                x_sessions[s],
                                ymax +1,
                                s,
                                va = &#39;bottom&#39;,
                                **(
                                        dict(ha = &#39;center&#39;)
                                        if len(self.sessions[s][&#39;data&#39;]) &gt; (0.15 * len(self))
                                        else dict(ha = &#39;left&#39;, rotation = 45)
                                        )
                                )

                for s in colors:
                        kw[&#39;marker&#39;] = &#39;+&#39;
                        kw[&#39;ms&#39;] = 5
                        kw[&#39;mec&#39;] = colors[s]
                        kw[&#39;label&#39;] = s
                        kw[&#39;alpha&#39;] = 1
                        ppl.plot([], [], **kw)

                kw[&#39;mec&#39;] = (0,0,0)

                if one_or_more_singlets:
                        kw[&#39;marker&#39;] = &#39;x&#39;
                        kw[&#39;ms&#39;] = 4
                        kw[&#39;alpha&#39;] = .2
                        kw[&#39;label&#39;] = &#39;other (N$\\,$=$\\,$1)&#39; if one_or_more_multiplets else &#39;other&#39;
                        ppl.plot([], [], **kw)

                if one_or_more_multiplets:
                        kw[&#39;marker&#39;] = &#39;+&#39;
                        kw[&#39;ms&#39;] = 4
                        kw[&#39;alpha&#39;] = 1
                        kw[&#39;label&#39;] = &#39;other (N$\\,$&gt;$\\,$1)&#39; if one_or_more_singlets else &#39;other&#39;
                        ppl.plot([], [], **kw)

                ppl.legend(loc = &#39;lower left&#39;, bbox_to_anchor = (1.03, 0), borderaxespad = 0)
                ppl.xticks([])
                ppl.ylabel(&#39;Δ$_{47}$ residuals (ppm)&#39;)
                ppl.axis([-1, len(self), None, None])

                if not os.path.exists(dir):
                        os.makedirs(dir)
                if filename is None:
                        return fig
                elif filename == &#39;&#39;:
                        filename = f&#39;D{self._4x}_residuals.pdf&#39;
                ppl.savefig(f&#39;{dir}/{filename}&#39;)
                ppl.close(fig)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.plot_sessions"><code class="name flex">
<span>def <span class="ident">plot_sessions</span></span>(<span>self, dir='output', figsize=(8, 8))</span>
</code></dt>
<dd>
<div class="desc"><p>Generate session plots and save them to disk.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>dir</code>: the directory in which to save the plots</li>
<li><code>figsize</code>: the width and height (in inches) of each plot</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_sessions(self, dir = &#39;output&#39;, figsize = (8,8)):
        &#39;&#39;&#39;
        Generate session plots and save them to disk.

        __Parameters__

        + `dir`: the directory in which to save the plots
        + `figsize`: the width and height (in inches) of each plot
        &#39;&#39;&#39;
        if not os.path.exists(dir):
                os.makedirs(dir)

        for session in self.sessions:
                sp = self.plot_single_session(session, xylimits = &#39;constant&#39;)
                ppl.savefig(f&#39;{dir}/D{self._4x}_plot_{session}.pdf&#39;)
                ppl.close(sp.fig)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.plot_single_session"><code class="name flex">
<span>def <span class="ident">plot_single_session</span></span>(<span>self, session, kw_plot_anchors={'ls': 'None', 'marker': 'x', 'mec': (0.75, 0, 0), 'mew': 0.75, 'ms': 4}, kw_plot_unknowns={'ls': 'None', 'marker': 'x', 'mec': (0, 0, 0.75), 'mew': 0.75, 'ms': 4}, kw_plot_anchor_avg={'ls': '-', 'marker': 'None', 'color': (0.75, 0, 0), 'lw': 0.75}, kw_plot_unknown_avg={'ls': '-', 'marker': 'None', 'color': (0, 0, 0.75), 'lw': 0.75}, kw_contour_error={'colors': [[0, 0, 0]], 'alpha': 0.5, 'linewidths': 0.75}, xylimits='free', x_label=None, y_label=None, error_contour_interval='auto', fig='new')</span>
</code></dt>
<dd>
<div class="desc"><p>Generate plot for a single session</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_single_session(self,
        session,
        kw_plot_anchors = dict(ls=&#39;None&#39;, marker=&#39;x&#39;, mec=(.75, 0, 0), mew = .75, ms = 4),
        kw_plot_unknowns = dict(ls=&#39;None&#39;, marker=&#39;x&#39;, mec=(0, 0, .75), mew = .75, ms = 4),
        kw_plot_anchor_avg = dict(ls=&#39;-&#39;, marker=&#39;None&#39;, color=(.75, 0, 0), lw = .75),
        kw_plot_unknown_avg = dict(ls=&#39;-&#39;, marker=&#39;None&#39;, color=(0, 0, .75), lw = .75),
        kw_contour_error = dict(colors = [[0, 0, 0]], alpha = .5, linewidths = 0.75),
        xylimits = &#39;free&#39;, # | &#39;constant&#39;
        x_label = None,
        y_label = None,
        error_contour_interval = &#39;auto&#39;,
        fig = &#39;new&#39;,
        ):
        &#39;&#39;&#39;
        Generate plot for a single session
        &#39;&#39;&#39;
        if x_label is None:
                x_label = f&#39;δ$_{{{self._4x}}}$ (‰)&#39;
        if y_label is None:
                y_label = f&#39;Δ$_{{{self._4x}}}$ (‰)&#39;

        out = _SessionPlot()
        anchors = [a for a in self.anchors if [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == a]]
        unknowns = [u for u in self.unknowns if [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == u]]
        
        if fig == &#39;new&#39;:
                out.fig = ppl.figure(figsize = (6,6))
                ppl.subplots_adjust(.1,.1,.9,.9)

        out.anchor_analyses, = ppl.plot(
                [r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors],
                [r[f&#39;D{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors],
                **kw_plot_anchors)
        out.unknown_analyses, = ppl.plot(
                [r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns],
                [r[f&#39;D{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns],
                **kw_plot_unknowns)
        out.anchor_avg = ppl.plot(
                np.array([ np.array([
                        np.min([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) - 1,
                        np.max([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) + 1
                        ]) for sample in anchors]).T,
                np.array([ np.array([0, 0]) + self.Nominal_D4x[sample] for sample in anchors]).T,
                **kw_plot_anchor_avg)
        out.unknown_avg = ppl.plot(
                np.array([ np.array([
                        np.min([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) - 1,
                        np.max([r[f&#39;d{self._4x}&#39;] for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]) + 1
                        ]) for sample in unknowns]).T,
                np.array([ np.array([0, 0]) + self.unknowns[sample][f&#39;D{self._4x}&#39;] for sample in unknowns]).T,
                **kw_plot_unknown_avg)
        if xylimits == &#39;constant&#39;:
                x = [r[f&#39;d{self._4x}&#39;] for r in self]
                y = [r[f&#39;D{self._4x}&#39;] for r in self]
                x1, x2, y1, y2 = np.min(x), np.max(x), np.min(y), np.max(y)
                w, h = x2-x1, y2-y1
                x1 -= w/20
                x2 += w/20
                y1 -= h/20
                y2 += h/20
                ppl.axis([x1, x2, y1, y2])
        elif xylimits == &#39;free&#39;:
                x1, x2, y1, y2 = ppl.axis()
        else:
                x1, x2, y1, y2 = ppl.axis(xylimits)
                        
        if error_contour_interval != &#39;none&#39;:
                xi, yi = np.linspace(x1, x2), np.linspace(y1, y2)
                XI,YI = np.meshgrid(xi, yi)
                SI = np.array([[self.standardization_error(session, x, y) for x in xi] for y in yi])
                if error_contour_interval == &#39;auto&#39;:
                        rng = np.max(SI) - np.min(SI)
                        if rng &lt;= 0.01:
                                cinterval = 0.001
                        elif rng &lt;= 0.03:
                                cinterval = 0.004
                        elif rng &lt;= 0.1:
                                cinterval = 0.01
                        elif rng &lt;= 0.3:
                                cinterval = 0.03
                        elif rng &lt;= 1.:
                                cinterval = 0.1
                        else:
                                cinterval = 0.5
                else:
                        cinterval = error_contour_interval

                cval = np.arange(np.ceil(SI.min() / .001) * .001, np.ceil(SI.max() / .001 + 1) * .001, cinterval)
                out.contour = ppl.contour(XI, YI, SI, cval, **kw_contour_error)
                out.clabel = ppl.clabel(out.contour)

        ppl.xlabel(x_label)
        ppl.ylabel(y_label)
        ppl.title(session, weight = &#39;bold&#39;)
        ppl.grid(alpha = .2)
        out.ax = ppl.gca()              

        return out</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, filename, sep='', session='')</span>
</code></dt>
<dd>
<div class="desc"><p>Read file in csv format to load data into a <code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code> object.</p>
<p>In the csv file, spaces before and after field separators (<code>','</code> by default)
are optional. Each line corresponds to a single analysis.</p>
<p>The required fields are:</p>
<ul>
<li><code>UID</code>: a unique identifier</li>
<li><code>Session</code>: an identifier for the analytical session</li>
<li><code>Sample</code>: a sample identifier</li>
<li><code>d45</code>, <code>d46</code>, and at least one of <code>d47</code> or <code>d48</code>: the working-gas delta values</li>
</ul>
<p>Independently known oxygen-17 anomalies may be provided as <code>D17O</code> (in ‰ relative to
VSMOW, λ = <code>self.lambda_17</code>), and are otherwise assumed to be zero. Working-gas deltas <code>d47</code>, <code>d48</code>
and <code>d49</code> are optional, and set to NaN by default.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fileneme</code>: the path of the file to read</li>
<li><code>sep</code>: csv separator delimiting the fields</li>
<li><code>session</code>: set <code>Session</code> field to this string for all analyses</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, filename, sep = &#39;&#39;, session = &#39;&#39;):
        &#39;&#39;&#39;
        Read file in csv format to load data into a `D47data` object.

        In the csv file, spaces before and after field separators (`&#39;,&#39;` by default)
        are optional. Each line corresponds to a single analysis.

        The required fields are:

        + `UID`: a unique identifier
        + `Session`: an identifier for the analytical session
        + `Sample`: a sample identifier
        + `d45`, `d46`, and at least one of `d47` or `d48`: the working-gas delta values

        Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
        VSMOW, λ = `self.lambda_17`), and are otherwise assumed to be zero. Working-gas deltas `d47`, `d48`
        and `d49` are optional, and set to NaN by default.

        __Parameters__

        + `fileneme`: the path of the file to read
        + `sep`: csv separator delimiting the fields
        + `session`: set `Session` field to this string for all analyses
        &#39;&#39;&#39;
        with open(filename) as fid:
                self.input(fid.read(), sep = sep, session = session)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.refresh"><code class="name flex">
<span>def <span class="ident">refresh</span></span>(<span>self, session='mySession')</span>
</code></dt>
<dd>
<div class="desc"><p>Update <code>self.sessions</code>, <code>self.samples</code>, <code>self.anchors</code>, and <code>self.unknowns</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh(self, session = &#39;mySession&#39;):
        &#39;&#39;&#39;
        Update `self.sessions`, `self.samples`, `self.anchors`, and `self.unknowns`.
        &#39;&#39;&#39;
        self.fill_in_missing_info(session = session)
        self.refresh_sessions()
        self.refresh_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.refresh_samples"><code class="name flex">
<span>def <span class="ident">refresh_samples</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Define <code>self.samples</code>, <code>self.anchors</code>, and <code>self.unknowns</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh_samples(self):
        &#39;&#39;&#39;
        Define `self.samples`, `self.anchors`, and `self.unknowns`.
        &#39;&#39;&#39;
        self.samples = {
                s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                for s in sorted({r[&#39;Sample&#39;] for r in self})
                }
        self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D4x}
        self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D4x}</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.refresh_sessions"><code class="name flex">
<span>def <span class="ident">refresh_sessions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Update <code>self.sessions</code> and set <code>scrambling_drift</code>, <code>slope_drift</code>, and <code>wg_drift</code>
to <code>False</code> for all sessions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh_sessions(self):
        &#39;&#39;&#39;
        Update `self.sessions` and set `scrambling_drift`, `slope_drift`, and `wg_drift`
        to `False` for all sessions.
        &#39;&#39;&#39;
        self.sessions = {
                s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                for s in sorted({r[&#39;Session&#39;] for r in self})
                }
        for s in self.sessions:
                self.sessions[s][&#39;scrambling_drift&#39;] = False
                self.sessions[s][&#39;slope_drift&#39;] = False
                self.sessions[s][&#39;wg_drift&#39;] = False
                self.sessions[s][&#39;d13C_standardization_method&#39;] = self.d13C_STANDARDIZATION_METHOD
                self.sessions[s][&#39;d18O_standardization_method&#39;] = self.d18O_STANDARDIZATION_METHOD</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.repeatabilities"><code class="name flex">
<span>def <span class="ident">repeatabilities</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute analytical repeatabilities for δ<sup>13</sup>C<sub>VPDB</sub>,
δ<sup>18</sup>O<sub>VSMOW</sub>, Δ<sub>4x</sub> (for all samples, for anchors,
and for unknowns).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def repeatabilities(self):
        &#39;&#39;&#39;
        Compute analytical repeatabilities for δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt;,
        δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VSMOW&lt;/sub&gt;, Δ&lt;sub&gt;4x&lt;/sub&gt; (for all samples, for anchors,
        and for unknowns).
        &#39;&#39;&#39;
        self.msg(&#39;Computing reproducibilities for all sessions&#39;)

        self.repeatability[&#39;r_d13C_VPDB&#39;] = self.compute_r(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
        self.repeatability[&#39;r_d18O_VSMOW&#39;] = self.compute_r(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)
        self.repeatability[f&#39;r_D{self._4x}a&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;anchors&#39;)
        self.repeatability[f&#39;r_D{self._4x}u&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;unknowns&#39;)
        self.repeatability[f&#39;r_D{self._4x}&#39;] = self.compute_r(f&#39;D{self._4x}&#39;, samples = &#39;all samples&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.report"><code class="name flex">
<span>def <span class="ident">report</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Prints a report on the standardization fit.
Only applicable after <code>D4xdata.standardize(method='pooled')</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def report(self):
        &#39;&#39;&#39;
        Prints a report on the standardization fit.
        Only applicable after `D4xdata.standardize(method=&#39;pooled&#39;)`.
        &#39;&#39;&#39;
        report_fit(self.standardization)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.rmswd"><code class="name flex">
<span>def <span class="ident">rmswd</span></span>(<span>self, samples='all samples', sessions='all sessions')</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the χ<sup>2</sup>, root mean squared weighted deviation
(i.e. reduced χ<sup>2</sup>), and corresponding degrees of freedom of the
Δ<sub>4x</sub> values for samples in <code>samples</code> and sessions in <code>sessions</code>.</p>
<p>Only used in <code><a title="D47crunch.D4xdata.standardize" href="#D47crunch.D4xdata.standardize">D4xdata.standardize()</a></code> with <code>method='indep_sessions'</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def rmswd(self,
        samples = &#39;all samples&#39;,
        sessions = &#39;all sessions&#39;,
        ):
        &#39;&#39;&#39;
        Compute the χ&lt;sup&gt;2&lt;/sup&gt;, root mean squared weighted deviation
        (i.e. reduced χ&lt;sup&gt;2&lt;/sup&gt;), and corresponding degrees of freedom of the
        Δ&lt;sub&gt;4x&lt;/sub&gt; values for samples in `samples` and sessions in `sessions`.
        
        Only used in `D4xdata.standardize()` with `method=&#39;indep_sessions&#39;`.
        &#39;&#39;&#39;
        if samples == &#39;all samples&#39;:
                mysamples = [k for k in self.samples]
        elif samples == &#39;anchors&#39;:
                mysamples = [k for k in self.anchors]
        elif samples == &#39;unknowns&#39;:
                mysamples = [k for k in self.unknowns]
        else:
                mysamples = samples

        if sessions == &#39;all sessions&#39;:
                sessions = [k for k in self.sessions]

        chisq, Nf = 0, 0
        for sample in mysamples :
                G = [ r for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                if len(G) &gt; 1 :
                        X, sX = w_avg([r[f&#39;D{self._4x}&#39;] for r in G], [r[f&#39;wD{self._4x}&#39;] for r in G])
                        Nf += (len(G) - 1)
                        chisq += np.sum([ ((r[f&#39;D{self._4x}&#39;]-X)/r[f&#39;wD{self._4x}&#39;])**2 for r in G])
        r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
        self.msg(f&#39;RMSWD of r[&#34;D{self._4x}&#34;] is {r:.6f} for {samples}.&#39;)
        return {&#39;rmswd&#39;: r, &#39;chisq&#39;: chisq, &#39;Nf&#39;: Nf}</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.sample_D4x_correl"><code class="name flex">
<span>def <span class="ident">sample_D4x_correl</span></span>(<span>self, sample1, sample2=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Correlation between Δ<sub>4x</sub> errors of samples</p>
<p>Returns the error correlation between the average Δ4x values of two samples.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_D4x_correl(self, sample1, sample2 = None):
        &#39;&#39;&#39;
        Correlation between Δ&lt;sub&gt;4x&lt;/sub&gt; errors of samples

        Returns the error correlation between the average Δ4x values of two samples.
        &#39;&#39;&#39;
        if sample2 is None or sample2 == sample1:
                return 1.
        return (
                self.sample_D4x_covar(sample1, sample2)
                / self.unknowns[sample1][f&#39;SE_D{self._4x}&#39;]
                / self.unknowns[sample2][f&#39;SE_D{self._4x}&#39;]
                )</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.sample_D4x_covar"><code class="name flex">
<span>def <span class="ident">sample_D4x_covar</span></span>(<span>self, sample1, sample2=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Covariance between Δ<sub>4x</sub> values of samples</p>
<p>Returns the error covariance between the average Δ<sub>4x</sub> values of two
samples. If if only <code>sample_1</code> is specified, or if <code>sample_1 == sample_2</code>),
returns the Δ<sub>4x</sub> variance for that sample.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_D4x_covar(self, sample1, sample2 = None):
        &#39;&#39;&#39;
        Covariance between Δ&lt;sub&gt;4x&lt;/sub&gt; values of samples

        Returns the error covariance between the average Δ&lt;sub&gt;4x&lt;/sub&gt; values of two
        samples. If if only `sample_1` is specified, or if `sample_1 == sample_2`),
        returns the Δ&lt;sub&gt;4x&lt;/sub&gt; variance for that sample.
        &#39;&#39;&#39;
        if sample2 is None:
                sample2 = sample1
        if self.standardization_method == &#39;pooled&#39;:
                i = self.standardization.var_names.index(f&#39;D{self._4x}_{pf(sample1)}&#39;)
                j = self.standardization.var_names.index(f&#39;D{self._4x}_{pf(sample2)}&#39;)
                return self.standardization.covar[i, j]
        elif self.standardization_method == &#39;indep_sessions&#39;:
                if sample1 == sample2:
                        return self.samples[sample1][f&#39;SE_D{self._4x}&#39;]**2
                else:
                        c = 0
                        for session in self.sessions:
                                sdata1 = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample1]
                                sdata2 = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample2]
                                if sdata1 and sdata2:
                                        a = self.sessions[session][&#39;a&#39;]
                                        # !! TODO: CM below does not account for temporal changes in standardization parameters
                                        CM = self.sessions[session][&#39;CM&#39;][:3,:3]
                                        avg_D4x_1 = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata1])
                                        avg_d4x_1 = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata1])
                                        avg_D4x_2 = np.mean([r[f&#39;D{self._4x}&#39;] for r in sdata2])
                                        avg_d4x_2 = np.mean([r[f&#39;d{self._4x}&#39;] for r in sdata2])
                                        c += (
                                                self.unknowns[sample1][f&#39;session_D{self._4x}&#39;][session][2]
                                                * self.unknowns[sample2][f&#39;session_D{self._4x}&#39;][session][2]
                                                * np.array([[avg_D4x_1, avg_d4x_1, 1]])
                                                @ CM
                                                @ np.array([[avg_D4x_2, avg_d4x_2, 1]]).T
                                                ) / a**2
                        return float(c)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.sample_average"><code class="name flex">
<span>def <span class="ident">sample_average</span></span>(<span>self, samples, weights='equal', normalize=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Weighted average Δ<sub>4x</sub> value of a group of samples, accounting for covariance.</p>
<p>Returns the weighed average Δ<sub>4x</sub> value and associated SE
of a group of samples. Weights are equal by default. If <code>normalize</code> is
true, <code>weights</code> will be rescaled so that their sum equals 1.</p>
<p><strong>Examples</strong></p>
<pre><code class="language-python">self.sample_average(['X','Y'], [1, 2])
</code></pre>
<p>returns the value and SE of [Δ<sub>4x</sub>(X) + 2 Δ<sub>4x</sub>(Y)]/3,
where Δ<sub>4x</sub>(X) and Δ<sub>4x</sub>(Y) are the average Δ<sub>4x</sub>
values of samples X and Y, respectively.</p>
<pre><code class="language-python">self.sample_average(['X','Y'], [1, -1], normalize = False)
</code></pre>
<p>returns the value and SE of the difference Δ<sub>4x</sub>(X) - Δ<sub>4x</sub>(Y).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Weighted average Δ&lt;sub&gt;4x&lt;/sub&gt; value of a group of samples, accounting for covariance.

                Returns the weighed average Δ&lt;sub&gt;4x&lt;/sub&gt; value and associated SE
                of a group of samples. Weights are equal by default. If `normalize` is
                true, `weights` will be rescaled so that their sum equals 1.

                __Examples__

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])
                ```

                returns the value and SE of [Δ&lt;sub&gt;4x&lt;/sub&gt;(X) + 2 Δ&lt;sub&gt;4x&lt;/sub&gt;(Y)]/3,
                where Δ&lt;sub&gt;4x&lt;/sub&gt;(X) and Δ&lt;sub&gt;4x&lt;/sub&gt;(Y) are the average Δ&lt;sub&gt;4x&lt;/sub&gt;
                values of samples X and Y, respectively.

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                ```

                returns the value and SE of the difference Δ&lt;sub&gt;4x&lt;/sub&gt;(X) - Δ&lt;sub&gt;4x&lt;/sub&gt;(Y).
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        if s:
                                weights = [w/s for w in weights]

                try:
#                       indices = [self.standardization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.standardization.covar[indices,:][:,indices]
                        C = np.array([[self.sample_D4x_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][f&#39;D{self._4x}&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.simulate"><code class="name flex">
<span>def <span class="ident">simulate</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Legacy function with warning message pointing to <code><a title="D47crunch.virtual_data" href="#D47crunch.virtual_data">virtual_data()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate(self, *args, **kwargs):
        &#39;&#39;&#39;
        Legacy function with warning message pointing to `virtual_data()`
        &#39;&#39;&#39;
        raise DeprecationWarning(&#39;D4xdata.simulate is deprecated and has been replaced by virtual_data()&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.split_samples"><code class="name flex">
<span>def <span class="ident">split_samples</span></span>(<span>self, samples_to_split='all', grouping='by_session')</span>
</code></dt>
<dd>
<div class="desc"><p>Split unknown samples by UID (treat all analyses as different samples)
or by session (treat analyses of a given sample in different sessions as
different samples).</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>samples_to_split</code>: a list of samples to split, e.g., <code>['IAEA-C1', 'IAEA-C2']</code></li>
<li><code>grouping</code>: <code>by_uid</code> | <code>by_session</code></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_session&#39;):
        &#39;&#39;&#39;
        Split unknown samples by UID (treat all analyses as different samples)
        or by session (treat analyses of a given sample in different sessions as
        different samples).

        __Parameters__

        + `samples_to_split`: a list of samples to split, e.g., `[&#39;IAEA-C1&#39;, &#39;IAEA-C2&#39;]`
        + `grouping`: `by_uid` | `by_session`
        &#39;&#39;&#39;
        if samples_to_split == &#39;all&#39;:
                samples_to_split = [s for s in self.unknowns]
        gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
        self.grouping = grouping.lower()
        if self.grouping in gkeys:
                gkey = gkeys[self.grouping]
        for r in self:
                if r[&#39;Sample&#39;] in samples_to_split:
                        r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                        r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                elif r[&#39;Sample&#39;] in self.unknowns:
                        r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
        self.refresh_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.standardization_error"><code class="name flex">
<span>def <span class="ident">standardization_error</span></span>(<span>self, session, d4x, D4x, t=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute standardization error for a given session and
(δ<sub>47</sub>, Δ<sub>47</sub>) composition.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def standardization_error(self, session, d4x, D4x, t = 0):
                &#39;&#39;&#39;
                Compute standardization error for a given session and
                (δ&lt;sub&gt;47&lt;/sub&gt;, Δ&lt;sub&gt;47&lt;/sub&gt;) composition.
                &#39;&#39;&#39;
                a = self.sessions[session][&#39;a&#39;]
                b = self.sessions[session][&#39;b&#39;]
                c = self.sessions[session][&#39;c&#39;]
                a2 = self.sessions[session][&#39;a2&#39;]
                b2 = self.sessions[session][&#39;b2&#39;]
                c2 = self.sessions[session][&#39;c2&#39;]
                CM = self.sessions[session][&#39;CM&#39;]

                x, y = D4x, d4x
                z = a * x + b * y + c + a2 * x * t + b2 * y * t + c2 * t
#               x = (z - b*y - b2*y*t - c - c2*t) / (a+a2*t)
                dxdy = -(b+b2*t) / (a+a2*t)
                dxdz = 1. / (a+a2*t)
                dxda = -x / (a+a2*t)
                dxdb = -y / (a+a2*t)
                dxdc = -1. / (a+a2*t)
                dxda2 = -x * a2 / (a+a2*t)
                dxdb2 = -y * t / (a+a2*t)
                dxdc2 = -t / (a+a2*t)
                V = np.array([dxda, dxdb, dxdc, dxda2, dxdb2, dxdc2])
                sx = (V @ CM @ V.T) ** .5
                return sx</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.standardize"><code class="name flex">
<span>def <span class="ident">standardize</span></span>(<span>self, method='pooled', weighted_sessions=[], consolidate=True, consolidate_tables=False, consolidate_plots=False, constraints={})</span>
</code></dt>
<dd>
<div class="desc"><p>Compute absolute Δ<sub>4x</sub> values for all replicate analyses and for sample averages.
If <code>method</code> argument is set to <code>'pooled'</code>, the standardization processes all sessions
in a single step, assuming that all samples (anchors and unknowns alike) are
homogeneous, i.e. that their true Δ<sub>4x</sub> value does not change between sessions,
(<a href="https://doi.org/10.1029/2020GC009592">Daëron, 2021</a>).
If <code>method</code> argument is set to <code>'indep_sessions'</code>, the standardization processes each
session independently, based only on anchors analyses.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        @make_verbal
        def standardize(self,
                method = &#39;pooled&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = False,
                consolidate_plots = False,
                constraints = {},
                ):
                &#39;&#39;&#39;
                Compute absolute Δ&lt;sub&gt;4x&lt;/sub&gt; values for all replicate analyses and for sample averages.
                If `method` argument is set to `&#39;pooled&#39;`, the standardization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous, i.e. that their true Δ&lt;sub&gt;4x&lt;/sub&gt; value does not change between sessions,
                ([Daëron, 2021]).
                If `method` argument is set to `&#39;indep_sessions&#39;`, the standardization processes each
                session independently, based only on anchors analyses.
                
                [Daëron, 2021]: https://doi.org/10.1029/2020GC009592
                &#39;&#39;&#39;

                self.standardization_method = method
                self.assign_timestamps()

                if method == &#39;pooled&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D4xdata([r for r in self if r[&#39;Session&#39;] in session_group], mass = self._4x)
                                        X.Nominal_D4x = self.Nominal_D4x.copy()
                                        X.refresh()
                                        result = X.standardize(method = &#39;pooled&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.msg(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[f&#39;wD{self._4x}raw&#39;] *= w
                        else:
                                self.msg(f&#39;All D{self._4x}raw weights set to 1 ‰&#39;)
                                for r in self:
                                        r[f&#39;wD{self._4x}raw&#39;] = 1.

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.msg(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.msg(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.msg(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D{self._4x}_{pf(sample)}&#39;, value = 0.5)

                        for k in constraints:
                                params[k].expr = constraints[k]

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D4x:
                                                R += [ (
                                                        r[f&#39;D{self._4x}raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D4x[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D4x[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[f&#39;wD{self._4x}raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[f&#39;D{self._4x}raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D{self._4x}_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D{self._4x}_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[f&#39;d{self._4x}&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[f&#39;wD{self._4x}raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.least_squares()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[f&#39;D{self._4x}&#39;] = (r[f&#39;D{self._4x}raw&#39;] - c - b * r[f&#39;d{self._4x}&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[f&#39;d{self._4x}&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.standardization = result

                        for session in self.sessions:
                                self.sessions[session][&#39;Np&#39;] = 3
                                for k in [&#39;scrambling&#39;, &#39;slope&#39;, &#39;wg&#39;]:
                                        if self.sessions[session][f&#39;{k}_drift&#39;]:
                                                self.sessions[session][&#39;Np&#39;] += 1

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result


                elif method == &#39;indep_sessions&#39;:

                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D4xdata([r for r in self if r[&#39;Session&#39;] in session_group], mass = self._4x)
                                        X.Nominal_D4x = self.Nominal_D4x.copy()
                                        X.refresh()
                                        # This is only done to assign r[&#39;wD47raw&#39;] for r in X:
                                        X.standardize(method = method, weighted_sessions = [], consolidate = False)
                                        self.msg(f&#39;D{self._4x}raw weights set to {1000*X[0][f&#34;wD{self._4x}raw&#34;]:.1f} ppm for sessions in {session_group}&#39;)
                        else:
                                self.msg(&#39;All weights set to 1 ‰&#39;)
                                for r in self:
                                        r[f&#39;wD{self._4x}raw&#39;] = 1

                        for session in self.sessions:
                                s = self.sessions[session]
                                p_names = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;a2&#39;, &#39;b2&#39;, &#39;c2&#39;]
                                p_active = [True, True, True, s[&#39;scrambling_drift&#39;], s[&#39;slope_drift&#39;], s[&#39;wg_drift&#39;]]
                                s[&#39;Np&#39;] = sum(p_active)
                                sdata = s[&#39;data&#39;]

                                A = np.array([
                                        [
                                                self.Nominal_D4x[r[&#39;Sample&#39;]] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[f&#39;d{self._4x}&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                1 / r[f&#39;wD{self._4x}raw&#39;],
                                                self.Nominal_D4x[r[&#39;Sample&#39;]] * r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[f&#39;d{self._4x}&#39;] * r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;],
                                                r[&#39;t&#39;] / r[f&#39;wD{self._4x}raw&#39;]
                                                ]
                                        for r in sdata if r[&#39;Sample&#39;] in self.anchors
                                        ])[:,p_active] # only keep columns for the active parameters
                                Y = np.array([[r[f&#39;D{self._4x}raw&#39;] / r[f&#39;wD{self._4x}raw&#39;]] for r in sdata if r[&#39;Sample&#39;] in self.anchors])
                                s[&#39;Na&#39;] = Y.size
                                CM = linalg.inv(A.T @ A)
                                bf = (CM @ A.T @ Y).T[0,:]
                                k = 0
                                for n,a in zip(p_names, p_active):
                                        if a:
                                                s[n] = bf[k]
#                                               self.msg(f&#39;{n} = {bf[k]}&#39;)
                                                k += 1
                                        else:
                                                s[n] = 0.
#                                               self.msg(f&#39;{n} = 0.0&#39;)

                                for r in sdata :
                                        a, b, c, a2, b2, c2 = s[&#39;a&#39;], s[&#39;b&#39;], s[&#39;c&#39;], s[&#39;a2&#39;], s[&#39;b2&#39;], s[&#39;c2&#39;]
                                        r[f&#39;D{self._4x}&#39;] = (r[f&#39;D{self._4x}raw&#39;] - c - b * r[f&#39;d{self._4x}&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[f&#39;d{self._4x}&#39;]) / (a + a2 * r[&#39;t&#39;])
                                        r[f&#39;wD{self._4x}&#39;] = r[f&#39;wD{self._4x}raw&#39;] / (a + a2 * r[&#39;t&#39;])

                                s[&#39;CM&#39;] = np.zeros((6,6))
                                i = 0
                                k_active = [j for j,a in enumerate(p_active) if a]
                                for j,a in enumerate(p_active):
                                        if a:
                                                s[&#39;CM&#39;][j,k_active] = CM[i,:]
                                                i += 1

                        if not weighted_sessions:
                                w = self.rmswd()[&#39;rmswd&#39;]
                                for r in self:
                                                r[f&#39;wD{self._4x}&#39;] *= w
                                                r[f&#39;wD{self._4x}raw&#39;] *= w
                                for session in self.sessions:
                                        self.sessions[session][&#39;CM&#39;] *= w**2

                        for session in self.sessions:
                                s = self.sessions[session]
                                s[&#39;SE_a&#39;] = s[&#39;CM&#39;][0,0]**.5
                                s[&#39;SE_b&#39;] = s[&#39;CM&#39;][1,1]**.5
                                s[&#39;SE_c&#39;] = s[&#39;CM&#39;][2,2]**.5
                                s[&#39;SE_a2&#39;] = s[&#39;CM&#39;][3,3]**.5
                                s[&#39;SE_b2&#39;] = s[&#39;CM&#39;][4,4]**.5
                                s[&#39;SE_c2&#39;] = s[&#39;CM&#39;][5,5]**.5

                        if not weighted_sessions:
                                self.Nf = len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        else:
                                self.Nf = 0
                                for sg in weighted_sessions:
                                        self.Nf += self.rmswd(sessions = sg)[&#39;Nf&#39;]

                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)

                        avgD4x = {
                                sample: np.mean([r[f&#39;D{self._4x}&#39;] for r in self if r[&#39;Sample&#39;] == sample])
                                for sample in self.samples
                                }
                        chi2 = np.sum([(r[f&#39;D{self._4x}&#39;] - avgD4x[r[&#39;Sample&#39;]])**2 for r in self])
                        rD4x = (chi2/self.Nf)**.5
                        self.repeatability[f&#39;sigma_{self._4x}&#39;] = rD4x

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.standardize_d13C"><code class="name flex">
<span>def <span class="ident">standardize_d13C</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform δ<sup>13</sup>C standadization within each session <code>s</code> according to
<code>self.sessions[s]['d13C_standardization_method']</code>, which is defined by default
by <code><a title="D47crunch.D47data.refresh_sessions" href="#D47crunch.D4xdata.refresh_sessions">D4xdata.refresh_sessions()</a></code>as equal to <code>self.d13C_STANDARDIZATION_METHOD</code>, but
may be redefined abitrarily at a later stage.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def standardize_d13C(self):
        &#39;&#39;&#39;
        Perform δ&lt;sup&gt;13&lt;/sup&gt;C standadization within each session `s` according to
        `self.sessions[s][&#39;d13C_standardization_method&#39;]`, which is defined by default
        by `D47data.refresh_sessions()`as equal to `self.d13C_STANDARDIZATION_METHOD`, but
        may be redefined abitrarily at a later stage.
        &#39;&#39;&#39;
        for s in self.sessions:
                if self.sessions[s][&#39;d13C_standardization_method&#39;] in [&#39;1pt&#39;, &#39;2pt&#39;]:
                        XY = [(r[&#39;d13C_VPDB&#39;], self.Nominal_d13C_VPDB[r[&#39;Sample&#39;]]) for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in self.Nominal_d13C_VPDB]
                        X,Y = zip(*XY)
                        if self.sessions[s][&#39;d13C_standardization_method&#39;] == &#39;1pt&#39;:
                                offset = np.mean(Y) - np.mean(X)
                                for r in self.sessions[s][&#39;data&#39;]:
                                        r[&#39;d13C_VPDB&#39;] += offset                                
                        elif self.sessions[s][&#39;d13C_standardization_method&#39;] == &#39;2pt&#39;:
                                a,b = np.polyfit(X,Y,1)
                                for r in self.sessions[s][&#39;data&#39;]:
                                        r[&#39;d13C_VPDB&#39;] = a * r[&#39;d13C_VPDB&#39;] + b</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.standardize_d18O"><code class="name flex">
<span>def <span class="ident">standardize_d18O</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform δ<sup>18</sup>O standadization within each session <code>s</code> according to
<code>self.ALPHA_18O_ACID_REACTION</code> and <code>self.sessions[s]['d18O_standardization_method']</code>,
which is defined by default by <code><a title="D47crunch.D47data.refresh_sessions" href="#D47crunch.D4xdata.refresh_sessions">D4xdata.refresh_sessions()</a></code>as equal to
<code>self.d18O_STANDARDIZATION_METHOD</code>, but may be redefined abitrarily at a later stage.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def standardize_d18O(self):
        &#39;&#39;&#39;
        Perform δ&lt;sup&gt;18&lt;/sup&gt;O standadization within each session `s` according to
        `self.ALPHA_18O_ACID_REACTION` and `self.sessions[s][&#39;d18O_standardization_method&#39;]`,
        which is defined by default by `D47data.refresh_sessions()`as equal to
        `self.d18O_STANDARDIZATION_METHOD`, but may be redefined abitrarily at a later stage.
        &#39;&#39;&#39;
        for s in self.sessions:
                if self.sessions[s][&#39;d18O_standardization_method&#39;] in [&#39;1pt&#39;, &#39;2pt&#39;]:
                        XY = [(r[&#39;d18O_VSMOW&#39;], self.Nominal_d18O_VPDB[r[&#39;Sample&#39;]]) for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in self.Nominal_d18O_VPDB]
                        X,Y = zip(*XY)
                        Y = [(1000+y) * self.R18_VPDB * self.ALPHA_18O_ACID_REACTION / self.R18_VSMOW - 1000 for y in Y]
                        if self.sessions[s][&#39;d18O_standardization_method&#39;] == &#39;1pt&#39;:
                                offset = np.mean(Y) - np.mean(X)
                                for r in self.sessions[s][&#39;data&#39;]:
                                        r[&#39;d18O_VSMOW&#39;] += offset                               
                        elif self.sessions[s][&#39;d18O_standardization_method&#39;] == &#39;2pt&#39;:
                                a,b = np.polyfit(X,Y,1)
                                for r in self.sessions[s][&#39;data&#39;]:
                                        r[&#39;d18O_VSMOW&#39;] = a * r[&#39;d18O_VSMOW&#39;] + b</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.summary"><code class="name flex">
<span>def <span class="ident">summary</span></span>(<span>self, dir='output', filename=None, save_to_file=True, print_out=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Print out an/or save to disk a summary of the standardization results.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>dir</code>: the directory in which to save the table</li>
<li><code>filename</code>: the name to the csv file to write to</li>
<li><code>save_to_file</code>: whether to save the table to disk</li>
<li><code>print_out</code>: whether to print out the table</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def summary(self,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        ):
        &#39;&#39;&#39;
        Print out an/or save to disk a summary of the standardization results.

        __Parameters__

        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        &#39;&#39;&#39;

        out = []
        out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
        out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
        out += [[&#39;Repeatability of δ13C_VPDB&#39;, f&#34;{1000 * self.repeatability[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
        out += [[&#39;Repeatability of δ18O_VSMOW&#39;, f&#34;{1000 * self.repeatability[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
        out += [[f&#39;Repeatability of Δ{self._4x} (anchors)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}a&#39;]:.1f} ppm&#34;]]
        out += [[f&#39;Repeatability of Δ{self._4x} (unknowns)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}u&#39;]:.1f} ppm&#34;]]
        out += [[f&#39;Repeatability of Δ{self._4x} (all)&#39;, f&#34;{1000 * self.repeatability[f&#39;r_D{self._4x}&#39;]:.1f} ppm&#34;]]
        out += [[&#39;Model degrees of freedom&#39;, f&#34;{self.Nf}&#34;]]
        out += [[&#39;Student\&#39;s 95% t-factor&#39;, f&#34;{self.t95:.2f}&#34;]]
        out += [[&#39;Standardization method&#39;, self.standardization_method]]

        if save_to_file:
                if not os.path.exists(dir):
                        os.makedirs(dir)
                if filename is None:
                        filename = f&#39;D{self._4x}_summary.csv&#39;
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))
        if print_out:
                self.msg(&#39;\n&#39; + pretty_table(out, header = 0))</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.table_of_analyses"><code class="name flex">
<span>def <span class="ident">table_of_analyses</span></span>(<span>self, dir='output', filename=None, save_to_file=True, print_out=True, output=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print out an/or save to disk a table of analyses.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>dir</code>: the directory in which to save the table</li>
<li><code>filename</code>: the name to the csv file to write to</li>
<li><code>save_to_file</code>: whether to save the table to disk</li>
<li><code>print_out</code>: whether to print out the table</li>
<li><code>output</code>: if set to <code>'pretty'</code>: return a pretty text table (see <code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table()</a></code>);
if set to <code>'raw'</code>: return a list of list of strings
(e.g., <code>[['header1', 'header2'], ['0.1', '0.2']]</code>)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def table_of_analyses(
        self,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out an/or save to disk a table of analyses.

        __Parameters__

        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
            if set to `&#39;raw&#39;`: return a list of list of strings
            (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;

        out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
        extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
        for f in extra_fields:
                out[-1] += [f[0]]
        out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,f&#39;D{self._4x}&#39;]
        for r in self:
                out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                for f in extra_fields:
                        out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                out[-1] += [
                        f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                        f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                        f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;d13C_VPDB&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;d18O_VSMOW&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                        f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                        f&#34;{r[f&#39;D{self._4x}&#39;]:.6f}&#34;
                        ]
        if save_to_file:
                if not os.path.exists(dir):
                        os.makedirs(dir)
                if filename is None:
                        filename = f&#39;D{self._4x}_analyses.csv&#39;
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))
        if print_out:
                self.msg(&#39;\n&#39; + pretty_table(out))
        return out</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.table_of_samples"><code class="name flex">
<span>def <span class="ident">table_of_samples</span></span>(<span>self, dir='output', filename=None, save_to_file=True, print_out=True, output=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print out, save to disk and/or return a table of samples.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>dir</code>: the directory in which to save the table</li>
<li><code>filename</code>: the name to the csv file to write to</li>
<li><code>save_to_file</code>: whether to save the table to disk</li>
<li><code>print_out</code>: whether to print out the table</li>
<li><code>output</code>: if set to <code>'pretty'</code>: return a pretty text table (see <code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table()</a></code>);
if set to <code>'raw'</code>: return a list of list of strings
(e.g., <code>[['header1', 'header2'], ['0.1', '0.2']]</code>)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def table_of_samples(
        self,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out, save to disk and/or return a table of samples.

        __Parameters__

        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
            if set to `&#39;raw&#39;`: return a list of list of strings
            (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;

        out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,f&#39;D{self._4x}&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
        for sample in self.anchors:
                out += [[
                        f&#34;{sample}&#34;,
                        f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                        f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][f&#39;D{self._4x}&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                        f&#34;{self.samples[sample][f&#39;SD_D{self._4x}&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                        ]]
        for sample in self.unknowns:
                out += [[
                        f&#34;{sample}&#34;,
                        f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                        f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][f&#39;D{self._4x}&#39;]:.4f}&#34;,
                        f&#34;{self.samples[sample][f&#39;SE_D{self._4x}&#39;]:.4f}&#34;,
                        f&#34;± {self.samples[sample][f&#39;SE_D{self._4x}&#39;] * self.t95:.4f}&#34;,
                        f&#34;{self.samples[sample][f&#39;SD_D{self._4x}&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                        f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 2 else &#39;&#39;
                        ]]
        if save_to_file:
                if not os.path.exists(dir):
                        os.makedirs(dir)
                if filename is None:
                        filename = f&#39;D{self._4x}_samples.csv&#39;
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))
        if print_out:
                self.msg(&#39;\n&#39;+pretty_table(out))
        if output == &#39;raw&#39;:
                return out
        elif output == &#39;pretty&#39;:
                return pretty_table(out)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.table_of_sessions"><code class="name flex">
<span>def <span class="ident">table_of_sessions</span></span>(<span>self, dir='output', filename=None, save_to_file=True, print_out=True, output=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print out an/or save to disk a table of sessions.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>dir</code>: the directory in which to save the table</li>
<li><code>filename</code>: the name to the csv file to write to</li>
<li><code>save_to_file</code>: whether to save the table to disk</li>
<li><code>print_out</code>: whether to print out the table</li>
<li><code>output</code>: if set to <code>'pretty'</code>: return a pretty text table (see <code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table()</a></code>);
if set to <code>'raw'</code>: return a list of list of strings
(e.g., <code>[['header1', 'header2'], ['0.1', '0.2']]</code>)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@make_verbal
def table_of_sessions(self,
        dir = &#39;output&#39;,
        filename = None,
        save_to_file = True,
        print_out = True,
        output = None,
        ):
        &#39;&#39;&#39;
        Print out an/or save to disk a table of sessions.

        __Parameters__

        + `dir`: the directory in which to save the table
        + `filename`: the name to the csv file to write to
        + `save_to_file`: whether to save the table to disk
        + `print_out`: whether to print out the table
        + `output`: if set to `&#39;pretty&#39;`: return a pretty text table (see `pretty_table()`);
            if set to `&#39;raw&#39;`: return a list of list of strings
            (e.g., `[[&#39;header1&#39;, &#39;header2&#39;], [&#39;0.1&#39;, &#39;0.2&#39;]]`)
        &#39;&#39;&#39;
        include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
        include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
        include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])

        out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,f&#39;r_D{self._4x}&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
        if include_a2:
                out[-1] += [&#39;a2 ± SE&#39;]
        if include_b2:
                out[-1] += [&#39;b2 ± SE&#39;]
        if include_c2:
                out[-1] += [&#39;c2 ± SE&#39;]
        for session in self.sessions:
                out += [[
                        session,
                        f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                        f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                        f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][f&#39;r_D{self._4x}&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                        f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                        ]]
                if include_a2:
                        if self.sessions[session][&#39;scrambling_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]
                if include_b2:
                        if self.sessions[session][&#39;slope_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]
                if include_c2:
                        if self.sessions[session][&#39;wg_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]

        if save_to_file:
                if not os.path.exists(dir):
                        os.makedirs(dir)
                if filename is None:
                        filename = f&#39;D{self._4x}_sessions.csv&#39;
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))
        if print_out:
                self.msg(&#39;\n&#39; + pretty_table(out))
        if output == &#39;raw&#39;:
                return out
        elif output == &#39;pretty&#39;:
                return pretty_table(out)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.unsplit_samples"><code class="name flex">
<span>def <span class="ident">unsplit_samples</span></span>(<span>self, tables=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Reverse the effects of <code><a title="D47crunch.D47data.split_samples" href="#D47crunch.D4xdata.split_samples">D4xdata.split_samples()</a></code>.</p>
<p>This should only be used after <code><a title="D47crunch.D4xdata.standardize" href="#D47crunch.D4xdata.standardize">D4xdata.standardize()</a></code> with <code>method='pooled'</code>.</p>
<p>After <code><a title="D47crunch.D4xdata.standardize" href="#D47crunch.D4xdata.standardize">D4xdata.standardize()</a></code> with <code>method='indep_sessions'</code>, one should
probably use <code><a title="D47crunch.D4xdata.combine_samples" href="#D47crunch.D4xdata.combine_samples">D4xdata.combine_samples()</a></code> instead to reverse the effects of
<code><a title="D47crunch.D47data.split_samples" href="#D47crunch.D4xdata.split_samples">D4xdata.split_samples()</a></code> with <code>grouping='by_uid'</code>, or <code><a title="D47crunch.w_avg" href="#D47crunch.w_avg">w_avg()</a></code> to reverse the
effects of <code><a title="D47crunch.D47data.split_samples" href="#D47crunch.D4xdata.split_samples">D4xdata.split_samples()</a></code> with <code>grouping='by_sessions'</code> (because in
that case session-averaged Δ<sub>4x</sub> values are statistically independent).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unsplit_samples(self, tables = False):
        &#39;&#39;&#39;
        Reverse the effects of `D47data.split_samples()`.
        
        This should only be used after `D4xdata.standardize()` with `method=&#39;pooled&#39;`.
        
        After `D4xdata.standardize()` with `method=&#39;indep_sessions&#39;`, one should
        probably use `D4xdata.combine_samples()` instead to reverse the effects of
        `D47data.split_samples()` with `grouping=&#39;by_uid&#39;`, or `w_avg()` to reverse the
        effects of `D47data.split_samples()` with `grouping=&#39;by_sessions&#39;` (because in
        that case session-averaged Δ&lt;sub&gt;4x&lt;/sub&gt; values are statistically independent).
        &#39;&#39;&#39;
        unknowns_old = sorted({s for s in self.unknowns})
        CM_old = self.standardization.covar[:,:]
        VD_old = self.standardization.params.valuesdict().copy()
        vars_old = self.standardization.var_names

        unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})

        Ns = len(vars_old) - len(unknowns_old)
        vars_new = vars_old[:Ns] + [f&#39;D{self._4x}_{pf(u)}&#39; for u in unknowns_new]
        VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

        W = np.zeros((len(vars_new), len(vars_old)))
        W[:Ns,:Ns] = np.eye(Ns)
        for u in unknowns_new:
                splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                if self.grouping == &#39;by_session&#39;:
                        weights = [self.samples[s][f&#39;SE_D{self._4x}&#39;]**-2 for s in splits]
                elif self.grouping == &#39;by_uid&#39;:
                        weights = [1 for s in splits]
                sw = sum(weights)
                weights = [w/sw for w in weights]
                W[vars_new.index(f&#39;D{self._4x}_{pf(u)}&#39;),[vars_old.index(f&#39;D{self._4x}_{pf(s)}&#39;) for s in splits]] = weights[:]

        CM_new = W @ CM_old @ W.T
        V = W @ np.array([[VD_old[k]] for k in vars_old])
        VD_new = {k:v[0] for k,v in zip(vars_new, V)}

        self.standardization.covar = CM_new
        self.standardization.params.valuesdict = lambda : VD_new
        self.standardization.var_names = vars_new

        for r in self:
                if r[&#39;Sample&#39;] in self.unknowns:
                        r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                        r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]

        self.refresh_samples()
        self.consolidate_samples()
        self.repeatabilities()

        if tables:
                self.table_of_analyses()
                self.table_of_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.vmsg"><code class="name flex">
<span>def <span class="ident">vmsg</span></span>(<span>self, txt)</span>
</code></dt>
<dd>
<div class="desc"><p>Log a message to <code>self.logfile</code> and print it out</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vmsg(self, txt):
        &#39;&#39;&#39;
        Log a message to `self.logfile` and print it out
        &#39;&#39;&#39;
        self.log(txt)
        print(txt)</code></pre>
</details>
</dd>
<dt id="D47crunch.D4xdata.wg"><code class="name flex">
<span>def <span class="ident">wg</span></span>(<span>self, samples=None, a18_acid=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute bulk composition of the working gas for each session based on
the carbonate standards defined in both <code>self.Nominal_d13C_VPDB</code> and
<code>self.Nominal_d18O_VPDB</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        @make_verbal
        def wg(self, samples = None, a18_acid = None):
                &#39;&#39;&#39;
                Compute bulk composition of the working gas for each session based on
                the carbonate standards defined in both `self.Nominal_d13C_VPDB` and
                `self.Nominal_d18O_VPDB`.
                &#39;&#39;&#39;

                self.msg(&#39;Computing WG composition:&#39;)

                if a18_acid is None:
                        a18_acid = self.ALPHA_18O_ACID_REACTION
                if samples is None:
                        samples = [s for s in self.Nominal_d13C_VPDB if s in self.Nominal_d18O_VPDB]

                assert a18_acid, f&#39;Acid fractionation factor should not be zero.&#39;

                samples = [s for s in samples if s in self.Nominal_d13C_VPDB and s in self.Nominal_d18O_VPDB]
                R45R46_standards = {}
                for sample in samples:
                        d13C_vpdb = self.Nominal_d13C_VPDB[sample]
                        d18O_vpdb = self.Nominal_d18O_VPDB[sample]
                        R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
                        R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
                        R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

                        C12_s = 1 / (1 + R13_s)
                        C13_s = R13_s / (1 + R13_s)
                        C16_s = 1 / (1 + R17_s + R18_s)
                        C17_s = R17_s / (1 + R17_s + R18_s)
                        C18_s = R18_s / (1 + R17_s + R18_s)

                        C626_s = C12_s * C16_s ** 2
                        C627_s = 2 * C12_s * C16_s * C17_s
                        C628_s = 2 * C12_s * C16_s * C18_s
                        C636_s = C13_s * C16_s ** 2
                        C637_s = 2 * C13_s * C16_s * C17_s
                        C727_s = C12_s * C17_s ** 2

                        R45_s = (C627_s + C636_s) / C626_s
                        R46_s = (C628_s + C637_s + C727_s) / C626_s
                        R45R46_standards[sample] = (R45_s, R46_s)
                
                for s in self.sessions:
                        db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] in samples]
                        assert db, f&#39;No sample from {samples} found in session &#34;{s}&#34;.&#39;
#                       dbsamples = sorted({r[&#39;Sample&#39;] for r in db})

                        X = [r[&#39;d45&#39;] for r in db]
                        Y = [R45R46_standards[r[&#39;Sample&#39;]][0] for r in db]
                        x1, x2 = np.min(X), np.max(X)

                        if x1 &lt; x2:
                                wgcoord = x1/(x1-x2)
                        else:
                                wgcoord = 999

                        if wgcoord &lt; -.5 or wgcoord &gt; 1.5:
                                # unreasonable to extrapolate to d45 = 0
                                R45_wg = np.mean([y/(1+x/1000) for x,y in zip(X,Y)])
                        else :
                                # d45 = 0 is reasonably well bracketed
                                R45_wg = np.polyfit(X, Y, 1)[1]

                        X = [r[&#39;d46&#39;] for r in db]
                        Y = [R45R46_standards[r[&#39;Sample&#39;]][1] for r in db]
                        x1, x2 = np.min(X), np.max(X)

                        if x1 &lt; x2:
                                wgcoord = x1/(x1-x2)
                        else:
                                wgcoord = 999

                        if wgcoord &lt; -.5 or wgcoord &gt; 1.5:
                                # unreasonable to extrapolate to d46 = 0
                                R46_wg = np.mean([y/(1+x/1000) for x,y in zip(X,Y)])
                        else :
                                # d46 = 0 is reasonably well bracketed
                                R46_wg = np.polyfit(X, Y, 1)[1]

                        d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_delta(R45_wg, R46_wg)

                        self.msg(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                        self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                        for r in self.sessions[s][&#39;data&#39;]:
                                r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                                r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#1-tutorial">1. Tutorial</a></li>
<li><a href="#2-how-to">2. How-to</a><ul>
<li><a href="#21-use-a-different-set-of-anchors-change-anchor-nominal-values-andor-change-17o-correction-parameters">2.1 Use a different set of anchors, change anchor nominal values, and/or change 17O correction parameters</a></li>
<li><a href="#22-simulate-a-virtual-data-set-to-play-with">2.2 Simulate a virtual data set to play with</a></li>
<li><a href="#23-process-paired-47-and-48-values">2.3 Process paired Δ47 and Δ48 values</a></li>
</ul>
</li>
<li><a href="#3-discussion">3. Discussion</a></li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="D47crunch.correlated_sum" href="#D47crunch.correlated_sum">correlated_sum</a></code></li>
<li><code><a title="D47crunch.fCO2eqD47_Petersen" href="#D47crunch.fCO2eqD47_Petersen">fCO2eqD47_Petersen</a></code></li>
<li><code><a title="D47crunch.fCO2eqD47_Wang" href="#D47crunch.fCO2eqD47_Wang">fCO2eqD47_Wang</a></code></li>
<li><code><a title="D47crunch.make_csv" href="#D47crunch.make_csv">make_csv</a></code></li>
<li><code><a title="D47crunch.pf" href="#D47crunch.pf">pf</a></code></li>
<li><code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table</a></code></li>
<li><code><a title="D47crunch.read_csv" href="#D47crunch.read_csv">read_csv</a></code></li>
<li><code><a title="D47crunch.simulate_single_analysis" href="#D47crunch.simulate_single_analysis">simulate_single_analysis</a></code></li>
<li><code><a title="D47crunch.smart_type" href="#D47crunch.smart_type">smart_type</a></code></li>
<li><code><a title="D47crunch.table_of_analyses" href="#D47crunch.table_of_analyses">table_of_analyses</a></code></li>
<li><code><a title="D47crunch.table_of_samples" href="#D47crunch.table_of_samples">table_of_samples</a></code></li>
<li><code><a title="D47crunch.table_of_sessions" href="#D47crunch.table_of_sessions">table_of_sessions</a></code></li>
<li><code><a title="D47crunch.transpose_table" href="#D47crunch.transpose_table">transpose_table</a></code></li>
<li><code><a title="D47crunch.virtual_data" href="#D47crunch.virtual_data">virtual_data</a></code></li>
<li><code><a title="D47crunch.w_avg" href="#D47crunch.w_avg">w_avg</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code></h4>
<ul class="">
<li><code><a title="D47crunch.D47data.D47fromTeq" href="#D47crunch.D47data.D47fromTeq">D47fromTeq</a></code></li>
<li><code><a title="D47crunch.D47data.Nominal_D47" href="#D47crunch.D47data.Nominal_D47">Nominal_D47</a></code></li>
<li><code><a title="D47crunch.D47data.Nominal_D4x" href="#D47crunch.D47data.Nominal_D4x">Nominal_D4x</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="D47crunch.D48data" href="#D47crunch.D48data">D48data</a></code></h4>
<ul class="">
<li><code><a title="D47crunch.D48data.Nominal_D48" href="#D47crunch.D48data.Nominal_D48">Nominal_D48</a></code></li>
<li><code><a title="D47crunch.D48data.Nominal_D4x" href="#D47crunch.D48data.Nominal_D4x">Nominal_D4x</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="D47crunch.D4xdata" href="#D47crunch.D4xdata">D4xdata</a></code></h4>
<ul class="">
<li><code><a title="D47crunch.D4xdata.ALPHA_18O_ACID_REACTION" href="#D47crunch.D4xdata.ALPHA_18O_ACID_REACTION">ALPHA_18O_ACID_REACTION</a></code></li>
<li><code><a title="D47crunch.D4xdata.LEVENE_REF_SAMPLE" href="#D47crunch.D4xdata.LEVENE_REF_SAMPLE">LEVENE_REF_SAMPLE</a></code></li>
<li><code><a title="D47crunch.D4xdata.Nominal_d13C_VPDB" href="#D47crunch.D4xdata.Nominal_d13C_VPDB">Nominal_d13C_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.Nominal_d18O_VPDB" href="#D47crunch.D4xdata.Nominal_d18O_VPDB">Nominal_d18O_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R13_VPDB" href="#D47crunch.D4xdata.R13_VPDB">R13_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R17_VPDB" href="#D47crunch.D4xdata.R17_VPDB">R17_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R17_VSMOW" href="#D47crunch.D4xdata.R17_VSMOW">R17_VSMOW</a></code></li>
<li><code><a title="D47crunch.D4xdata.R18_VPDB" href="#D47crunch.D4xdata.R18_VPDB">R18_VPDB</a></code></li>
<li><code><a title="D47crunch.D4xdata.R18_VSMOW" href="#D47crunch.D4xdata.R18_VSMOW">R18_VSMOW</a></code></li>
<li><code><a title="D47crunch.D4xdata.assign_timestamps" href="#D47crunch.D4xdata.assign_timestamps">assign_timestamps</a></code></li>
<li><code><a title="D47crunch.D4xdata.combine_samples" href="#D47crunch.D4xdata.combine_samples">combine_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_bulk_and_clumping_deltas" href="#D47crunch.D4xdata.compute_bulk_and_clumping_deltas">compute_bulk_and_clumping_deltas</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_bulk_delta" href="#D47crunch.D4xdata.compute_bulk_delta">compute_bulk_delta</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_isobar_ratios" href="#D47crunch.D4xdata.compute_isobar_ratios">compute_isobar_ratios</a></code></li>
<li><code><a title="D47crunch.D4xdata.compute_r" href="#D47crunch.D4xdata.compute_r">compute_r</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate" href="#D47crunch.D4xdata.consolidate">consolidate</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate_samples" href="#D47crunch.D4xdata.consolidate_samples">consolidate_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.consolidate_sessions" href="#D47crunch.D4xdata.consolidate_sessions">consolidate_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.crunch" href="#D47crunch.D4xdata.crunch">crunch</a></code></li>
<li><code><a title="D47crunch.D4xdata.d13C_STANDARDIZATION_METHOD" href="#D47crunch.D4xdata.d13C_STANDARDIZATION_METHOD">d13C_STANDARDIZATION_METHOD</a></code></li>
<li><code><a title="D47crunch.D4xdata.d18O_STANDARDIZATION_METHOD" href="#D47crunch.D4xdata.d18O_STANDARDIZATION_METHOD">d18O_STANDARDIZATION_METHOD</a></code></li>
<li><code><a title="D47crunch.D4xdata.fill_in_missing_info" href="#D47crunch.D4xdata.fill_in_missing_info">fill_in_missing_info</a></code></li>
<li><code><a title="D47crunch.D4xdata.input" href="#D47crunch.D4xdata.input">input</a></code></li>
<li><code><a title="D47crunch.D4xdata.lambda_17" href="#D47crunch.D4xdata.lambda_17">lambda_17</a></code></li>
<li><code><a title="D47crunch.D4xdata.log" href="#D47crunch.D4xdata.log">log</a></code></li>
<li><code><a title="D47crunch.D4xdata.make_verbal" href="#D47crunch.D4xdata.make_verbal">make_verbal</a></code></li>
<li><code><a title="D47crunch.D4xdata.msg" href="#D47crunch.D4xdata.msg">msg</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_distribution_of_analyses" href="#D47crunch.D4xdata.plot_distribution_of_analyses">plot_distribution_of_analyses</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_residuals" href="#D47crunch.D4xdata.plot_residuals">plot_residuals</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_sessions" href="#D47crunch.D4xdata.plot_sessions">plot_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.plot_single_session" href="#D47crunch.D4xdata.plot_single_session">plot_single_session</a></code></li>
<li><code><a title="D47crunch.D4xdata.read" href="#D47crunch.D4xdata.read">read</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh" href="#D47crunch.D4xdata.refresh">refresh</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh_samples" href="#D47crunch.D4xdata.refresh_samples">refresh_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.refresh_sessions" href="#D47crunch.D4xdata.refresh_sessions">refresh_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.repeatabilities" href="#D47crunch.D4xdata.repeatabilities">repeatabilities</a></code></li>
<li><code><a title="D47crunch.D4xdata.report" href="#D47crunch.D4xdata.report">report</a></code></li>
<li><code><a title="D47crunch.D4xdata.rmswd" href="#D47crunch.D4xdata.rmswd">rmswd</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_D4x_correl" href="#D47crunch.D4xdata.sample_D4x_correl">sample_D4x_correl</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_D4x_covar" href="#D47crunch.D4xdata.sample_D4x_covar">sample_D4x_covar</a></code></li>
<li><code><a title="D47crunch.D4xdata.sample_average" href="#D47crunch.D4xdata.sample_average">sample_average</a></code></li>
<li><code><a title="D47crunch.D4xdata.simulate" href="#D47crunch.D4xdata.simulate">simulate</a></code></li>
<li><code><a title="D47crunch.D4xdata.split_samples" href="#D47crunch.D4xdata.split_samples">split_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardization_error" href="#D47crunch.D4xdata.standardization_error">standardization_error</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize" href="#D47crunch.D4xdata.standardize">standardize</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize_d13C" href="#D47crunch.D4xdata.standardize_d13C">standardize_d13C</a></code></li>
<li><code><a title="D47crunch.D4xdata.standardize_d18O" href="#D47crunch.D4xdata.standardize_d18O">standardize_d18O</a></code></li>
<li><code><a title="D47crunch.D4xdata.summary" href="#D47crunch.D4xdata.summary">summary</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_analyses" href="#D47crunch.D4xdata.table_of_analyses">table_of_analyses</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_samples" href="#D47crunch.D4xdata.table_of_samples">table_of_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.table_of_sessions" href="#D47crunch.D4xdata.table_of_sessions">table_of_sessions</a></code></li>
<li><code><a title="D47crunch.D4xdata.unsplit_samples" href="#D47crunch.D4xdata.unsplit_samples">unsplit_samples</a></code></li>
<li><code><a title="D47crunch.D4xdata.vmsg" href="#D47crunch.D4xdata.vmsg">vmsg</a></code></li>
<li><code><a title="D47crunch.D4xdata.wg" href="#D47crunch.D4xdata.wg">wg</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>