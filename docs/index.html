<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>D47crunch API documentation</title>
<meta name="description" content="Carbonate clumped-isotope data processing and error propagation …" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>D47crunch</code></h1>
</header>
<section id="section-intro">
<p>Carbonate clumped-isotope data processing and error propagation</p>
<p>This library is designed to process and standardize carbonate clumped-isotope
analyses, from low-level data out of a dual-inlet mass spectrometer to final,
“absolute” Δ47 values with fully propagated analytical error estimates.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#! /usr/bin/env python3
&#39;&#39;&#39;
Carbonate clumped-isotope data processing and error propagation

This library is designed to process and standardize carbonate clumped-isotope
analyses, from low-level data out of a dual-inlet mass spectrometer to final,
“absolute” Δ47 values with fully propagated analytical error estimates.
&#39;&#39;&#39;

__author__ = &#39;Mathieu Daëron&#39;
__contact__ = &#39;daeron@lsce.ipsl.fr&#39;
__copyright__ = &#39;Copyright (c) 2020 Mathieu Daëron&#39;
__license__ = &#39;Modified BSD License - https://opensource.org/licenses/BSD-3-Clause&#39;
__date__ = &#39;2020-02-08&#39;
__version__ = &#39;0.1&#39;


import os
import numpy as np
from statistics import stdev
from scipy.stats import t as tstudent
from scipy.stats import levene
from numpy import linalg
from lmfit import Minimizer, Parameters, report_fit
from matplotlib import pyplot as ppl
from matplotlib import rcParams

rcParams[&#39;font.family&#39;] = &#39;sans-serif&#39;
rcParams[&#39;font.sans-serif&#39;] = &#39;Helvetica&#39;
rcParams[&#39;font.size&#39;] = 10
rcParams[&#39;mathtext.fontset&#39;] = &#39;custom&#39;
rcParams[&#39;mathtext.rm&#39;] = &#39;sans&#39;
rcParams[&#39;mathtext.bf&#39;] = &#39;sans:bold&#39;
rcParams[&#39;mathtext.it&#39;] = &#39;sans:italic&#39;
rcParams[&#39;mathtext.cal&#39;] = &#39;sans:italic&#39;
rcParams[&#39;mathtext.default&#39;] = &#39;rm&#39;
rcParams[&#39;xtick.major.size&#39;] = 4
rcParams[&#39;xtick.major.width&#39;] = 1
rcParams[&#39;ytick.major.size&#39;] = 4
rcParams[&#39;ytick.major.width&#39;] = 1
rcParams[&#39;axes.grid&#39;] = False
rcParams[&#39;axes.linewidth&#39;] = 1
rcParams[&#39;grid.linewidth&#39;] = .75
rcParams[&#39;grid.linestyle&#39;] = &#39;-&#39;
rcParams[&#39;grid.alpha&#39;] = .15
rcParams[&#39;savefig.dpi&#39;] = 150


def smart_type(x):
        &#39;&#39;&#39;
        Tries to convert string `x` to a float if it includes a decimal point, or
        to an integer if it does not. If both attempts fail, return the original
        string unchanged.
        &#39;&#39;&#39;
        try:
                y = float(x)
        except ValueError:
                return x
        if &#39;.&#39; not in x:
                return int(y)
        return y


def pf(txt):
        &#39;&#39;&#39;
        Modify string `txt` to follow `lmfit.Parameter()` naming rules.
        &#39;&#39;&#39;
        return txt.replace(&#39;-&#39;,&#39;_&#39;).replace(&#39;.&#39;,&#39;_&#39;)


def pretty_table(x, header = 1, hsep = &#39;  &#39;, vsep = &#39;-&#39;):
        &#39;&#39;&#39;
        Reads a list of lists of strings and outputs an ascii table
        
        __Parameters__
        
        + `x`: a list of lists of strings
        + `header`: the number of lines to treat as header lines
        + `hsep`: the horizontal separator between columns
        + `vsep`: the character to use as vertical separator
        
        __Example__
        
        ```python
        x = [[&#39;A&#39;,&#39;B&#39;, &#39;C&#39;], [&#39;1&#39;, &#39;1.9999&#39;, &#39;foo&#39;], [&#39;10&#39;, &#39;x&#39;, &#39;bar&#39;]]
        print(pretty_table(x))
        ```
        
        output:

        ```python
        --  ------  ---
        A        B    C
        --  ------  ---
        1   1.9999  foo
        10       x  bar
        --  ------  ---
        ```
        &#39;&#39;&#39;
        txt = [&#39;&#39;]
        widths = [np.max([len(e) for e in c]) for c in zip(*x)]
        
        align = &#39;&lt;&#39; + &#39;&gt;&#39;*(len(widths)-1)
        sepline = hsep.join([vsep*w for w in widths])
        txt += [sepline]
        for k,l in enumerate(x):
                if k and k == header:
                        txt += [sepline]
                txt += [hsep.join([f&#39;{e:{a}{w}}&#39; for e, w, a in zip(l, widths, align)])]
        txt += [sepline]
        txt += [&#39;&#39;]
        return &#39;\n&#39;.join(txt)


def make_csv(x, hsep = &#39;,&#39;, vsep = &#39;\n&#39;):
        &#39;&#39;&#39;
        Formats a list of lists of strings as a CSV
        
        __Parameters__
        
        + `x`: the list of lists of strings to format
        + `hsep`: the field separator (a comma, by default)
        + `vsep`: the line-ending convention to use (`&#39;\\n&#39;` by default)
        
        __Example__
        
        ```python
        x = [[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [&#39;d&#39;, &#39;e&#39;, &#39;f&#39;]]
        print(make_csv(x))
        ```
        
        output:
        
        ```python
        a,b,c
        d,e,f
        ```
        &#39;&#39;&#39;
        return vsep.join([hsep.join(l) for l in x])


def transpose_table(x):
        &#39;&#39;&#39;
        Transpose a list if lists
        
        __Parameters__
        
        + `x`: a list of lists

        __Example__
        
        ```python
        x = [[1, 2], [3, 4]]
        print(transpose_table(x))
        ```
        
        outputs:
        
        ```python
        [[1, 3], [2, 4]]
        ```

        &#39;&#39;&#39;
        return [[e for e in c] for c in zip(*x)]


def correlated_sum(X,C,f = &#39;&#39;):
        &#39;&#39;&#39;
        Compute covariance-aware linear combinations
        
        Return the mean and SE of the sum of the elements of `X`, with optional
        weights corresponding to the elements of `f`, accounting for `C`,
        the covariance matrix of `X`.
        &#39;&#39;&#39;
        if f == &#39;&#39;:
                f = [1 for x in X]
        return np.dot(f,X), (np.dot(f,np.dot(C,f)))**.5


def w_avg(X, sX) :
        &#39;&#39;&#39;
        Compute variance-weighted average
        
        Returns the value and SE of the weighted average of the elements of `X`,
        with relative weights equal to their inverse variances (`1/sX**2`).
        
        __Parameters__
        
        + `X`: array-like of elements to average
        + `sX`: array-like of the corresponding SE values

        __Tip__

        If `X` and `sX` are initially arranged as a list of `(x, sx)` doublets,
        they may be rearranged using `zip()`:
        
        ```python
        foo = [(0, 0.1), (1, 0.05), (2, 0.05)]
        print(w_avg(*zip(*foo)))
        
        # output:
        # (1.3333333333333333, 0.03333333333333334)
        ```
        &#39;&#39;&#39;
        X = [ x for x in X ]
        sX = [ sx for sx in sX ]
        W = [ sx**-2 for sx in sX ]
        W = [ w/sum(W) for w in W ]
        Xavg = sum([ w*x for w,x in zip(W,X) ])
        sXavg = sum([ w**2*sx**2 for w,sx in zip(W,sX) ])**.5
        return Xavg, sXavg


class D47data(list):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ&lt;sub&gt;47&lt;/sub&gt; analyses,
        usually comprising more than one analytical session.
        &#39;&#39;&#39;

        ### 17O CORRECTION PARAMETERS
        R13_VPDB = 0.01118  # (Chang &amp; Li, 1990)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;13&lt;/sup&gt;C/&lt;sup&gt;12&lt;/sup&gt;C) ratio of VPDB.
        By default equal to 0.01118 ([Chang &amp; Li, 1990])
        
        [Chang &amp; Li, 1990]: http://www.cnki.com.cn/Article/CJFDTotal-JXTW199004006.htm
        &#39;&#39;&#39;
        
        R18_VSMOW = 0.0020052  # (Baertschi, 1976)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VSMOW.
        By default equal to 0.0020052 ([Baertschi, 1976])
        
        [Baertschi, 1976]: https://doi.org/10.1016/0012-821X(76)90115-1
        &#39;&#39;&#39;

        lambda_17 = 0.528  # (Barkan &amp; Luz, 2005)
        &#39;&#39;&#39;
        Mass-dependent exponent for triple oxygen isotopes.
        By default equal to 0.528 ([Barkan &amp; Luz, 2005])
        
        [Barkan &amp; Luz, 2005]: https://doi.org/10.1002/rcm.2250
        &#39;&#39;&#39;

        R17_VSMOW = 0.00038475  # (Assonov &amp; Brenninkmeijer, 2003, rescaled to R13_VPDB)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;17&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VSMOW.
        By default equal to 0.00038475 ([Daëron et al., 2016])
        
        [Daëron et al., 2016]: https://dx.doi.org/10.1016/j.chemgeo.2016.08.014
        &#39;&#39;&#39;

        R18_VPDB = R18_VSMOW * 1.03092
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VPDB.
        By definition equal to `R18_VSMOW * 1.03092`.
        &#39;&#39;&#39;

        R17_VPDB = R17_VSMOW * 1.03092 ** lambda_17
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;17&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VPDB.
        By definition equal to `R17_VSMOW * 1.03092 ** lambda_17`.
        &#39;&#39;&#39;

        LEVENE_REF_SAMPLE = &#39;ETH-3&#39;
        &#39;&#39;&#39;
        After the Δ&lt;sub&gt;47&lt;/sub&gt; standardization step, each sample is tested to
        assess whether the Δ&lt;sub&gt;47&lt;/sub&gt; variance within all analyses for that
        sample is significantly larger than that observed for a given reference
        sample (using [Levene&#39;s test], which yields a p-value corresponding to
        the null hypothesis that the underlying variances are equal).
        
        `LEVENE_REF_SAMPLE` (by default equal to `&#39;ETH-3&#39;`) specifies which
        sample should be used as a reference for this test.
        
        [Levene&#39;s test]: https://en.wikipedia.org/wiki/Levene%27s_test
        &#39;&#39;&#39;
        
        SAMPLE_CONSTRAINING_WG_COMPOSITION = (&#39;ETH-3&#39;, 1.71, -1.78) # (Bernasconi et al., 2018)
        &#39;&#39;&#39;
        specifies the name, δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; and δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VPDB&lt;/sub&gt;
        of the carbonate standard used by `D47data.wg()` to compute the isotopic composition
        of the working gas in each session.
        
        By default equal to `(&#39;ETH-3&#39;, 1.71, -1.78)` after [Bernasconi et al. (2018)].
        
        [Bernasconi et al. (2018)]: https://doi.org/10.1029/2017GC007385
        &#39;&#39;&#39;
        
        ALPHA_18O_ACID_REACTION = np.exp(3.59 / (90 + 273.15) - 1.79e-3)  # (Kim et al., 2007, calcite)
        &#39;&#39;&#39;
        specifies the &lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;O fractionation factor generally applicable
        to acid reactions in the dataset. Currently only used by `self.wg()`.
        
        By default equal to 1.00813 (calcite reacted at 90 °C, [Kim et al., 2007]).
        
        [Kim et al., 2007]: https://dx.doi.org/10.1016/j.chemgeo.2007.08.005
        &#39;&#39;&#39;

        Nominal_D47 = {
                &#39;ETH-1&#39;: 0.258,
                &#39;ETH-2&#39;: 0.256,
                &#39;ETH-3&#39;: 0.691,
                }       # (Bernasconi et al., 2018)
        &#39;&#39;&#39;
        Nominal Δ&lt;sub&gt;47&lt;/sub&gt; values assigned to the anchor samples, used in particular by
        `self.normalize()` to standardize unknown samples to a carbonate Δ&lt;sub&gt;47&lt;/sub&gt;
        reference frame.
        
        By default equal to `{&#39;ETH-1&#39;: 0.258, &#39;ETH-2&#39;: 0.256, &#39;ETH-3&#39;: 0.691}` after
        [Bernasconi et al. (2018)].
        
        [Bernasconi et al. (2018)]: https://doi.org/10.1029/2017GC007385
        &#39;&#39;&#39;


        def __init__(self, l = [], verbose = False, msgcolor = &#39;\033[92m&#39;):
                &#39;&#39;&#39;
                _Parameters_
                
                + `l`: a list of dictionaries, with each element including at least the keys
                `UID`, `Session`, `Sample`, `d45`, `d46`, and `d47`.
                + `verbose`: if `True`, print out additional information when calling `D47data`
                methods.
                + `msgcolor`: terminal color used when printing out verbose information
                (light green by default).
                
                _Returns_ a `D47data` object derived from `list`.
                &#39;&#39;&#39;
                self.verbose = verbose
                self.msgcolor = msgcolor
                list.__init__(self, l)
                self.Nf = None
                self.repro = {}
                self.refresh()


        def vprint(self, txt):
                &#39;&#39;&#39;
                Print verbose message `txt` to screen if `self.verbose == True`.
                &#39;&#39;&#39;
                if self.verbose:
                        print(f&#39;{self.msgcolor}[D47data]   {txt}\033[0m&#39;)


        def refresh(self):
                &#39;&#39;&#39;
                Update `self.sessions`, `self.samples`, `self.anchors`, and `self.unknowns`.
                &#39;&#39;&#39;
                self.refresh_sessions()
                self.refresh_samples()


        def refresh_sessions(self):
                &#39;&#39;&#39;
                Update `self.sessions` and set `scrambling_drift`, `slope_drift`, and `wg_drift`
                to `False` for all sessions.
                &#39;&#39;&#39;
                self.sessions = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                        for s in sorted({r[&#39;Session&#39;] for r in self})
                        }
                for s in self.sessions:
                        self.sessions[s][&#39;scrambling_drift&#39;] = False
                        self.sessions[s][&#39;slope_drift&#39;] = False
                        self.sessions[s][&#39;wg_drift&#39;] = False


        def refresh_samples(self):
                &#39;&#39;&#39;
                Define `self.samples`, `self.anchors`, and `self.unknowns`.
                &#39;&#39;&#39;
                self.samples = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                        for s in sorted({r[&#39;Sample&#39;] for r in self})
                        }
                self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D47}
                self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D47}


        def read(self, filename, sep = &#39;,&#39;):
                &#39;&#39;&#39;
                Read file in csv format to load data into a `D47data` object.
                
                In the csv file, spaces befor and after field separators (`&#39;,&#39;` by default)
                are optional. Each line corresponds to a single analysis.
                
                The required fields are:
                
                + `UID`: a unique identifier
                + `Session`: an identifier for the analytical session
                + `Sample`: a sample identifier
                + `d45`, `d46`, `d47`: the working-gas delta values

                Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
                VSMOW, λ = 0.528), and are otherwise assumed to be zero. Working-gas deltas `d48`
                and `d49` may also be provided, and are also set to 0 otherwise.
                
                __Parameters__
                
                + `fileneme`: the path of the file to read
                + `sep`: csv separator delimiting the fields
                &#39;&#39;&#39;
                with open(filename) as fid:
                        self.input(fid.read(), sep = sep)


        def input(self, txt, sep = &#39;,&#39;):
                &#39;&#39;&#39;
                Read `txt` string in csv format to load analysis data into a `D47data` object.

                In the csv string, spaces befor and after field separators (`&#39;,&#39;` by default)
                are optional. Each line corresponds to a single analysis.
                
                The required fields are:
                
                + `UID`: a unique identifier
                + `Session`: an identifier for the analytical session
                + `Sample`: a sample identifier
                + `d45`, `d46`, `d47`: the working-gas delta values

                Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
                VSMOW, λ = 0.528), and are otherwise assumed to be zero. Working-gas deltas `d48`
                and `d49` may also be provided, and are also set to 0 otherwise.
                
                __Parameters__
                
                + `txt`: the csv string to read
                + `sep`: csv separator delimiting the fields
                &#39;&#39;&#39;
                txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
                data = [{k: smart_type(v) for k,v in zip(txt[0], l)} for l in txt[1:]]
                self += data
                self.refresh()


        def wg(self, sample = &#39;&#39;, d13C_vpdb = &#39;&#39;, d18O_vpdb = &#39;&#39;, a18_acid = &#39;&#39;):
                &#39;&#39;&#39;
                Compute bulk composition of the working gas for each session
                based on the average composition, within each session,
                of a given sample.
                &#39;&#39;&#39;

                self.vprint(f&#34;Computing working gas composition:&#34;)

                if sample == &#39;&#39;:
                        sample = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[0]
                if d13C_vpdb == &#39;&#39;:
                        d13C_vpdb = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[1]
                if d18O_vpdb == &#39;&#39;:
                        d18O_vpdb = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[2]
                if a18_acid == &#39;&#39;:
                        a18_acid = self.ALPHA_18O_ACID_REACTION

                R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
                R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
                R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

                C12_s = 1 / (1 + R13_s)
                C13_s = R13_s / (1 + R13_s)
                C16_s = 1 / (1 + R17_s + R18_s)
                C17_s = R17_s / (1 + R17_s + R18_s)
                C18_s = R18_s / (1 + R17_s + R18_s)

                C626_s = C12_s * C16_s ** 2
                C627_s = 2 * C12_s * C16_s * C17_s
                C628_s = 2 * C12_s * C16_s * C18_s
                C636_s = C13_s * C16_s ** 2
                C637_s = 2 * C13_s * C16_s * C17_s
                C727_s = C12_s * C17_s ** 2

                R45_s = (C627_s + C636_s) / C626_s
                R46_s = (C628_s + C637_s + C727_s) / C626_s

                for s in self.sessions:
                        db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                        d45_s = np.mean([r[&#39;d45&#39;] for r in db])
                        d46_s = np.mean([r[&#39;d46&#39;] for r in db])
                        R45_wg = R45_s / (1 + d45_s / 1000)
                        R46_wg = R46_s / (1 + d46_s / 1000)

                        d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_deltas(R45_wg, R46_wg)

                        self.vprint(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                        self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                        for r in self.sessions[s][&#39;data&#39;]:
                                r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                                r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW


        def compute_bulk_deltas(self, R45, R46, D17O = 0):
                &#39;&#39;&#39;
                Compute δ13C_VPDB and δ18O_VSMOW, by solving the generalized form of equation (17)
                from Brand et al. (2010), assuming that d18O_VSMOW is not too big ( 0 ± 50 ‰) and
                solving the corresponding second-order Taylor polynomial.
                (Appendix A, Daëron et al., 2016, &lt;https://doi.org/10.1016/j.chemgeo.2016.08.014&gt;)
                &#39;&#39;&#39;

                K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

                A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
                B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
                C = 2 * self.R18_VSMOW
                D = -R46

                aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
                bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
                cc = A + B + C + D

                d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

                R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
                R17 = K * R18 ** self.lambda_17
                R13 = R45 - 2 * R17

                d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

                return d13C_VPDB, d18O_VSMOW


        def crunch(self):
                &#39;&#39;&#39;
                Compute bulk composition and raw clumped isotope anomalies for all analyses.
                &#39;&#39;&#39;
                for i,r in enumerate(self):
                        for k in [&#39;D17O&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                                if k not in r:
                                        r[k] = 0.
                        self.compute_bulk_and_clumping_deltas(r)
                self.vprint(f&#34;Crunched {len(self)} analyses.&#34;)


        def compute_bulk_and_clumping_deltas(self, r):
                &#39;&#39;&#39;
                Compute δ13C_VPDB, δ18O_VSMOW, and raw Δ47, Δ48, Δ49 values for an analysis.
                &#39;&#39;&#39;

                # Compute working gas R13, R18, and isobar ratios
                R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
                R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
                R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

                # Compute analyte isobar ratios
                R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
                R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
                R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
                R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
                R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

                r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_deltas(R45, R46, D17O = r[&#39;D17O&#39;])
                R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
                R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

                # Compute stochastic isobar ratios of the analyte
                R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                        R13, R18, D17O = r[&#39;D17O&#39;]
                )

                # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
                # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
                if (R45 / R45stoch - 1) &gt; 5e-8:
                        self.vprint(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):%.3f} ppm&#39;)
                if (R46 / R46stoch - 1) &gt; 5e-8:
                        self.vprint(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):%.3f} ppm&#39;)

                # Compute raw clumped isotope anomalies
                r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
                r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
                r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)

        def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
                &#39;&#39;&#39;
                Compute isobar ratios for a sample with isotopic ratios R13 and R18,
                optionally accounting for non-zero values of Δ17O and clumped isotope
                anomalies, all expressed in permil.
                &#39;&#39;&#39;

                # Compute R17
                R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

                # Compute isotope concentrations
                C12 = (1 + R13) ** -1
                C13 = C12 * R13
                C16 = (1 + R17 + R18) ** -1
                C17 = C16 * R17
                C18 = C16 * R18

                # Compute stochastic isotopologue concentrations
                C626 = C16 * C12 * C16
                C627 = C16 * C12 * C17 * 2
                C628 = C16 * C12 * C18 * 2
                C636 = C16 * C13 * C16
                C637 = C16 * C13 * C17 * 2
                C638 = C16 * C13 * C18 * 2
                C727 = C17 * C12 * C17
                C728 = C17 * C12 * C18 * 2
                C737 = C17 * C13 * C17
                C738 = C17 * C13 * C18 * 2
                C828 = C18 * C12 * C18
                C838 = C18 * C13 * C18

                # Compute stochastic isobar ratios
                R45 = (C636 + C627) / C626
                R46 = (C628 + C637 + C727) / C626
                R47 = (C638 + C728 + C737) / C626
                R48 = (C738 + C828) / C626
                R49 = C838 / C626

                # Account for stochastic anomalies
                R47 *= 1 + D47 / 1000
                R48 *= 1 + D48 / 1000
                R49 *= 1 + D49 / 1000

                # Return isobar ratios
                return R45, R46, R47, R48, R49

        def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_uid&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if samples_to_split == &#39;all&#39;:
                        samples_to_split = [s for s in self.unknowns]
                gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
                self.grouping = grouping.lower()
                if self.grouping in gkeys:
                        gkey = gkeys[self.grouping]
                for r in self:
                        if r[&#39;Sample&#39;] in samples_to_split:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                        elif r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                self.refresh_samples()


        def unsplit_samples(self, tables = True):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                unknowns_old = sorted({s for s in self.unknowns})
                CM_old = self.normalization.covar[:,:]
                VD_old = self.normalization.params.valuesdict().copy()
                vars_old = self.normalization.var_names

                unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})
                
                Ns = len(vars_old) - len(unknowns_old)
                vars_new = vars_old[:Ns] + [f&#39;D47_{pf(u)}&#39; for u in unknowns_new]
                VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

                W = np.zeros((len(vars_new), len(vars_old)))
                W[:Ns,:Ns] = np.eye(Ns)
                for u in unknowns_new:
                        splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                        if self.grouping == &#39;by_session&#39;:
                                weights = [self.samples[s][&#39;SE_D47&#39;]**-2 for s in splits]
                        elif self.grouping == &#39;by_uid&#39;:
                                weights = [1 for s in splits]
                        sw = sum(weights)
                        weights = [w/sw for w in weights]
                        W[vars_new.index(f&#39;D47_{pf(u)}&#39;),[vars_old.index(f&#39;D47_{pf(s)}&#39;) for s in splits]] = weights[:]
#               print(&#39;\nUnsplitting weights matrix:&#39;)
#               print(&#39;\n&#39;.join([&#39; &#39;.join([f&#39;{x:.1f}&#39; if x else &#39; - &#39; for x in l]) for l in W]))
#               print(&#39;---&#39;)

                CM_new = W @ CM_old @ W.T
                V = W @ np.array([[VD_old[k]] for k in vars_old])
                VD_new = {k:v[0] for k,v in zip(vars_new, V)}
                
                self.normalization.covar = CM_new
                self.normalization.params.valuesdict = lambda : VD_new
                self.normalization.var_names = vars_new

                for r in self:
                        if r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]
                
                self.refresh_samples()
                self.consolidate_samples()
                self.consolidate_repro()

                if tables:
                        self.table_of_analyses()
                        self.table_of_samples()


        def assign_timestamps(self):
                &#39;&#39;&#39;
                Assign a time field `t` to each analysis.
                
                If `TimeTag` is one of the data fields, `t` is equal within a given session
                to `TimeTag` minus the mean value of `TimeTag` for that session.
                Otherwise, `TimeTag` is by default equal to the index of each analysis
                in the dataset and `t` is defined as above.
                &#39;&#39;&#39;
                for session in self.sessions:
                        sdata = self.sessions[session][&#39;data&#39;]
                        try:
                                t0 = np.mean([r[&#39;TimeTag&#39;] for r in sdata])
                                for r in sdata:
                                        r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
                        except KeyError:
                                t0 = (len(sdata)-1)/2
                                for t,r in enumerate(sdata):
                                        r[&#39;t&#39;] = t - t0


        def normalize(self,
                method = &#39;integrated_fit&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = True,
                consolidate_plots = True,
                ):
                &#39;&#39;&#39;
                Compute absolute Δ47 values for all replicate analyses and for sample averages.
                If `method` argument is set to `&#39;integrated_fit&#39;`, the normalization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous (i.e. that their true Δ&lt;sub&gt;47&lt;/sub&gt; value does not change between sessions).
                If `method` argument is set to `&#39;independent_sessions&#39;`, the normalization processes each
                session independently, based only on anchors analyses.
                &#39;&#39;&#39;

                self.normalization_method = method
                self.assign_timestamps()

                if method == &#39;integrated_fit&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D47data([r for r in self if r[&#39;Session&#39;] in session_group], verbose = self.verbose)
                                        result = X.normalize(method = &#39;integrated_fit&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.vprint(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[&#39;wD47raw&#39;] *= w
                        else:
                                self.vprint(&#39;All weights set to 1 ppm&#39;)
                                for r in self:
                                        r[&#39;wD47raw&#39;] = 0.001

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.vprint(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D47_{pf(sample)}&#39;, value=0.6)

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D47:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.leastsq()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[&#39;D47&#39;] = (r[&#39;D47raw&#39;] - c - b * r[&#39;d47&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[&#39;d47&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.normalization = result
                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result

                elif method == &#39;independent_sessions&#39;:
                        for session in self.sessions:
                                self.sessions[session][&#39;Np&#39;] = 3
                                self.vprint(&#39;&#39;)
                                self.vprint(f&#39;Standardizing session {session}.&#39;)
                                sdata = self.sessions[session][&#39;data&#39;]
                                A = np.array([
                                        [self.Nominal_D47[r[&#39;Sample&#39;]], r[&#39;d47&#39;], 1]
                                        for r in sdata if r[&#39;Sample&#39;] in self.anchors
                                        ])
                                Y = np.array([[r[&#39;D47raw&#39;]] for r in sdata if r[&#39;Sample&#39;] in self.anchors])
                                self.sessions[session][&#39;Na&#39;] = Y.size
                                CM = linalg.inv(A.T @ A)
                                a,b,c = (CM @ A.T @ Y).T[0,:3]

                                self.vprint(f&#39;a = {a:.4f}&#39;)
                                self.vprint(f&#39;b = {b:.2e}&#39;)
                                self.vprint(f&#39;c = {c:.4f}&#39;)
                                self.sessions[session][&#39;a&#39;] = a
                                self.sessions[session][&#39;b&#39;] = b
                                self.sessions[session][&#39;c&#39;] = c
                                self.sessions[session][&#39;CM&#39;] = CM.copy()

                                for r in sdata :
                                        r[&#39;D47&#39;] = ( r[&#39;D47raw&#39;] - b * r[&#39;d47&#39;] - c ) / a
                        
                        Nss = len(self.sessions)
                        Na = len(self)
                        Ns = len(self.samples)
                        Nu = len(self.unknowns)
                        avgD47 = {
                                sample: np.mean([r[&#39;D47&#39;] for r in self if r[&#39;Sample&#39;] == sample])
                                for sample in self.samples
                                }
                        chi2 = np.sum([(r[&#39;D47&#39;] - avgD47[r[&#39;Sample&#39;]])**2 for r in self])
                        rD47 = (chi2/(Na-Nu-3*Nss))**.5
                        self.repro[&#39;sigma_47&#39;] = rD47

                        for session in self.sessions:
                                self.sessions[session][&#39;CM&#39;] *= a**2 * chi2 / (Na-Nu-3*Nss)
                                self.sessions[session][&#39;SE_a&#39;] = self.sessions[session][&#39;CM&#39;][0,0]**.5
                                self.sessions[session][&#39;SE_b&#39;] = self.sessions[session][&#39;CM&#39;][1,1]**.5
                                self.sessions[session][&#39;SE_c&#39;] = self.sessions[session][&#39;CM&#39;][2,2]**.5
                        
#                       self.Nf = np.sum([self.sessions[s][&#39;Na&#39;] - self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        self.Nf = len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)


        def report(self):
                &#39;&#39;&#39;
                Prints a report on the normalization fit.
                &#39;&#39;&#39;
                report_fit(self.normalization)

        def normalization_error(self, session, d47, D47):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                a = self.sessions[session][&#39;a&#39;]
                b = self.sessions[session][&#39;b&#39;]
                c = self.sessions[session][&#39;c&#39;]
#               s = pf(session)
#               i = self.normalization.var_names.index(f&#39;a_{s}&#39;)
#               j = self.normalization.var_names.index(f&#39;b_{s}&#39;)
#               k = self.normalization.var_names.index(f&#39;c_{s}&#39;)
#               CM = np.zeros((3,3))
#               CM[0,0] = self.normalization.covar[i,i]
#               CM[0,1] = self.normalization.covar[i,j]
#               CM[0,2] = self.normalization.covar[i,k]
#               CM[1,0] = self.normalization.covar[j,i]
#               CM[1,1] = self.normalization.covar[j,j]
#               CM[1,2] = self.normalization.covar[j,k]
#               CM[2,0] = self.normalization.covar[k,i]
#               CM[2,1] = self.normalization.covar[k,j]
#               CM[2,2] = self.normalization.covar[k,k]
                CM = self.sessions[session][&#39;CM&#39;]

                y, x = d47, D47
                z = a * x + b * y + c
                dxdy = -b / a
                dxdz = a ** -1
                dxda = -x / a
                dxdb = -y / a
                dxdc = -a ** -1
                V = np.array([dxda, dxdb, dxdc])
                sx = (V @ CM @ V.T) ** .5
                return sx


        def table_of_sessions(self, dir = &#39;results&#39;, filename = &#39;sessions.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = []
                out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
                out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
                out += [[&#39;External reproducibility of δ13C_VPDB&#39;, f&#34;{1000 * self.repro[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of δ18O_VSMOW&#39;, f&#34;{1000 * self.repro[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (anchors)&#39;, f&#34;{1000 * self.repro[&#39;r_D47a&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (unknowns)&#39;, f&#34;{1000 * self.repro[&#39;r_D47u&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (all)&#39;, f&#34;{1000 * self.repro[&#39;r_D47&#39;]:.1f} ppm&#34;]]
                out += [[&#39;Degrees of freedom (Student\&#39;s 95% t-factor)&#39;, f&#34;{self.Nf} ({self.t95:.2f})&#34;]]
                out += [[&#39;Standardization method&#39;, self.normalization_method]]
                print(pretty_table(out, header = 0)) 
                
                include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
                include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
                include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])
                out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,&#39;r_D47&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
                if include_a2:
                        out[-1] += [&#39;a2 ± SE&#39;]
                if include_b2:
                        out[-1] += [&#39;b2 ± SE&#39;]
                if include_c2:
                        out[-1] += [&#39;c2 ± SE&#39;]
                for session in self.sessions:
                        out += [[
                                session,
                                f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_D47&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                                f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                                ]]
                        if include_a2:
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_b2:
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_c2:
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]

                print(pretty_table(out))
                if not os.path.exists(dir):
                        os.makedirs(dir)
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))

        
        def table_of_analyses(self, dir = &#39;results&#39;, filename = &#39;analyses.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
                extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
                for f in extra_fields:
                        out[-1] += [f[0]]
                out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,&#39;D47&#39;]
                for r in self:
                        out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                        for f in extra_fields:
                                out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                        out[-1] += [
                                f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47&#39;]:.6f}&#34;
                                ]
#                       print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        


        def table_of_samples(self, dir = &#39;results&#39;, filename = &#39;samples.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
                for sample in self.anchors:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                                f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                                ]]
                for sample in self.unknowns:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,
                                f&#34;{self.samples[sample][&#39;SE_D47&#39;]:.4f}&#34;,
                                f&#34;± {self.samples[sample][&#39;SE_D47&#39;]*self.t95:.4f}&#34;,
                                f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                                f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;
                                ]]
                print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        


        def plot_sessions(self, dir = &#39;plots&#39;, figsize = (8,8)):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if not os.path.exists(dir):
                        os.makedirs(dir)
                anchor_color = &#39;r&#39;
                unknown_color = &#39;b&#39;

                xmin = min([r[&#39;d47&#39;] for r in self])
                xmax = max([r[&#39;d47&#39;] for r in self])
                xmin -= (xmax - xmin)/10
                xmax += (xmax - xmin)/11

                ymin = min([r[&#39;D47&#39;] for r in self])
                ymax = max([r[&#39;D47&#39;] for r in self])
                ymin -= (ymax - ymin)/10
                ymax += (ymax - ymin)/11

                repl_kw = dict(ls = &#39;None&#39;, marker = &#39;x&#39;, mfc = &#39;None&#39;, ms = 4, mew = .67, alpha = 1)
                avg_kw = dict(ls = &#39;-&#39;, marker = &#39;None&#39;, lw = .67, alpha = .67)
                for session in self.sessions:
                        fig = ppl.figure( figsize = figsize)
                        for sample in self.anchors:
                                db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                                if len(db):
                                        repl_kw[&#39;mec&#39;] = anchor_color
                                        X = [r[&#39;d47&#39;] for r in db]
                                        Y = [r[&#39;D47&#39;] for r in db]
                                        ppl.plot(X, Y, **repl_kw)
                                
                                        avg_kw[&#39;color&#39;] = anchor_color
                                        X = [min(X)-.5, max(X)+.5]
                                        Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                        ppl.plot(X, Y, **avg_kw)
                                
                        for sample in self.unknowns:

                                db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                                if len(db):
                                        repl_kw[&#39;mec&#39;] = unknown_color
                                        X = [r[&#39;d47&#39;] for r in db]
                                        Y = [r[&#39;D47&#39;] for r in db]
                                        ppl.plot(X, Y, **repl_kw)

                                        avg_kw[&#39;color&#39;] = unknown_color
                                        X = [min(X)-.19, max(X)+.19]
                                        Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                        ppl.plot(X, Y, **avg_kw)

                        XI,YI = np.meshgrid(np.linspace(xmin, xmax), np.linspace(ymin, ymax))
                        SI = np.array([[self.normalization_error(session, xi, yi) for xi in XI[0,:]] for yi in YI[:,0]])
                        rng = np.max(SI) - np.min(SI)
                        if rng &lt;= 0.01:
                                cinterval = 0.001
                        elif rng &lt;= 0.03:
                                cinterval = 0.004
                        elif rng &lt;= 0.1:
                                cinterval = 0.01
                        elif rng &lt;= 0.3:
                                cinterval = 0.03
                        else:
                                cinterval = 0.1
                        cval = [np.ceil(SI.min() / .001) * .001 + k * cinterval for k in range(int(np.ceil((SI.max() - SI.min()) / cinterval)))]
                        cs = ppl.contour(XI, YI, SI, cval, colors = anchor_color, alpha = .5)
                        ppl.clabel(cs)

                        ppl.axis([xmin, xmax, ymin, ymax])
                        ppl.xlabel(&#39;δ$_{47}$ (‰ WG)&#39;)
                        ppl.ylabel(&#39;Δ$_{47}$ (‰)&#39;)
                        ppl.grid(alpha = .15)
                        ppl.title(session, weight = &#39;bold&#39;)
                        ppl.savefig(f&#39;{dir}/D47model_{session}.pdf&#39;)
                        ppl.close(fig)


        def sample_D47_covar(self, sample_1, sample_2 = &#39;&#39;):
                &#39;&#39;&#39;
                Covariance between Δ47 values of samples
                
                Returns the covariance (or the variance, if sample_1 == sample_2)
                between the average Δ47 values of two samples. Also returns the
                variance if only sample_1 is specified.
                &#39;&#39;&#39;
                i = self.normalization.var_names.index(f&#39;D47_{pf(sample_1)}&#39;)
                if sample_2 in [sample_1,&#39;&#39;]:
                        return self.normalization.covar[i,i]
                else:
                        j = self.normalization.var_names.index(f&#39;D47_{pf(sample_2)}&#39;)
                        return self.normalization.covar[i,j]
                        

        def consolidate_samples(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                D47_ref_pop = [r[&#39;D47&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]
                for sample in self.samples:
                        self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                        if self.samples[sample][&#39;N&#39;] &gt; 1:
                                self.samples[sample][&#39;SD_D47&#39;] = stdev([r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]])

                        self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                        self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

                        D47_pop = [r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]]
                        if len(D47_pop) &gt; 1:
                                self.samples[sample][&#39;p_Levene&#39;] = levene(D47_ref_pop, D47_pop, center = &#39;median&#39;)[1]

                if self.normalization_method == &#39;integrated_fit&#39;:
                        for sample in self.anchors:
                                self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                                self.samples[sample][&#39;SE_D47&#39;] = 0.
                        for sample in self.unknowns:
                                self.samples[sample][&#39;D47&#39;] = self.normalization.params.valuesdict()[f&#39;D47_{pf(sample)}&#39;]
                                self.samples[sample][&#39;SE_D47&#39;] = self.sample_D47_covar(sample)**.5

                elif self.normalization_method == &#39;independent_sessions&#39;:
                        for sample in self.anchors:
                                self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                                self.samples[sample][&#39;SE_D47&#39;] = 0.
                        for sample in self.unknowns:
                                session_avg = []
                                for session in self.sessions:
                                        sdata = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                                        if sdata:
                                                avg_D47 = np.mean([r[&#39;D47&#39;] for r in sdata])
                                                avg_d47 = np.mean([r[&#39;d47&#39;] for r in sdata])
                                                sigma_s = self.normalization_error(session, avg_d47, avg_D47)
                                                sigma_u = self.repro[&#39;sigma_47&#39;] / len(sdata)**.5
                                                session_avg.append((avg_D47, (sigma_u**2 + sigma_s**2)**.5))
                                self.samples[sample][&#39;D47&#39;], self.samples[sample][&#39;SE_D47&#39;] = w_avg(*zip(*session_avg))


        def consolidate_sessions(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                for session in self.sessions:
                        self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                        self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])

                        self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, sessions = [session])

                if self.normalization_method == &#39;integrated_fit&#39;:
                        for session in self.sessions:

                                self.sessions[session][&#39;Np&#39;] = 3
                                for k in [&#39;scrambling&#39;, &#39;slope&#39;, &#39;wg&#39;]:
                                        if self.sessions[session][f&#39;{k}_drift&#39;]:
                                                self.sessions[session][&#39;Np&#39;] += 1

                                self.sessions[session][&#39;a&#39;] = self.normalization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                                i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_a&#39;] = self.normalization.covar[i,i]**.5

                                self.sessions[session][&#39;b&#39;] = self.normalization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                                i = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_b&#39;] = self.normalization.covar[i,i]**.5

                                self.sessions[session][&#39;c&#39;] = self.normalization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                                i = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_c&#39;] = self.normalization.covar[i,i]**.5

                                self.sessions[session][&#39;a2&#39;] = self.normalization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        i = self.normalization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_a2&#39;] = self.normalization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_a2&#39;] = 0.

                                self.sessions[session][&#39;b2&#39;] = self.normalization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        i = self.normalization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_b2&#39;] = self.normalization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_b2&#39;] = 0.

                                self.sessions[session][&#39;c2&#39;] = self.normalization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        i = self.normalization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_c2&#39;] = self.normalization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_c2&#39;] = 0.

                                i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                                j = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                                k = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                                self.sessions[session][&#39;CM&#39;] = self.normalization.covar[[i,j,k],:][:,[i,j,k]]

                elif self.normalization_method == &#39;independent_sessions&#39;:
                        pass


        def consolidate_repro(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.repro[&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)

                N_anchor_analyses = len([r for r in self if r[&#39;Sample&#39;] in self.anchors])

                self.repro[&#39;r_D47a&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_D47a&#39;] /= (
                        (N_anchor_analyses - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])) / (N_anchor_analyses - len(self.anchors))
                        )**.5

                self.repro[&#39;r_D47u&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;unknowns&#39;)

                self.repro[&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;all samples&#39;)
                self.repro[&#39;r_D47&#39;] /= (
                        (len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])) / (len(self) - len(self.samples))
                        )**.5


        def consolidate(self,
                tables = True,
                plots = True,
                ):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.consolidate_samples()
                self.consolidate_sessions()
                self.consolidate_repro()

                if tables:
                        self.table_of_sessions()
                        self.table_of_analyses()
                        self.table_of_samples()
                
                if plots:
                        self.plot_sessions()


        def compute_reproducibility(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
                &#39;&#39;&#39;
                Compute external reproducibility of `[r[key] for r in self]`.
                &#39;&#39;&#39;
                # NB: it&#39;s debatable whether rD47 should be computed
                # with Nf = len(self)-len(self.samples) instead of
                # Nf = len(self) - len(self.unknwons) - 3*len(self.sessions)

                if samples == &#39;all samples&#39;:
                        mysamples = [k for k in self.samples]
                elif samples == &#39;anchors&#39;:
                        mysamples = [k for k in self.anchors]
                elif samples == &#39;unknowns&#39;:
                        mysamples = [k for k in self.unknowns]
                else:
                        mysamples = samples

                if sessions == &#39;all sessions&#39;:
                        sessions = [k for k in self.sessions]

                chisq, Nf = 0, 0
                for sample in mysamples :
                        X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                        if len(X) &gt; 1 :
                                Nf += len(X) - 1
                                chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
                r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
                self.vprint(f&#39;External reproducibility of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
                return r

        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Average Δ47 value of a group of samples, accounting for covariance.
                
                Returns the (weighed, optionally) average Δ47 value and associated SE
                of a group of samples. Weights are equal by default. If normalize is
                True, weights will be rescaled so that their sum equals 1.
                
                __Examples__

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])
                ```

                returns the value and SE of [Δ&lt;sub&gt;47&lt;/sub&gt;(X) + 2 Δ&lt;sub&gt;47&lt;/sub&gt;(Y)]/3,
                where Δ&lt;sub&gt;47&lt;/sub&gt;(X) and Δ&lt;sub&gt;47&lt;/sub&gt;(Y) are the average Δ&lt;sub&gt;47&lt;/sub&gt;
                values of samples X and Y, respectively.

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                ```

                returns the value and SE of the difference Δ&lt;sub&gt;47&lt;/sub&gt;(X) - Δ&lt;sub&gt;47&lt;/sub&gt;(Y).
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        weights = [w/s for w in weights]

                try:
#                       indices = [self.normalization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.normalization.covar[indices,:][:,indices]
                        C = array([[self.sample_D47_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][&#39;D47&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)


        def sample_D47_covar(self, sample1, sample2 = &#39;&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if sample2 == &#39;&#39;:
                        sample2 = sample1
                if self.normalization_method == &#39;integrated_fit&#39;:
                        i = self.normalization.var_names.index(f&#39;D47_{pf(sample1)}&#39;)
                        j = self.normalization.var_names.index(f&#39;D47_{pf(sample2)}&#39;)
                        return self.normalization.covar[i, j]           
                elif self.normalization_method == &#39;independent_sessions&#39;:
                        if sample1 == sample2:
                                return self.samples[sample1][&#39;SE_D47&#39;]**2</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="D47crunch.correlated_sum"><code class="name flex">
<span>def <span class="ident">correlated_sum</span></span>(<span>X, C, f='')</span>
</code></dt>
<dd>
<section class="desc"><p>Compute covariance-aware linear combinations</p>
<p>Return the mean and SE of the sum of the elements of <code>X</code>, with optional
weights corresponding to the elements of <code>f</code>, accounting for <code>C</code>,
the covariance matrix of <code>X</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correlated_sum(X,C,f = &#39;&#39;):
        &#39;&#39;&#39;
        Compute covariance-aware linear combinations
        
        Return the mean and SE of the sum of the elements of `X`, with optional
        weights corresponding to the elements of `f`, accounting for `C`,
        the covariance matrix of `X`.
        &#39;&#39;&#39;
        if f == &#39;&#39;:
                f = [1 for x in X]
        return np.dot(f,X), (np.dot(f,np.dot(C,f)))**.5</code></pre>
</details>
</dd>
<dt id="D47crunch.make_csv"><code class="name flex">
<span>def <span class="ident">make_csv</span></span>(<span>x, hsep=',', vsep='\n')</span>
</code></dt>
<dd>
<section class="desc"><p>Formats a list of lists of strings as a CSV</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>x</code>: the list of lists of strings to format</li>
<li><code>hsep</code>: the field separator (a comma, by default)</li>
<li><code>vsep</code>: the line-ending convention to use (<code>'\n'</code> by default)</li>
</ul>
<p><strong>Example</strong></p>
<pre><code class="python">x = [['a', 'b', 'c'], ['d', 'e', 'f']]
print(make_csv(x))
</code></pre>
<p>output:</p>
<pre><code class="python">a,b,c
d,e,f
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_csv(x, hsep = &#39;,&#39;, vsep = &#39;\n&#39;):
        &#39;&#39;&#39;
        Formats a list of lists of strings as a CSV
        
        __Parameters__
        
        + `x`: the list of lists of strings to format
        + `hsep`: the field separator (a comma, by default)
        + `vsep`: the line-ending convention to use (`&#39;\\n&#39;` by default)
        
        __Example__
        
        ```python
        x = [[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [&#39;d&#39;, &#39;e&#39;, &#39;f&#39;]]
        print(make_csv(x))
        ```
        
        output:
        
        ```python
        a,b,c
        d,e,f
        ```
        &#39;&#39;&#39;
        return vsep.join([hsep.join(l) for l in x])</code></pre>
</details>
</dd>
<dt id="D47crunch.pf"><code class="name flex">
<span>def <span class="ident">pf</span></span>(<span>txt)</span>
</code></dt>
<dd>
<section class="desc"><p>Modify string <code>txt</code> to follow <code>lmfit.Parameter()</code> naming rules.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pf(txt):
        &#39;&#39;&#39;
        Modify string `txt` to follow `lmfit.Parameter()` naming rules.
        &#39;&#39;&#39;
        return txt.replace(&#39;-&#39;,&#39;_&#39;).replace(&#39;.&#39;,&#39;_&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.pretty_table"><code class="name flex">
<span>def <span class="ident">pretty_table</span></span>(<span>x, header=1, hsep='
', vsep='-')</span>
</code></dt>
<dd>
<section class="desc"><p>Reads a list of lists of strings and outputs an ascii table</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>x</code>: a list of lists of strings</li>
<li><code>header</code>: the number of lines to treat as header lines</li>
<li><code>hsep</code>: the horizontal separator between columns</li>
<li><code>vsep</code>: the character to use as vertical separator</li>
</ul>
<p><strong>Example</strong></p>
<pre><code class="python">x = [['A','B', 'C'], ['1', '1.9999', 'foo'], ['10', 'x', 'bar']]
print(pretty_table(x))
</code></pre>
<p>output:</p>
<pre><code class="python">--  ------  ---
A        B    C
--  ------  ---
1   1.9999  foo
10       x  bar
--  ------  ---
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pretty_table(x, header = 1, hsep = &#39;  &#39;, vsep = &#39;-&#39;):
        &#39;&#39;&#39;
        Reads a list of lists of strings and outputs an ascii table
        
        __Parameters__
        
        + `x`: a list of lists of strings
        + `header`: the number of lines to treat as header lines
        + `hsep`: the horizontal separator between columns
        + `vsep`: the character to use as vertical separator
        
        __Example__
        
        ```python
        x = [[&#39;A&#39;,&#39;B&#39;, &#39;C&#39;], [&#39;1&#39;, &#39;1.9999&#39;, &#39;foo&#39;], [&#39;10&#39;, &#39;x&#39;, &#39;bar&#39;]]
        print(pretty_table(x))
        ```
        
        output:

        ```python
        --  ------  ---
        A        B    C
        --  ------  ---
        1   1.9999  foo
        10       x  bar
        --  ------  ---
        ```
        &#39;&#39;&#39;
        txt = [&#39;&#39;]
        widths = [np.max([len(e) for e in c]) for c in zip(*x)]
        
        align = &#39;&lt;&#39; + &#39;&gt;&#39;*(len(widths)-1)
        sepline = hsep.join([vsep*w for w in widths])
        txt += [sepline]
        for k,l in enumerate(x):
                if k and k == header:
                        txt += [sepline]
                txt += [hsep.join([f&#39;{e:{a}{w}}&#39; for e, w, a in zip(l, widths, align)])]
        txt += [sepline]
        txt += [&#39;&#39;]
        return &#39;\n&#39;.join(txt)</code></pre>
</details>
</dd>
<dt id="D47crunch.smart_type"><code class="name flex">
<span>def <span class="ident">smart_type</span></span>(<span>x)</span>
</code></dt>
<dd>
<section class="desc"><p>Tries to convert string <code>x</code> to a float if it includes a decimal point, or
to an integer if it does not. If both attempts fail, return the original
string unchanged.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def smart_type(x):
        &#39;&#39;&#39;
        Tries to convert string `x` to a float if it includes a decimal point, or
        to an integer if it does not. If both attempts fail, return the original
        string unchanged.
        &#39;&#39;&#39;
        try:
                y = float(x)
        except ValueError:
                return x
        if &#39;.&#39; not in x:
                return int(y)
        return y</code></pre>
</details>
</dd>
<dt id="D47crunch.transpose_table"><code class="name flex">
<span>def <span class="ident">transpose_table</span></span>(<span>x)</span>
</code></dt>
<dd>
<section class="desc"><p>Transpose a list if lists</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>x</code>: a list of lists</li>
</ul>
<p><strong>Example</strong></p>
<pre><code class="python">x = [[1, 2], [3, 4]]
print(transpose_table(x))
</code></pre>
<p>outputs:</p>
<pre><code class="python">[[1, 3], [2, 4]]
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transpose_table(x):
        &#39;&#39;&#39;
        Transpose a list if lists
        
        __Parameters__
        
        + `x`: a list of lists

        __Example__
        
        ```python
        x = [[1, 2], [3, 4]]
        print(transpose_table(x))
        ```
        
        outputs:
        
        ```python
        [[1, 3], [2, 4]]
        ```

        &#39;&#39;&#39;
        return [[e for e in c] for c in zip(*x)]</code></pre>
</details>
</dd>
<dt id="D47crunch.w_avg"><code class="name flex">
<span>def <span class="ident">w_avg</span></span>(<span>X, sX)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute variance-weighted average</p>
<p>Returns the value and SE of the weighted average of the elements of <code>X</code>,
with relative weights equal to their inverse variances (<code>1/sX**2</code>).</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>X</code>: array-like of elements to average</li>
<li><code>sX</code>: array-like of the corresponding SE values</li>
</ul>
<p><strong>Tip</strong></p>
<p>If <code>X</code> and <code>sX</code> are initially arranged as a list of <code>(x, sx)</code> doublets,
they may be rearranged using <code>zip()</code>:</p>
<pre><code class="python">foo = [(0, 0.1), (1, 0.05), (2, 0.05)]
print(w_avg(*zip(*foo)))

# output:
# (1.3333333333333333, 0.03333333333333334)
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def w_avg(X, sX) :
        &#39;&#39;&#39;
        Compute variance-weighted average
        
        Returns the value and SE of the weighted average of the elements of `X`,
        with relative weights equal to their inverse variances (`1/sX**2`).
        
        __Parameters__
        
        + `X`: array-like of elements to average
        + `sX`: array-like of the corresponding SE values

        __Tip__

        If `X` and `sX` are initially arranged as a list of `(x, sx)` doublets,
        they may be rearranged using `zip()`:
        
        ```python
        foo = [(0, 0.1), (1, 0.05), (2, 0.05)]
        print(w_avg(*zip(*foo)))
        
        # output:
        # (1.3333333333333333, 0.03333333333333334)
        ```
        &#39;&#39;&#39;
        X = [ x for x in X ]
        sX = [ sx for sx in sX ]
        W = [ sx**-2 for sx in sX ]
        W = [ w/sum(W) for w in W ]
        Xavg = sum([ w*x for w,x in zip(W,X) ])
        sXavg = sum([ w**2*sx**2 for w,sx in zip(W,sX) ])**.5
        return Xavg, sXavg</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="D47crunch.D47data"><code class="flex name class">
<span>class <span class="ident">D47data</span></span>
<span>(</span><span>l=[], verbose=False, msgcolor='\x1b[92m')</span>
</code></dt>
<dd>
<section class="desc"><p>Store and process data for a large set of Δ<sub>47</sub> analyses,
usually comprising more than one analytical session.</p>
<p><em>Parameters</em></p>
<ul>
<li><code>l</code>: a list of dictionaries, with each element including at least the keys
<code>UID</code>, <code>Session</code>, <code>Sample</code>, <code>d45</code>, <code>d46</code>, and <code>d47</code>.</li>
<li><code>verbose</code>: if <code>True</code>, print out additional information when calling <a title="D47crunch.D47data" href="#D47crunch.D47data"><code>D47data</code></a>
methods.</li>
<li><code>msgcolor</code>: terminal color used when printing out verbose information
(light green by default).</li>
</ul>
<p><em>Returns</em> a <a title="D47crunch.D47data" href="#D47crunch.D47data"><code>D47data</code></a> object derived from <code>list</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class D47data(list):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ&lt;sub&gt;47&lt;/sub&gt; analyses,
        usually comprising more than one analytical session.
        &#39;&#39;&#39;

        ### 17O CORRECTION PARAMETERS
        R13_VPDB = 0.01118  # (Chang &amp; Li, 1990)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;13&lt;/sup&gt;C/&lt;sup&gt;12&lt;/sup&gt;C) ratio of VPDB.
        By default equal to 0.01118 ([Chang &amp; Li, 1990])
        
        [Chang &amp; Li, 1990]: http://www.cnki.com.cn/Article/CJFDTotal-JXTW199004006.htm
        &#39;&#39;&#39;
        
        R18_VSMOW = 0.0020052  # (Baertschi, 1976)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VSMOW.
        By default equal to 0.0020052 ([Baertschi, 1976])
        
        [Baertschi, 1976]: https://doi.org/10.1016/0012-821X(76)90115-1
        &#39;&#39;&#39;

        lambda_17 = 0.528  # (Barkan &amp; Luz, 2005)
        &#39;&#39;&#39;
        Mass-dependent exponent for triple oxygen isotopes.
        By default equal to 0.528 ([Barkan &amp; Luz, 2005])
        
        [Barkan &amp; Luz, 2005]: https://doi.org/10.1002/rcm.2250
        &#39;&#39;&#39;

        R17_VSMOW = 0.00038475  # (Assonov &amp; Brenninkmeijer, 2003, rescaled to R13_VPDB)
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;17&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VSMOW.
        By default equal to 0.00038475 ([Daëron et al., 2016])
        
        [Daëron et al., 2016]: https://dx.doi.org/10.1016/j.chemgeo.2016.08.014
        &#39;&#39;&#39;

        R18_VPDB = R18_VSMOW * 1.03092
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VPDB.
        By definition equal to `R18_VSMOW * 1.03092`.
        &#39;&#39;&#39;

        R17_VPDB = R17_VSMOW * 1.03092 ** lambda_17
        &#39;&#39;&#39;
        Absolute (&lt;sup&gt;17&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;C) ratio of VPDB.
        By definition equal to `R17_VSMOW * 1.03092 ** lambda_17`.
        &#39;&#39;&#39;

        LEVENE_REF_SAMPLE = &#39;ETH-3&#39;
        &#39;&#39;&#39;
        After the Δ&lt;sub&gt;47&lt;/sub&gt; standardization step, each sample is tested to
        assess whether the Δ&lt;sub&gt;47&lt;/sub&gt; variance within all analyses for that
        sample is significantly larger than that observed for a given reference
        sample (using [Levene&#39;s test], which yields a p-value corresponding to
        the null hypothesis that the underlying variances are equal).
        
        `LEVENE_REF_SAMPLE` (by default equal to `&#39;ETH-3&#39;`) specifies which
        sample should be used as a reference for this test.
        
        [Levene&#39;s test]: https://en.wikipedia.org/wiki/Levene%27s_test
        &#39;&#39;&#39;
        
        SAMPLE_CONSTRAINING_WG_COMPOSITION = (&#39;ETH-3&#39;, 1.71, -1.78) # (Bernasconi et al., 2018)
        &#39;&#39;&#39;
        specifies the name, δ&lt;sup&gt;13&lt;/sup&gt;C&lt;sub&gt;VPDB&lt;/sub&gt; and δ&lt;sup&gt;18&lt;/sup&gt;O&lt;sub&gt;VPDB&lt;/sub&gt;
        of the carbonate standard used by `D47data.wg()` to compute the isotopic composition
        of the working gas in each session.
        
        By default equal to `(&#39;ETH-3&#39;, 1.71, -1.78)` after [Bernasconi et al. (2018)].
        
        [Bernasconi et al. (2018)]: https://doi.org/10.1029/2017GC007385
        &#39;&#39;&#39;
        
        ALPHA_18O_ACID_REACTION = np.exp(3.59 / (90 + 273.15) - 1.79e-3)  # (Kim et al., 2007, calcite)
        &#39;&#39;&#39;
        specifies the &lt;sup&gt;18&lt;/sup&gt;O/&lt;sup&gt;16&lt;/sup&gt;O fractionation factor generally applicable
        to acid reactions in the dataset. Currently only used by `self.wg()`.
        
        By default equal to 1.00813 (calcite reacted at 90 °C, [Kim et al., 2007]).
        
        [Kim et al., 2007]: https://dx.doi.org/10.1016/j.chemgeo.2007.08.005
        &#39;&#39;&#39;

        Nominal_D47 = {
                &#39;ETH-1&#39;: 0.258,
                &#39;ETH-2&#39;: 0.256,
                &#39;ETH-3&#39;: 0.691,
                }       # (Bernasconi et al., 2018)
        &#39;&#39;&#39;
        Nominal Δ&lt;sub&gt;47&lt;/sub&gt; values assigned to the anchor samples, used in particular by
        `self.normalize()` to standardize unknown samples to a carbonate Δ&lt;sub&gt;47&lt;/sub&gt;
        reference frame.
        
        By default equal to `{&#39;ETH-1&#39;: 0.258, &#39;ETH-2&#39;: 0.256, &#39;ETH-3&#39;: 0.691}` after
        [Bernasconi et al. (2018)].
        
        [Bernasconi et al. (2018)]: https://doi.org/10.1029/2017GC007385
        &#39;&#39;&#39;


        def __init__(self, l = [], verbose = False, msgcolor = &#39;\033[92m&#39;):
                &#39;&#39;&#39;
                _Parameters_
                
                + `l`: a list of dictionaries, with each element including at least the keys
                `UID`, `Session`, `Sample`, `d45`, `d46`, and `d47`.
                + `verbose`: if `True`, print out additional information when calling `D47data`
                methods.
                + `msgcolor`: terminal color used when printing out verbose information
                (light green by default).
                
                _Returns_ a `D47data` object derived from `list`.
                &#39;&#39;&#39;
                self.verbose = verbose
                self.msgcolor = msgcolor
                list.__init__(self, l)
                self.Nf = None
                self.repro = {}
                self.refresh()


        def vprint(self, txt):
                &#39;&#39;&#39;
                Print verbose message `txt` to screen if `self.verbose == True`.
                &#39;&#39;&#39;
                if self.verbose:
                        print(f&#39;{self.msgcolor}[D47data]   {txt}\033[0m&#39;)


        def refresh(self):
                &#39;&#39;&#39;
                Update `self.sessions`, `self.samples`, `self.anchors`, and `self.unknowns`.
                &#39;&#39;&#39;
                self.refresh_sessions()
                self.refresh_samples()


        def refresh_sessions(self):
                &#39;&#39;&#39;
                Update `self.sessions` and set `scrambling_drift`, `slope_drift`, and `wg_drift`
                to `False` for all sessions.
                &#39;&#39;&#39;
                self.sessions = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                        for s in sorted({r[&#39;Session&#39;] for r in self})
                        }
                for s in self.sessions:
                        self.sessions[s][&#39;scrambling_drift&#39;] = False
                        self.sessions[s][&#39;slope_drift&#39;] = False
                        self.sessions[s][&#39;wg_drift&#39;] = False


        def refresh_samples(self):
                &#39;&#39;&#39;
                Define `self.samples`, `self.anchors`, and `self.unknowns`.
                &#39;&#39;&#39;
                self.samples = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                        for s in sorted({r[&#39;Sample&#39;] for r in self})
                        }
                self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D47}
                self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D47}


        def read(self, filename, sep = &#39;,&#39;):
                &#39;&#39;&#39;
                Read file in csv format to load data into a `D47data` object.
                
                In the csv file, spaces befor and after field separators (`&#39;,&#39;` by default)
                are optional. Each line corresponds to a single analysis.
                
                The required fields are:
                
                + `UID`: a unique identifier
                + `Session`: an identifier for the analytical session
                + `Sample`: a sample identifier
                + `d45`, `d46`, `d47`: the working-gas delta values

                Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
                VSMOW, λ = 0.528), and are otherwise assumed to be zero. Working-gas deltas `d48`
                and `d49` may also be provided, and are also set to 0 otherwise.
                
                __Parameters__
                
                + `fileneme`: the path of the file to read
                + `sep`: csv separator delimiting the fields
                &#39;&#39;&#39;
                with open(filename) as fid:
                        self.input(fid.read(), sep = sep)


        def input(self, txt, sep = &#39;,&#39;):
                &#39;&#39;&#39;
                Read `txt` string in csv format to load analysis data into a `D47data` object.

                In the csv string, spaces befor and after field separators (`&#39;,&#39;` by default)
                are optional. Each line corresponds to a single analysis.
                
                The required fields are:
                
                + `UID`: a unique identifier
                + `Session`: an identifier for the analytical session
                + `Sample`: a sample identifier
                + `d45`, `d46`, `d47`: the working-gas delta values

                Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
                VSMOW, λ = 0.528), and are otherwise assumed to be zero. Working-gas deltas `d48`
                and `d49` may also be provided, and are also set to 0 otherwise.
                
                __Parameters__
                
                + `txt`: the csv string to read
                + `sep`: csv separator delimiting the fields
                &#39;&#39;&#39;
                txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
                data = [{k: smart_type(v) for k,v in zip(txt[0], l)} for l in txt[1:]]
                self += data
                self.refresh()


        def wg(self, sample = &#39;&#39;, d13C_vpdb = &#39;&#39;, d18O_vpdb = &#39;&#39;, a18_acid = &#39;&#39;):
                &#39;&#39;&#39;
                Compute bulk composition of the working gas for each session
                based on the average composition, within each session,
                of a given sample.
                &#39;&#39;&#39;

                self.vprint(f&#34;Computing working gas composition:&#34;)

                if sample == &#39;&#39;:
                        sample = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[0]
                if d13C_vpdb == &#39;&#39;:
                        d13C_vpdb = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[1]
                if d18O_vpdb == &#39;&#39;:
                        d18O_vpdb = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[2]
                if a18_acid == &#39;&#39;:
                        a18_acid = self.ALPHA_18O_ACID_REACTION

                R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
                R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
                R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

                C12_s = 1 / (1 + R13_s)
                C13_s = R13_s / (1 + R13_s)
                C16_s = 1 / (1 + R17_s + R18_s)
                C17_s = R17_s / (1 + R17_s + R18_s)
                C18_s = R18_s / (1 + R17_s + R18_s)

                C626_s = C12_s * C16_s ** 2
                C627_s = 2 * C12_s * C16_s * C17_s
                C628_s = 2 * C12_s * C16_s * C18_s
                C636_s = C13_s * C16_s ** 2
                C637_s = 2 * C13_s * C16_s * C17_s
                C727_s = C12_s * C17_s ** 2

                R45_s = (C627_s + C636_s) / C626_s
                R46_s = (C628_s + C637_s + C727_s) / C626_s

                for s in self.sessions:
                        db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                        d45_s = np.mean([r[&#39;d45&#39;] for r in db])
                        d46_s = np.mean([r[&#39;d46&#39;] for r in db])
                        R45_wg = R45_s / (1 + d45_s / 1000)
                        R46_wg = R46_s / (1 + d46_s / 1000)

                        d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_deltas(R45_wg, R46_wg)

                        self.vprint(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                        self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                        for r in self.sessions[s][&#39;data&#39;]:
                                r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                                r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW


        def compute_bulk_deltas(self, R45, R46, D17O = 0):
                &#39;&#39;&#39;
                Compute δ13C_VPDB and δ18O_VSMOW, by solving the generalized form of equation (17)
                from Brand et al. (2010), assuming that d18O_VSMOW is not too big ( 0 ± 50 ‰) and
                solving the corresponding second-order Taylor polynomial.
                (Appendix A, Daëron et al., 2016, &lt;https://doi.org/10.1016/j.chemgeo.2016.08.014&gt;)
                &#39;&#39;&#39;

                K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

                A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
                B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
                C = 2 * self.R18_VSMOW
                D = -R46

                aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
                bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
                cc = A + B + C + D

                d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

                R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
                R17 = K * R18 ** self.lambda_17
                R13 = R45 - 2 * R17

                d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

                return d13C_VPDB, d18O_VSMOW


        def crunch(self):
                &#39;&#39;&#39;
                Compute bulk composition and raw clumped isotope anomalies for all analyses.
                &#39;&#39;&#39;
                for i,r in enumerate(self):
                        for k in [&#39;D17O&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                                if k not in r:
                                        r[k] = 0.
                        self.compute_bulk_and_clumping_deltas(r)
                self.vprint(f&#34;Crunched {len(self)} analyses.&#34;)


        def compute_bulk_and_clumping_deltas(self, r):
                &#39;&#39;&#39;
                Compute δ13C_VPDB, δ18O_VSMOW, and raw Δ47, Δ48, Δ49 values for an analysis.
                &#39;&#39;&#39;

                # Compute working gas R13, R18, and isobar ratios
                R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
                R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
                R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

                # Compute analyte isobar ratios
                R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
                R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
                R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
                R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
                R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

                r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_deltas(R45, R46, D17O = r[&#39;D17O&#39;])
                R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
                R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

                # Compute stochastic isobar ratios of the analyte
                R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                        R13, R18, D17O = r[&#39;D17O&#39;]
                )

                # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
                # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
                if (R45 / R45stoch - 1) &gt; 5e-8:
                        self.vprint(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):%.3f} ppm&#39;)
                if (R46 / R46stoch - 1) &gt; 5e-8:
                        self.vprint(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):%.3f} ppm&#39;)

                # Compute raw clumped isotope anomalies
                r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
                r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
                r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)

        def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
                &#39;&#39;&#39;
                Compute isobar ratios for a sample with isotopic ratios R13 and R18,
                optionally accounting for non-zero values of Δ17O and clumped isotope
                anomalies, all expressed in permil.
                &#39;&#39;&#39;

                # Compute R17
                R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

                # Compute isotope concentrations
                C12 = (1 + R13) ** -1
                C13 = C12 * R13
                C16 = (1 + R17 + R18) ** -1
                C17 = C16 * R17
                C18 = C16 * R18

                # Compute stochastic isotopologue concentrations
                C626 = C16 * C12 * C16
                C627 = C16 * C12 * C17 * 2
                C628 = C16 * C12 * C18 * 2
                C636 = C16 * C13 * C16
                C637 = C16 * C13 * C17 * 2
                C638 = C16 * C13 * C18 * 2
                C727 = C17 * C12 * C17
                C728 = C17 * C12 * C18 * 2
                C737 = C17 * C13 * C17
                C738 = C17 * C13 * C18 * 2
                C828 = C18 * C12 * C18
                C838 = C18 * C13 * C18

                # Compute stochastic isobar ratios
                R45 = (C636 + C627) / C626
                R46 = (C628 + C637 + C727) / C626
                R47 = (C638 + C728 + C737) / C626
                R48 = (C738 + C828) / C626
                R49 = C838 / C626

                # Account for stochastic anomalies
                R47 *= 1 + D47 / 1000
                R48 *= 1 + D48 / 1000
                R49 *= 1 + D49 / 1000

                # Return isobar ratios
                return R45, R46, R47, R48, R49

        def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_uid&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if samples_to_split == &#39;all&#39;:
                        samples_to_split = [s for s in self.unknowns]
                gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
                self.grouping = grouping.lower()
                if self.grouping in gkeys:
                        gkey = gkeys[self.grouping]
                for r in self:
                        if r[&#39;Sample&#39;] in samples_to_split:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                        elif r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                self.refresh_samples()


        def unsplit_samples(self, tables = True):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                unknowns_old = sorted({s for s in self.unknowns})
                CM_old = self.normalization.covar[:,:]
                VD_old = self.normalization.params.valuesdict().copy()
                vars_old = self.normalization.var_names

                unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})
                
                Ns = len(vars_old) - len(unknowns_old)
                vars_new = vars_old[:Ns] + [f&#39;D47_{pf(u)}&#39; for u in unknowns_new]
                VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

                W = np.zeros((len(vars_new), len(vars_old)))
                W[:Ns,:Ns] = np.eye(Ns)
                for u in unknowns_new:
                        splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                        if self.grouping == &#39;by_session&#39;:
                                weights = [self.samples[s][&#39;SE_D47&#39;]**-2 for s in splits]
                        elif self.grouping == &#39;by_uid&#39;:
                                weights = [1 for s in splits]
                        sw = sum(weights)
                        weights = [w/sw for w in weights]
                        W[vars_new.index(f&#39;D47_{pf(u)}&#39;),[vars_old.index(f&#39;D47_{pf(s)}&#39;) for s in splits]] = weights[:]
#               print(&#39;\nUnsplitting weights matrix:&#39;)
#               print(&#39;\n&#39;.join([&#39; &#39;.join([f&#39;{x:.1f}&#39; if x else &#39; - &#39; for x in l]) for l in W]))
#               print(&#39;---&#39;)

                CM_new = W @ CM_old @ W.T
                V = W @ np.array([[VD_old[k]] for k in vars_old])
                VD_new = {k:v[0] for k,v in zip(vars_new, V)}
                
                self.normalization.covar = CM_new
                self.normalization.params.valuesdict = lambda : VD_new
                self.normalization.var_names = vars_new

                for r in self:
                        if r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]
                
                self.refresh_samples()
                self.consolidate_samples()
                self.consolidate_repro()

                if tables:
                        self.table_of_analyses()
                        self.table_of_samples()


        def assign_timestamps(self):
                &#39;&#39;&#39;
                Assign a time field `t` to each analysis.
                
                If `TimeTag` is one of the data fields, `t` is equal within a given session
                to `TimeTag` minus the mean value of `TimeTag` for that session.
                Otherwise, `TimeTag` is by default equal to the index of each analysis
                in the dataset and `t` is defined as above.
                &#39;&#39;&#39;
                for session in self.sessions:
                        sdata = self.sessions[session][&#39;data&#39;]
                        try:
                                t0 = np.mean([r[&#39;TimeTag&#39;] for r in sdata])
                                for r in sdata:
                                        r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
                        except KeyError:
                                t0 = (len(sdata)-1)/2
                                for t,r in enumerate(sdata):
                                        r[&#39;t&#39;] = t - t0


        def normalize(self,
                method = &#39;integrated_fit&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = True,
                consolidate_plots = True,
                ):
                &#39;&#39;&#39;
                Compute absolute Δ47 values for all replicate analyses and for sample averages.
                If `method` argument is set to `&#39;integrated_fit&#39;`, the normalization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous (i.e. that their true Δ&lt;sub&gt;47&lt;/sub&gt; value does not change between sessions).
                If `method` argument is set to `&#39;independent_sessions&#39;`, the normalization processes each
                session independently, based only on anchors analyses.
                &#39;&#39;&#39;

                self.normalization_method = method
                self.assign_timestamps()

                if method == &#39;integrated_fit&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D47data([r for r in self if r[&#39;Session&#39;] in session_group], verbose = self.verbose)
                                        result = X.normalize(method = &#39;integrated_fit&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.vprint(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[&#39;wD47raw&#39;] *= w
                        else:
                                self.vprint(&#39;All weights set to 1 ppm&#39;)
                                for r in self:
                                        r[&#39;wD47raw&#39;] = 0.001

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.vprint(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D47_{pf(sample)}&#39;, value=0.6)

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D47:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.leastsq()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[&#39;D47&#39;] = (r[&#39;D47raw&#39;] - c - b * r[&#39;d47&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[&#39;d47&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.normalization = result
                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result

                elif method == &#39;independent_sessions&#39;:
                        for session in self.sessions:
                                self.sessions[session][&#39;Np&#39;] = 3
                                self.vprint(&#39;&#39;)
                                self.vprint(f&#39;Standardizing session {session}.&#39;)
                                sdata = self.sessions[session][&#39;data&#39;]
                                A = np.array([
                                        [self.Nominal_D47[r[&#39;Sample&#39;]], r[&#39;d47&#39;], 1]
                                        for r in sdata if r[&#39;Sample&#39;] in self.anchors
                                        ])
                                Y = np.array([[r[&#39;D47raw&#39;]] for r in sdata if r[&#39;Sample&#39;] in self.anchors])
                                self.sessions[session][&#39;Na&#39;] = Y.size
                                CM = linalg.inv(A.T @ A)
                                a,b,c = (CM @ A.T @ Y).T[0,:3]

                                self.vprint(f&#39;a = {a:.4f}&#39;)
                                self.vprint(f&#39;b = {b:.2e}&#39;)
                                self.vprint(f&#39;c = {c:.4f}&#39;)
                                self.sessions[session][&#39;a&#39;] = a
                                self.sessions[session][&#39;b&#39;] = b
                                self.sessions[session][&#39;c&#39;] = c
                                self.sessions[session][&#39;CM&#39;] = CM.copy()

                                for r in sdata :
                                        r[&#39;D47&#39;] = ( r[&#39;D47raw&#39;] - b * r[&#39;d47&#39;] - c ) / a
                        
                        Nss = len(self.sessions)
                        Na = len(self)
                        Ns = len(self.samples)
                        Nu = len(self.unknowns)
                        avgD47 = {
                                sample: np.mean([r[&#39;D47&#39;] for r in self if r[&#39;Sample&#39;] == sample])
                                for sample in self.samples
                                }
                        chi2 = np.sum([(r[&#39;D47&#39;] - avgD47[r[&#39;Sample&#39;]])**2 for r in self])
                        rD47 = (chi2/(Na-Nu-3*Nss))**.5
                        self.repro[&#39;sigma_47&#39;] = rD47

                        for session in self.sessions:
                                self.sessions[session][&#39;CM&#39;] *= a**2 * chi2 / (Na-Nu-3*Nss)
                                self.sessions[session][&#39;SE_a&#39;] = self.sessions[session][&#39;CM&#39;][0,0]**.5
                                self.sessions[session][&#39;SE_b&#39;] = self.sessions[session][&#39;CM&#39;][1,1]**.5
                                self.sessions[session][&#39;SE_c&#39;] = self.sessions[session][&#39;CM&#39;][2,2]**.5
                        
#                       self.Nf = np.sum([self.sessions[s][&#39;Na&#39;] - self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        self.Nf = len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)


        def report(self):
                &#39;&#39;&#39;
                Prints a report on the normalization fit.
                &#39;&#39;&#39;
                report_fit(self.normalization)

        def normalization_error(self, session, d47, D47):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                a = self.sessions[session][&#39;a&#39;]
                b = self.sessions[session][&#39;b&#39;]
                c = self.sessions[session][&#39;c&#39;]
#               s = pf(session)
#               i = self.normalization.var_names.index(f&#39;a_{s}&#39;)
#               j = self.normalization.var_names.index(f&#39;b_{s}&#39;)
#               k = self.normalization.var_names.index(f&#39;c_{s}&#39;)
#               CM = np.zeros((3,3))
#               CM[0,0] = self.normalization.covar[i,i]
#               CM[0,1] = self.normalization.covar[i,j]
#               CM[0,2] = self.normalization.covar[i,k]
#               CM[1,0] = self.normalization.covar[j,i]
#               CM[1,1] = self.normalization.covar[j,j]
#               CM[1,2] = self.normalization.covar[j,k]
#               CM[2,0] = self.normalization.covar[k,i]
#               CM[2,1] = self.normalization.covar[k,j]
#               CM[2,2] = self.normalization.covar[k,k]
                CM = self.sessions[session][&#39;CM&#39;]

                y, x = d47, D47
                z = a * x + b * y + c
                dxdy = -b / a
                dxdz = a ** -1
                dxda = -x / a
                dxdb = -y / a
                dxdc = -a ** -1
                V = np.array([dxda, dxdb, dxdc])
                sx = (V @ CM @ V.T) ** .5
                return sx


        def table_of_sessions(self, dir = &#39;results&#39;, filename = &#39;sessions.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = []
                out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
                out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
                out += [[&#39;External reproducibility of δ13C_VPDB&#39;, f&#34;{1000 * self.repro[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of δ18O_VSMOW&#39;, f&#34;{1000 * self.repro[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (anchors)&#39;, f&#34;{1000 * self.repro[&#39;r_D47a&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (unknowns)&#39;, f&#34;{1000 * self.repro[&#39;r_D47u&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (all)&#39;, f&#34;{1000 * self.repro[&#39;r_D47&#39;]:.1f} ppm&#34;]]
                out += [[&#39;Degrees of freedom (Student\&#39;s 95% t-factor)&#39;, f&#34;{self.Nf} ({self.t95:.2f})&#34;]]
                out += [[&#39;Standardization method&#39;, self.normalization_method]]
                print(pretty_table(out, header = 0)) 
                
                include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
                include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
                include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])
                out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,&#39;r_D47&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
                if include_a2:
                        out[-1] += [&#39;a2 ± SE&#39;]
                if include_b2:
                        out[-1] += [&#39;b2 ± SE&#39;]
                if include_c2:
                        out[-1] += [&#39;c2 ± SE&#39;]
                for session in self.sessions:
                        out += [[
                                session,
                                f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_D47&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                                f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                                ]]
                        if include_a2:
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_b2:
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_c2:
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]

                print(pretty_table(out))
                if not os.path.exists(dir):
                        os.makedirs(dir)
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))

        
        def table_of_analyses(self, dir = &#39;results&#39;, filename = &#39;analyses.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
                extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
                for f in extra_fields:
                        out[-1] += [f[0]]
                out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,&#39;D47&#39;]
                for r in self:
                        out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                        for f in extra_fields:
                                out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                        out[-1] += [
                                f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47&#39;]:.6f}&#34;
                                ]
#                       print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        


        def table_of_samples(self, dir = &#39;results&#39;, filename = &#39;samples.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
                for sample in self.anchors:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                                f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                                ]]
                for sample in self.unknowns:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,
                                f&#34;{self.samples[sample][&#39;SE_D47&#39;]:.4f}&#34;,
                                f&#34;± {self.samples[sample][&#39;SE_D47&#39;]*self.t95:.4f}&#34;,
                                f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                                f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;
                                ]]
                print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        


        def plot_sessions(self, dir = &#39;plots&#39;, figsize = (8,8)):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if not os.path.exists(dir):
                        os.makedirs(dir)
                anchor_color = &#39;r&#39;
                unknown_color = &#39;b&#39;

                xmin = min([r[&#39;d47&#39;] for r in self])
                xmax = max([r[&#39;d47&#39;] for r in self])
                xmin -= (xmax - xmin)/10
                xmax += (xmax - xmin)/11

                ymin = min([r[&#39;D47&#39;] for r in self])
                ymax = max([r[&#39;D47&#39;] for r in self])
                ymin -= (ymax - ymin)/10
                ymax += (ymax - ymin)/11

                repl_kw = dict(ls = &#39;None&#39;, marker = &#39;x&#39;, mfc = &#39;None&#39;, ms = 4, mew = .67, alpha = 1)
                avg_kw = dict(ls = &#39;-&#39;, marker = &#39;None&#39;, lw = .67, alpha = .67)
                for session in self.sessions:
                        fig = ppl.figure( figsize = figsize)
                        for sample in self.anchors:
                                db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                                if len(db):
                                        repl_kw[&#39;mec&#39;] = anchor_color
                                        X = [r[&#39;d47&#39;] for r in db]
                                        Y = [r[&#39;D47&#39;] for r in db]
                                        ppl.plot(X, Y, **repl_kw)
                                
                                        avg_kw[&#39;color&#39;] = anchor_color
                                        X = [min(X)-.5, max(X)+.5]
                                        Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                        ppl.plot(X, Y, **avg_kw)
                                
                        for sample in self.unknowns:

                                db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                                if len(db):
                                        repl_kw[&#39;mec&#39;] = unknown_color
                                        X = [r[&#39;d47&#39;] for r in db]
                                        Y = [r[&#39;D47&#39;] for r in db]
                                        ppl.plot(X, Y, **repl_kw)

                                        avg_kw[&#39;color&#39;] = unknown_color
                                        X = [min(X)-.19, max(X)+.19]
                                        Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                        ppl.plot(X, Y, **avg_kw)

                        XI,YI = np.meshgrid(np.linspace(xmin, xmax), np.linspace(ymin, ymax))
                        SI = np.array([[self.normalization_error(session, xi, yi) for xi in XI[0,:]] for yi in YI[:,0]])
                        rng = np.max(SI) - np.min(SI)
                        if rng &lt;= 0.01:
                                cinterval = 0.001
                        elif rng &lt;= 0.03:
                                cinterval = 0.004
                        elif rng &lt;= 0.1:
                                cinterval = 0.01
                        elif rng &lt;= 0.3:
                                cinterval = 0.03
                        else:
                                cinterval = 0.1
                        cval = [np.ceil(SI.min() / .001) * .001 + k * cinterval for k in range(int(np.ceil((SI.max() - SI.min()) / cinterval)))]
                        cs = ppl.contour(XI, YI, SI, cval, colors = anchor_color, alpha = .5)
                        ppl.clabel(cs)

                        ppl.axis([xmin, xmax, ymin, ymax])
                        ppl.xlabel(&#39;δ$_{47}$ (‰ WG)&#39;)
                        ppl.ylabel(&#39;Δ$_{47}$ (‰)&#39;)
                        ppl.grid(alpha = .15)
                        ppl.title(session, weight = &#39;bold&#39;)
                        ppl.savefig(f&#39;{dir}/D47model_{session}.pdf&#39;)
                        ppl.close(fig)


        def sample_D47_covar(self, sample_1, sample_2 = &#39;&#39;):
                &#39;&#39;&#39;
                Covariance between Δ47 values of samples
                
                Returns the covariance (or the variance, if sample_1 == sample_2)
                between the average Δ47 values of two samples. Also returns the
                variance if only sample_1 is specified.
                &#39;&#39;&#39;
                i = self.normalization.var_names.index(f&#39;D47_{pf(sample_1)}&#39;)
                if sample_2 in [sample_1,&#39;&#39;]:
                        return self.normalization.covar[i,i]
                else:
                        j = self.normalization.var_names.index(f&#39;D47_{pf(sample_2)}&#39;)
                        return self.normalization.covar[i,j]
                        

        def consolidate_samples(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                D47_ref_pop = [r[&#39;D47&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]
                for sample in self.samples:
                        self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                        if self.samples[sample][&#39;N&#39;] &gt; 1:
                                self.samples[sample][&#39;SD_D47&#39;] = stdev([r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]])

                        self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                        self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

                        D47_pop = [r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]]
                        if len(D47_pop) &gt; 1:
                                self.samples[sample][&#39;p_Levene&#39;] = levene(D47_ref_pop, D47_pop, center = &#39;median&#39;)[1]

                if self.normalization_method == &#39;integrated_fit&#39;:
                        for sample in self.anchors:
                                self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                                self.samples[sample][&#39;SE_D47&#39;] = 0.
                        for sample in self.unknowns:
                                self.samples[sample][&#39;D47&#39;] = self.normalization.params.valuesdict()[f&#39;D47_{pf(sample)}&#39;]
                                self.samples[sample][&#39;SE_D47&#39;] = self.sample_D47_covar(sample)**.5

                elif self.normalization_method == &#39;independent_sessions&#39;:
                        for sample in self.anchors:
                                self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                                self.samples[sample][&#39;SE_D47&#39;] = 0.
                        for sample in self.unknowns:
                                session_avg = []
                                for session in self.sessions:
                                        sdata = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                                        if sdata:
                                                avg_D47 = np.mean([r[&#39;D47&#39;] for r in sdata])
                                                avg_d47 = np.mean([r[&#39;d47&#39;] for r in sdata])
                                                sigma_s = self.normalization_error(session, avg_d47, avg_D47)
                                                sigma_u = self.repro[&#39;sigma_47&#39;] / len(sdata)**.5
                                                session_avg.append((avg_D47, (sigma_u**2 + sigma_s**2)**.5))
                                self.samples[sample][&#39;D47&#39;], self.samples[sample][&#39;SE_D47&#39;] = w_avg(*zip(*session_avg))


        def consolidate_sessions(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                for session in self.sessions:
                        self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                        self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])

                        self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, sessions = [session])

                if self.normalization_method == &#39;integrated_fit&#39;:
                        for session in self.sessions:

                                self.sessions[session][&#39;Np&#39;] = 3
                                for k in [&#39;scrambling&#39;, &#39;slope&#39;, &#39;wg&#39;]:
                                        if self.sessions[session][f&#39;{k}_drift&#39;]:
                                                self.sessions[session][&#39;Np&#39;] += 1

                                self.sessions[session][&#39;a&#39;] = self.normalization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                                i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_a&#39;] = self.normalization.covar[i,i]**.5

                                self.sessions[session][&#39;b&#39;] = self.normalization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                                i = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_b&#39;] = self.normalization.covar[i,i]**.5

                                self.sessions[session][&#39;c&#39;] = self.normalization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                                i = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_c&#39;] = self.normalization.covar[i,i]**.5

                                self.sessions[session][&#39;a2&#39;] = self.normalization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        i = self.normalization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_a2&#39;] = self.normalization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_a2&#39;] = 0.

                                self.sessions[session][&#39;b2&#39;] = self.normalization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        i = self.normalization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_b2&#39;] = self.normalization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_b2&#39;] = 0.

                                self.sessions[session][&#39;c2&#39;] = self.normalization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        i = self.normalization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                        self.sessions[session][&#39;SE_c2&#39;] = self.normalization.covar[i,i]**.5
                                else:
                                        self.sessions[session][&#39;SE_c2&#39;] = 0.

                                i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                                j = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                                k = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                                self.sessions[session][&#39;CM&#39;] = self.normalization.covar[[i,j,k],:][:,[i,j,k]]

                elif self.normalization_method == &#39;independent_sessions&#39;:
                        pass


        def consolidate_repro(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.repro[&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)

                N_anchor_analyses = len([r for r in self if r[&#39;Sample&#39;] in self.anchors])

                self.repro[&#39;r_D47a&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_D47a&#39;] /= (
                        (N_anchor_analyses - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])) / (N_anchor_analyses - len(self.anchors))
                        )**.5

                self.repro[&#39;r_D47u&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;unknowns&#39;)

                self.repro[&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;all samples&#39;)
                self.repro[&#39;r_D47&#39;] /= (
                        (len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])) / (len(self) - len(self.samples))
                        )**.5


        def consolidate(self,
                tables = True,
                plots = True,
                ):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.consolidate_samples()
                self.consolidate_sessions()
                self.consolidate_repro()

                if tables:
                        self.table_of_sessions()
                        self.table_of_analyses()
                        self.table_of_samples()
                
                if plots:
                        self.plot_sessions()


        def compute_reproducibility(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
                &#39;&#39;&#39;
                Compute external reproducibility of `[r[key] for r in self]`.
                &#39;&#39;&#39;
                # NB: it&#39;s debatable whether rD47 should be computed
                # with Nf = len(self)-len(self.samples) instead of
                # Nf = len(self) - len(self.unknwons) - 3*len(self.sessions)

                if samples == &#39;all samples&#39;:
                        mysamples = [k for k in self.samples]
                elif samples == &#39;anchors&#39;:
                        mysamples = [k for k in self.anchors]
                elif samples == &#39;unknowns&#39;:
                        mysamples = [k for k in self.unknowns]
                else:
                        mysamples = samples

                if sessions == &#39;all sessions&#39;:
                        sessions = [k for k in self.sessions]

                chisq, Nf = 0, 0
                for sample in mysamples :
                        X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                        if len(X) &gt; 1 :
                                Nf += len(X) - 1
                                chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
                r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
                self.vprint(f&#39;External reproducibility of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
                return r

        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Average Δ47 value of a group of samples, accounting for covariance.
                
                Returns the (weighed, optionally) average Δ47 value and associated SE
                of a group of samples. Weights are equal by default. If normalize is
                True, weights will be rescaled so that their sum equals 1.
                
                __Examples__

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])
                ```

                returns the value and SE of [Δ&lt;sub&gt;47&lt;/sub&gt;(X) + 2 Δ&lt;sub&gt;47&lt;/sub&gt;(Y)]/3,
                where Δ&lt;sub&gt;47&lt;/sub&gt;(X) and Δ&lt;sub&gt;47&lt;/sub&gt;(Y) are the average Δ&lt;sub&gt;47&lt;/sub&gt;
                values of samples X and Y, respectively.

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                ```

                returns the value and SE of the difference Δ&lt;sub&gt;47&lt;/sub&gt;(X) - Δ&lt;sub&gt;47&lt;/sub&gt;(Y).
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        weights = [w/s for w in weights]

                try:
#                       indices = [self.normalization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.normalization.covar[indices,:][:,indices]
                        C = array([[self.sample_D47_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][&#39;D47&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)


        def sample_D47_covar(self, sample1, sample2 = &#39;&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if sample2 == &#39;&#39;:
                        sample2 = sample1
                if self.normalization_method == &#39;integrated_fit&#39;:
                        i = self.normalization.var_names.index(f&#39;D47_{pf(sample1)}&#39;)
                        j = self.normalization.var_names.index(f&#39;D47_{pf(sample2)}&#39;)
                        return self.normalization.covar[i, j]           
                elif self.normalization_method == &#39;independent_sessions&#39;:
                        if sample1 == sample2:
                                return self.samples[sample1][&#39;SE_D47&#39;]**2</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.list</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="D47crunch.D47data.ALPHA_18O_ACID_REACTION"><code class="name">var <span class="ident">ALPHA_18O_ACID_REACTION</span></code></dt>
<dd>
<section class="desc"><p>specifies the <sup>18</sup>O/<sup>16</sup>O fractionation factor generally applicable
to acid reactions in the dataset. Currently only used by <code>self.wg()</code>.</p>
<p>By default equal to 1.00813 (calcite reacted at 90 °C, <a href="https://dx.doi.org/10.1016/j.chemgeo.2007.08.005">Kim et al., 2007</a>).</p></section>
</dd>
<dt id="D47crunch.D47data.LEVENE_REF_SAMPLE"><code class="name">var <span class="ident">LEVENE_REF_SAMPLE</span></code></dt>
<dd>
<section class="desc"><p>After the Δ<sub>47</sub> standardization step, each sample is tested to
assess whether the Δ<sub>47</sub> variance within all analyses for that
sample is significantly larger than that observed for a given reference
sample (using <a href="https://en.wikipedia.org/wiki/Levene%27s_test">Levene's test</a>, which yields a p-value corresponding to
the null hypothesis that the underlying variances are equal).</p>
<p><code>LEVENE_REF_SAMPLE</code> (by default equal to <code>'ETH-3'</code>) specifies which
sample should be used as a reference for this test.</p></section>
</dd>
<dt id="D47crunch.D47data.Nominal_D47"><code class="name">var <span class="ident">Nominal_D47</span></code></dt>
<dd>
<section class="desc"><p>Nominal Δ<sub>47</sub> values assigned to the anchor samples, used in particular by
<code>self.normalize()</code> to standardize unknown samples to a carbonate Δ<sub>47</sub>
reference frame.</p>
<p>By default equal to <code>{'ETH-1': 0.258, 'ETH-2': 0.256, 'ETH-3': 0.691}</code> after
<a href="https://doi.org/10.1029/2017GC007385">Bernasconi et al. (2018)</a>.</p></section>
</dd>
<dt id="D47crunch.D47data.R13_VPDB"><code class="name">var <span class="ident">R13_VPDB</span></code></dt>
<dd>
<section class="desc"><p>Absolute (<sup>13</sup>C/<sup>12</sup>C) ratio of VPDB.
By default equal to 0.01118 (<a href="http://www.cnki.com.cn/Article/CJFDTotal-JXTW199004006.htm">Chang &amp; Li, 1990</a>)</p></section>
</dd>
<dt id="D47crunch.D47data.R17_VPDB"><code class="name">var <span class="ident">R17_VPDB</span></code></dt>
<dd>
<section class="desc"><p>Absolute (<sup>17</sup>O/<sup>16</sup>C) ratio of VPDB.
By definition equal to <code>R17_VSMOW * 1.03092 ** lambda_17</code>.</p></section>
</dd>
<dt id="D47crunch.D47data.R17_VSMOW"><code class="name">var <span class="ident">R17_VSMOW</span></code></dt>
<dd>
<section class="desc"><p>Absolute (<sup>17</sup>O/<sup>16</sup>C) ratio of VSMOW.
By default equal to 0.00038475 (<a href="https://dx.doi.org/10.1016/j.chemgeo.2016.08.014">Daëron et al., 2016</a>)</p></section>
</dd>
<dt id="D47crunch.D47data.R18_VPDB"><code class="name">var <span class="ident">R18_VPDB</span></code></dt>
<dd>
<section class="desc"><p>Absolute (<sup>18</sup>O/<sup>16</sup>C) ratio of VPDB.
By definition equal to <code>R18_VSMOW * 1.03092</code>.</p></section>
</dd>
<dt id="D47crunch.D47data.R18_VSMOW"><code class="name">var <span class="ident">R18_VSMOW</span></code></dt>
<dd>
<section class="desc"><p>Absolute (<sup>18</sup>O/<sup>16</sup>C) ratio of VSMOW.
By default equal to 0.0020052 (<a href="https://doi.org/10.1016/0012-821X(76&gt;)90115-1">Baertschi, 1976</a>)</p></section>
</dd>
<dt id="D47crunch.D47data.SAMPLE_CONSTRAINING_WG_COMPOSITION"><code class="name">var <span class="ident">SAMPLE_CONSTRAINING_WG_COMPOSITION</span></code></dt>
<dd>
<section class="desc"><p>specifies the name, δ<sup>13</sup>C<sub>VPDB</sub> and δ<sup>18</sup>O<sub>VPDB</sub>
of the carbonate standard used by <a title="D47crunch.D47data.wg" href="#D47crunch.D47data.wg"><code>D47data.wg()</code></a> to compute the isotopic composition
of the working gas in each session.</p>
<p>By default equal to <code>('ETH-3', 1.71, -1.78)</code> after <a href="https://doi.org/10.1029/2017GC007385">Bernasconi et al. (2018)</a>.</p></section>
</dd>
<dt id="D47crunch.D47data.lambda_17"><code class="name">var <span class="ident">lambda_17</span></code></dt>
<dd>
<section class="desc"><p>Mass-dependent exponent for triple oxygen isotopes.
By default equal to 0.528 (<a href="https://doi.org/10.1002/rcm.2250">Barkan &amp; Luz, 2005</a>)</p></section>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="D47crunch.D47data.assign_timestamps"><code class="name flex">
<span>def <span class="ident">assign_timestamps</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Assign a time field <code>t</code> to each analysis.</p>
<p>If <code>TimeTag</code> is one of the data fields, <code>t</code> is equal within a given session
to <code>TimeTag</code> minus the mean value of <code>TimeTag</code> for that session.
Otherwise, <code>TimeTag</code> is by default equal to the index of each analysis
in the dataset and <code>t</code> is defined as above.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assign_timestamps(self):
        &#39;&#39;&#39;
        Assign a time field `t` to each analysis.
        
        If `TimeTag` is one of the data fields, `t` is equal within a given session
        to `TimeTag` minus the mean value of `TimeTag` for that session.
        Otherwise, `TimeTag` is by default equal to the index of each analysis
        in the dataset and `t` is defined as above.
        &#39;&#39;&#39;
        for session in self.sessions:
                sdata = self.sessions[session][&#39;data&#39;]
                try:
                        t0 = np.mean([r[&#39;TimeTag&#39;] for r in sdata])
                        for r in sdata:
                                r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
                except KeyError:
                        t0 = (len(sdata)-1)/2
                        for t,r in enumerate(sdata):
                                r[&#39;t&#39;] = t - t0</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.compute_bulk_and_clumping_deltas"><code class="name flex">
<span>def <span class="ident">compute_bulk_and_clumping_deltas</span></span>(<span>self, r)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute δ13C_VPDB, δ18O_VSMOW, and raw Δ47, Δ48, Δ49 values for an analysis.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_bulk_and_clumping_deltas(self, r):
        &#39;&#39;&#39;
        Compute δ13C_VPDB, δ18O_VSMOW, and raw Δ47, Δ48, Δ49 values for an analysis.
        &#39;&#39;&#39;

        # Compute working gas R13, R18, and isobar ratios
        R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
        R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
        R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

        # Compute analyte isobar ratios
        R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
        R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
        R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
        R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
        R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

        r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_deltas(R45, R46, D17O = r[&#39;D17O&#39;])
        R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
        R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

        # Compute stochastic isobar ratios of the analyte
        R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                R13, R18, D17O = r[&#39;D17O&#39;]
        )

        # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
        # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
        if (R45 / R45stoch - 1) &gt; 5e-8:
                self.vprint(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):%.3f} ppm&#39;)
        if (R46 / R46stoch - 1) &gt; 5e-8:
                self.vprint(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):%.3f} ppm&#39;)

        # Compute raw clumped isotope anomalies
        r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
        r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
        r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.compute_bulk_deltas"><code class="name flex">
<span>def <span class="ident">compute_bulk_deltas</span></span>(<span>self, R45, R46, D17O=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute δ13C_VPDB and δ18O_VSMOW, by solving the generalized form of equation (17)
from Brand et al. (2010), assuming that d18O_VSMOW is not too big ( 0 ± 50 ‰) and
solving the corresponding second-order Taylor polynomial.
(Appendix A, Daëron et al., 2016, <a href="https://doi.org/10.1016/j.chemgeo.2016.08.014">https://doi.org/10.1016/j.chemgeo.2016.08.014</a>)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_bulk_deltas(self, R45, R46, D17O = 0):
        &#39;&#39;&#39;
        Compute δ13C_VPDB and δ18O_VSMOW, by solving the generalized form of equation (17)
        from Brand et al. (2010), assuming that d18O_VSMOW is not too big ( 0 ± 50 ‰) and
        solving the corresponding second-order Taylor polynomial.
        (Appendix A, Daëron et al., 2016, &lt;https://doi.org/10.1016/j.chemgeo.2016.08.014&gt;)
        &#39;&#39;&#39;

        K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

        A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
        B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
        C = 2 * self.R18_VSMOW
        D = -R46

        aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
        bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
        cc = A + B + C + D

        d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

        R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
        R17 = K * R18 ** self.lambda_17
        R13 = R45 - 2 * R17

        d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

        return d13C_VPDB, d18O_VSMOW</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.compute_isobar_ratios"><code class="name flex">
<span>def <span class="ident">compute_isobar_ratios</span></span>(<span>self, R13, R18, D17O=0, D47=0, D48=0, D49=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute isobar ratios for a sample with isotopic ratios R13 and R18,
optionally accounting for non-zero values of Δ17O and clumped isotope
anomalies, all expressed in permil.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
        &#39;&#39;&#39;
        Compute isobar ratios for a sample with isotopic ratios R13 and R18,
        optionally accounting for non-zero values of Δ17O and clumped isotope
        anomalies, all expressed in permil.
        &#39;&#39;&#39;

        # Compute R17
        R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

        # Compute isotope concentrations
        C12 = (1 + R13) ** -1
        C13 = C12 * R13
        C16 = (1 + R17 + R18) ** -1
        C17 = C16 * R17
        C18 = C16 * R18

        # Compute stochastic isotopologue concentrations
        C626 = C16 * C12 * C16
        C627 = C16 * C12 * C17 * 2
        C628 = C16 * C12 * C18 * 2
        C636 = C16 * C13 * C16
        C637 = C16 * C13 * C17 * 2
        C638 = C16 * C13 * C18 * 2
        C727 = C17 * C12 * C17
        C728 = C17 * C12 * C18 * 2
        C737 = C17 * C13 * C17
        C738 = C17 * C13 * C18 * 2
        C828 = C18 * C12 * C18
        C838 = C18 * C13 * C18

        # Compute stochastic isobar ratios
        R45 = (C636 + C627) / C626
        R46 = (C628 + C637 + C727) / C626
        R47 = (C638 + C728 + C737) / C626
        R48 = (C738 + C828) / C626
        R49 = C838 / C626

        # Account for stochastic anomalies
        R47 *= 1 + D47 / 1000
        R48 *= 1 + D48 / 1000
        R49 *= 1 + D49 / 1000

        # Return isobar ratios
        return R45, R46, R47, R48, R49</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.compute_reproducibility"><code class="name flex">
<span>def <span class="ident">compute_reproducibility</span></span>(<span>self, key, samples='all samples', sessions='all sessions')</span>
</code></dt>
<dd>
<section class="desc"><p>Compute external reproducibility of <code>[r[key] for r in self]</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_reproducibility(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
        &#39;&#39;&#39;
        Compute external reproducibility of `[r[key] for r in self]`.
        &#39;&#39;&#39;
        # NB: it&#39;s debatable whether rD47 should be computed
        # with Nf = len(self)-len(self.samples) instead of
        # Nf = len(self) - len(self.unknwons) - 3*len(self.sessions)

        if samples == &#39;all samples&#39;:
                mysamples = [k for k in self.samples]
        elif samples == &#39;anchors&#39;:
                mysamples = [k for k in self.anchors]
        elif samples == &#39;unknowns&#39;:
                mysamples = [k for k in self.unknowns]
        else:
                mysamples = samples

        if sessions == &#39;all sessions&#39;:
                sessions = [k for k in self.sessions]

        chisq, Nf = 0, 0
        for sample in mysamples :
                X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                if len(X) &gt; 1 :
                        Nf += len(X) - 1
                        chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
        r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
        self.vprint(f&#39;External reproducibility of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
        return r</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.consolidate"><code class="name flex">
<span>def <span class="ident">consolidate</span></span>(<span>self, tables=True, plots=True)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate(self,
        tables = True,
        plots = True,
        ):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        self.consolidate_samples()
        self.consolidate_sessions()
        self.consolidate_repro()

        if tables:
                self.table_of_sessions()
                self.table_of_analyses()
                self.table_of_samples()
        
        if plots:
                self.plot_sessions()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.consolidate_repro"><code class="name flex">
<span>def <span class="ident">consolidate_repro</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate_repro(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        self.repro[&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
        self.repro[&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)

        N_anchor_analyses = len([r for r in self if r[&#39;Sample&#39;] in self.anchors])

        self.repro[&#39;r_D47a&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;anchors&#39;)
        self.repro[&#39;r_D47a&#39;] /= (
                (N_anchor_analyses - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])) / (N_anchor_analyses - len(self.anchors))
                )**.5

        self.repro[&#39;r_D47u&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;unknowns&#39;)

        self.repro[&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;all samples&#39;)
        self.repro[&#39;r_D47&#39;] /= (
                (len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])) / (len(self) - len(self.samples))
                )**.5</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.consolidate_samples"><code class="name flex">
<span>def <span class="ident">consolidate_samples</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate_samples(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        D47_ref_pop = [r[&#39;D47&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]
        for sample in self.samples:
                self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                if self.samples[sample][&#39;N&#39;] &gt; 1:
                        self.samples[sample][&#39;SD_D47&#39;] = stdev([r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]])

                self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

                D47_pop = [r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]]
                if len(D47_pop) &gt; 1:
                        self.samples[sample][&#39;p_Levene&#39;] = levene(D47_ref_pop, D47_pop, center = &#39;median&#39;)[1]

        if self.normalization_method == &#39;integrated_fit&#39;:
                for sample in self.anchors:
                        self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                        self.samples[sample][&#39;SE_D47&#39;] = 0.
                for sample in self.unknowns:
                        self.samples[sample][&#39;D47&#39;] = self.normalization.params.valuesdict()[f&#39;D47_{pf(sample)}&#39;]
                        self.samples[sample][&#39;SE_D47&#39;] = self.sample_D47_covar(sample)**.5

        elif self.normalization_method == &#39;independent_sessions&#39;:
                for sample in self.anchors:
                        self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                        self.samples[sample][&#39;SE_D47&#39;] = 0.
                for sample in self.unknowns:
                        session_avg = []
                        for session in self.sessions:
                                sdata = [r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                                if sdata:
                                        avg_D47 = np.mean([r[&#39;D47&#39;] for r in sdata])
                                        avg_d47 = np.mean([r[&#39;d47&#39;] for r in sdata])
                                        sigma_s = self.normalization_error(session, avg_d47, avg_D47)
                                        sigma_u = self.repro[&#39;sigma_47&#39;] / len(sdata)**.5
                                        session_avg.append((avg_D47, (sigma_u**2 + sigma_s**2)**.5))
                        self.samples[sample][&#39;D47&#39;], self.samples[sample][&#39;SE_D47&#39;] = w_avg(*zip(*session_avg))</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.consolidate_sessions"><code class="name flex">
<span>def <span class="ident">consolidate_sessions</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate_sessions(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        for session in self.sessions:
                self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])

                self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                self.sessions[session][&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, sessions = [session])

        if self.normalization_method == &#39;integrated_fit&#39;:
                for session in self.sessions:

                        self.sessions[session][&#39;Np&#39;] = 3
                        for k in [&#39;scrambling&#39;, &#39;slope&#39;, &#39;wg&#39;]:
                                if self.sessions[session][f&#39;{k}_drift&#39;]:
                                        self.sessions[session][&#39;Np&#39;] += 1

                        self.sessions[session][&#39;a&#39;] = self.normalization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_a&#39;] = self.normalization.covar[i,i]**.5

                        self.sessions[session][&#39;b&#39;] = self.normalization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_b&#39;] = self.normalization.covar[i,i]**.5

                        self.sessions[session][&#39;c&#39;] = self.normalization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_c&#39;] = self.normalization.covar[i,i]**.5

                        self.sessions[session][&#39;a2&#39;] = self.normalization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;scrambling_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_a2&#39;] = self.normalization.covar[i,i]**.5
                        else:
                                self.sessions[session][&#39;SE_a2&#39;] = 0.

                        self.sessions[session][&#39;b2&#39;] = self.normalization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;slope_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_b2&#39;] = self.normalization.covar[i,i]**.5
                        else:
                                self.sessions[session][&#39;SE_b2&#39;] = 0.

                        self.sessions[session][&#39;c2&#39;] = self.normalization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;wg_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_c2&#39;] = self.normalization.covar[i,i]**.5
                        else:
                                self.sessions[session][&#39;SE_c2&#39;] = 0.

                        i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                        j = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                        k = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                        self.sessions[session][&#39;CM&#39;] = self.normalization.covar[[i,j,k],:][:,[i,j,k]]

        elif self.normalization_method == &#39;independent_sessions&#39;:
                pass</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.crunch"><code class="name flex">
<span>def <span class="ident">crunch</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute bulk composition and raw clumped isotope anomalies for all analyses.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crunch(self):
        &#39;&#39;&#39;
        Compute bulk composition and raw clumped isotope anomalies for all analyses.
        &#39;&#39;&#39;
        for i,r in enumerate(self):
                for k in [&#39;D17O&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                        if k not in r:
                                r[k] = 0.
                self.compute_bulk_and_clumping_deltas(r)
        self.vprint(f&#34;Crunched {len(self)} analyses.&#34;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.input"><code class="name flex">
<span>def <span class="ident">input</span></span>(<span>self, txt, sep=',')</span>
</code></dt>
<dd>
<section class="desc"><p>Read <code>txt</code> string in csv format to load analysis data into a <a title="D47crunch.D47data" href="#D47crunch.D47data"><code>D47data</code></a> object.</p>
<p>In the csv string, spaces befor and after field separators (<code>','</code> by default)
are optional. Each line corresponds to a single analysis.</p>
<p>The required fields are:</p>
<ul>
<li><code>UID</code>: a unique identifier</li>
<li><code>Session</code>: an identifier for the analytical session</li>
<li><code>Sample</code>: a sample identifier</li>
<li><code>d45</code>, <code>d46</code>, <code>d47</code>: the working-gas delta values</li>
</ul>
<p>Independently known oxygen-17 anomalies may be provided as <code>D17O</code> (in ‰ relative to
VSMOW, λ = 0.528), and are otherwise assumed to be zero. Working-gas deltas <code>d48</code>
and <code>d49</code> may also be provided, and are also set to 0 otherwise.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>txt</code>: the csv string to read</li>
<li><code>sep</code>: csv separator delimiting the fields</li>
</ul></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def input(self, txt, sep = &#39;,&#39;):
        &#39;&#39;&#39;
        Read `txt` string in csv format to load analysis data into a `D47data` object.

        In the csv string, spaces befor and after field separators (`&#39;,&#39;` by default)
        are optional. Each line corresponds to a single analysis.
        
        The required fields are:
        
        + `UID`: a unique identifier
        + `Session`: an identifier for the analytical session
        + `Sample`: a sample identifier
        + `d45`, `d46`, `d47`: the working-gas delta values

        Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
        VSMOW, λ = 0.528), and are otherwise assumed to be zero. Working-gas deltas `d48`
        and `d49` may also be provided, and are also set to 0 otherwise.
        
        __Parameters__
        
        + `txt`: the csv string to read
        + `sep`: csv separator delimiting the fields
        &#39;&#39;&#39;
        txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
        data = [{k: smart_type(v) for k,v in zip(txt[0], l)} for l in txt[1:]]
        self += data
        self.refresh()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.normalization_error"><code class="name flex">
<span>def <span class="ident">normalization_error</span></span>(<span>self, session, d47, D47)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def normalization_error(self, session, d47, D47):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                a = self.sessions[session][&#39;a&#39;]
                b = self.sessions[session][&#39;b&#39;]
                c = self.sessions[session][&#39;c&#39;]
#               s = pf(session)
#               i = self.normalization.var_names.index(f&#39;a_{s}&#39;)
#               j = self.normalization.var_names.index(f&#39;b_{s}&#39;)
#               k = self.normalization.var_names.index(f&#39;c_{s}&#39;)
#               CM = np.zeros((3,3))
#               CM[0,0] = self.normalization.covar[i,i]
#               CM[0,1] = self.normalization.covar[i,j]
#               CM[0,2] = self.normalization.covar[i,k]
#               CM[1,0] = self.normalization.covar[j,i]
#               CM[1,1] = self.normalization.covar[j,j]
#               CM[1,2] = self.normalization.covar[j,k]
#               CM[2,0] = self.normalization.covar[k,i]
#               CM[2,1] = self.normalization.covar[k,j]
#               CM[2,2] = self.normalization.covar[k,k]
                CM = self.sessions[session][&#39;CM&#39;]

                y, x = d47, D47
                z = a * x + b * y + c
                dxdy = -b / a
                dxdz = a ** -1
                dxda = -x / a
                dxdb = -y / a
                dxdc = -a ** -1
                V = np.array([dxda, dxdb, dxdc])
                sx = (V @ CM @ V.T) ** .5
                return sx</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>self, method='integrated_fit', weighted_sessions=[], consolidate=True, consolidate_tables=True, consolidate_plots=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute absolute Δ47 values for all replicate analyses and for sample averages.
If <code>method</code> argument is set to <code>'integrated_fit'</code>, the normalization processes all sessions
in a single step, assuming that all samples (anchors and unknowns alike) are
homogeneous (i.e. that their true Δ<sub>47</sub> value does not change between sessions).
If <code>method</code> argument is set to <code>'independent_sessions'</code>, the normalization processes each
session independently, based only on anchors analyses.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def normalize(self,
                method = &#39;integrated_fit&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = True,
                consolidate_plots = True,
                ):
                &#39;&#39;&#39;
                Compute absolute Δ47 values for all replicate analyses and for sample averages.
                If `method` argument is set to `&#39;integrated_fit&#39;`, the normalization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous (i.e. that their true Δ&lt;sub&gt;47&lt;/sub&gt; value does not change between sessions).
                If `method` argument is set to `&#39;independent_sessions&#39;`, the normalization processes each
                session independently, based only on anchors analyses.
                &#39;&#39;&#39;

                self.normalization_method = method
                self.assign_timestamps()

                if method == &#39;integrated_fit&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D47data([r for r in self if r[&#39;Session&#39;] in session_group], verbose = self.verbose)
                                        result = X.normalize(method = &#39;integrated_fit&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.vprint(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[&#39;wD47raw&#39;] *= w
                        else:
                                self.vprint(&#39;All weights set to 1 ppm&#39;)
                                for r in self:
                                        r[&#39;wD47raw&#39;] = 0.001

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.vprint(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D47_{pf(sample)}&#39;, value=0.6)

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D47:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.leastsq()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[&#39;D47&#39;] = (r[&#39;D47raw&#39;] - c - b * r[&#39;d47&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[&#39;d47&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.normalization = result
                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result

                elif method == &#39;independent_sessions&#39;:
                        for session in self.sessions:
                                self.sessions[session][&#39;Np&#39;] = 3
                                self.vprint(&#39;&#39;)
                                self.vprint(f&#39;Standardizing session {session}.&#39;)
                                sdata = self.sessions[session][&#39;data&#39;]
                                A = np.array([
                                        [self.Nominal_D47[r[&#39;Sample&#39;]], r[&#39;d47&#39;], 1]
                                        for r in sdata if r[&#39;Sample&#39;] in self.anchors
                                        ])
                                Y = np.array([[r[&#39;D47raw&#39;]] for r in sdata if r[&#39;Sample&#39;] in self.anchors])
                                self.sessions[session][&#39;Na&#39;] = Y.size
                                CM = linalg.inv(A.T @ A)
                                a,b,c = (CM @ A.T @ Y).T[0,:3]

                                self.vprint(f&#39;a = {a:.4f}&#39;)
                                self.vprint(f&#39;b = {b:.2e}&#39;)
                                self.vprint(f&#39;c = {c:.4f}&#39;)
                                self.sessions[session][&#39;a&#39;] = a
                                self.sessions[session][&#39;b&#39;] = b
                                self.sessions[session][&#39;c&#39;] = c
                                self.sessions[session][&#39;CM&#39;] = CM.copy()

                                for r in sdata :
                                        r[&#39;D47&#39;] = ( r[&#39;D47raw&#39;] - b * r[&#39;d47&#39;] - c ) / a
                        
                        Nss = len(self.sessions)
                        Na = len(self)
                        Ns = len(self.samples)
                        Nu = len(self.unknowns)
                        avgD47 = {
                                sample: np.mean([r[&#39;D47&#39;] for r in self if r[&#39;Sample&#39;] == sample])
                                for sample in self.samples
                                }
                        chi2 = np.sum([(r[&#39;D47&#39;] - avgD47[r[&#39;Sample&#39;]])**2 for r in self])
                        rD47 = (chi2/(Na-Nu-3*Nss))**.5
                        self.repro[&#39;sigma_47&#39;] = rD47

                        for session in self.sessions:
                                self.sessions[session][&#39;CM&#39;] *= a**2 * chi2 / (Na-Nu-3*Nss)
                                self.sessions[session][&#39;SE_a&#39;] = self.sessions[session][&#39;CM&#39;][0,0]**.5
                                self.sessions[session][&#39;SE_b&#39;] = self.sessions[session][&#39;CM&#39;][1,1]**.5
                                self.sessions[session][&#39;SE_c&#39;] = self.sessions[session][&#39;CM&#39;][2,2]**.5
                        
#                       self.Nf = np.sum([self.sessions[s][&#39;Na&#39;] - self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        self.Nf = len(self) - len(self.unknowns) - np.sum([self.sessions[s][&#39;Np&#39;] for s in self.sessions])
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)

                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.plot_sessions"><code class="name flex">
<span>def <span class="ident">plot_sessions</span></span>(<span>self, dir='plots', figsize=(8, 8))</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_sessions(self, dir = &#39;plots&#39;, figsize = (8,8)):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        if not os.path.exists(dir):
                os.makedirs(dir)
        anchor_color = &#39;r&#39;
        unknown_color = &#39;b&#39;

        xmin = min([r[&#39;d47&#39;] for r in self])
        xmax = max([r[&#39;d47&#39;] for r in self])
        xmin -= (xmax - xmin)/10
        xmax += (xmax - xmin)/11

        ymin = min([r[&#39;D47&#39;] for r in self])
        ymax = max([r[&#39;D47&#39;] for r in self])
        ymin -= (ymax - ymin)/10
        ymax += (ymax - ymin)/11

        repl_kw = dict(ls = &#39;None&#39;, marker = &#39;x&#39;, mfc = &#39;None&#39;, ms = 4, mew = .67, alpha = 1)
        avg_kw = dict(ls = &#39;-&#39;, marker = &#39;None&#39;, lw = .67, alpha = .67)
        for session in self.sessions:
                fig = ppl.figure( figsize = figsize)
                for sample in self.anchors:
                        db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                        if len(db):
                                repl_kw[&#39;mec&#39;] = anchor_color
                                X = [r[&#39;d47&#39;] for r in db]
                                Y = [r[&#39;D47&#39;] for r in db]
                                ppl.plot(X, Y, **repl_kw)
                        
                                avg_kw[&#39;color&#39;] = anchor_color
                                X = [min(X)-.5, max(X)+.5]
                                Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                ppl.plot(X, Y, **avg_kw)
                        
                for sample in self.unknowns:

                        db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                        if len(db):
                                repl_kw[&#39;mec&#39;] = unknown_color
                                X = [r[&#39;d47&#39;] for r in db]
                                Y = [r[&#39;D47&#39;] for r in db]
                                ppl.plot(X, Y, **repl_kw)

                                avg_kw[&#39;color&#39;] = unknown_color
                                X = [min(X)-.19, max(X)+.19]
                                Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                ppl.plot(X, Y, **avg_kw)

                XI,YI = np.meshgrid(np.linspace(xmin, xmax), np.linspace(ymin, ymax))
                SI = np.array([[self.normalization_error(session, xi, yi) for xi in XI[0,:]] for yi in YI[:,0]])
                rng = np.max(SI) - np.min(SI)
                if rng &lt;= 0.01:
                        cinterval = 0.001
                elif rng &lt;= 0.03:
                        cinterval = 0.004
                elif rng &lt;= 0.1:
                        cinterval = 0.01
                elif rng &lt;= 0.3:
                        cinterval = 0.03
                else:
                        cinterval = 0.1
                cval = [np.ceil(SI.min() / .001) * .001 + k * cinterval for k in range(int(np.ceil((SI.max() - SI.min()) / cinterval)))]
                cs = ppl.contour(XI, YI, SI, cval, colors = anchor_color, alpha = .5)
                ppl.clabel(cs)

                ppl.axis([xmin, xmax, ymin, ymax])
                ppl.xlabel(&#39;δ$_{47}$ (‰ WG)&#39;)
                ppl.ylabel(&#39;Δ$_{47}$ (‰)&#39;)
                ppl.grid(alpha = .15)
                ppl.title(session, weight = &#39;bold&#39;)
                ppl.savefig(f&#39;{dir}/D47model_{session}.pdf&#39;)
                ppl.close(fig)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, filename, sep=',')</span>
</code></dt>
<dd>
<section class="desc"><p>Read file in csv format to load data into a <a title="D47crunch.D47data" href="#D47crunch.D47data"><code>D47data</code></a> object.</p>
<p>In the csv file, spaces befor and after field separators (<code>','</code> by default)
are optional. Each line corresponds to a single analysis.</p>
<p>The required fields are:</p>
<ul>
<li><code>UID</code>: a unique identifier</li>
<li><code>Session</code>: an identifier for the analytical session</li>
<li><code>Sample</code>: a sample identifier</li>
<li><code>d45</code>, <code>d46</code>, <code>d47</code>: the working-gas delta values</li>
</ul>
<p>Independently known oxygen-17 anomalies may be provided as <code>D17O</code> (in ‰ relative to
VSMOW, λ = 0.528), and are otherwise assumed to be zero. Working-gas deltas <code>d48</code>
and <code>d49</code> may also be provided, and are also set to 0 otherwise.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fileneme</code>: the path of the file to read</li>
<li><code>sep</code>: csv separator delimiting the fields</li>
</ul></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, filename, sep = &#39;,&#39;):
        &#39;&#39;&#39;
        Read file in csv format to load data into a `D47data` object.
        
        In the csv file, spaces befor and after field separators (`&#39;,&#39;` by default)
        are optional. Each line corresponds to a single analysis.
        
        The required fields are:
        
        + `UID`: a unique identifier
        + `Session`: an identifier for the analytical session
        + `Sample`: a sample identifier
        + `d45`, `d46`, `d47`: the working-gas delta values

        Independently known oxygen-17 anomalies may be provided as `D17O` (in ‰ relative to
        VSMOW, λ = 0.528), and are otherwise assumed to be zero. Working-gas deltas `d48`
        and `d49` may also be provided, and are also set to 0 otherwise.
        
        __Parameters__
        
        + `fileneme`: the path of the file to read
        + `sep`: csv separator delimiting the fields
        &#39;&#39;&#39;
        with open(filename) as fid:
                self.input(fid.read(), sep = sep)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.refresh"><code class="name flex">
<span>def <span class="ident">refresh</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Update <code>self.sessions</code>, <code>self.samples</code>, <code>self.anchors</code>, and <code>self.unknowns</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh(self):
        &#39;&#39;&#39;
        Update `self.sessions`, `self.samples`, `self.anchors`, and `self.unknowns`.
        &#39;&#39;&#39;
        self.refresh_sessions()
        self.refresh_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.refresh_samples"><code class="name flex">
<span>def <span class="ident">refresh_samples</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Define <code>self.samples</code>, <code>self.anchors</code>, and <code>self.unknowns</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh_samples(self):
        &#39;&#39;&#39;
        Define `self.samples`, `self.anchors`, and `self.unknowns`.
        &#39;&#39;&#39;
        self.samples = {
                s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                for s in sorted({r[&#39;Sample&#39;] for r in self})
                }
        self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D47}
        self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D47}</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.refresh_sessions"><code class="name flex">
<span>def <span class="ident">refresh_sessions</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Update <code>self.sessions</code> and set <code>scrambling_drift</code>, <code>slope_drift</code>, and <code>wg_drift</code>
to <code>False</code> for all sessions.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh_sessions(self):
        &#39;&#39;&#39;
        Update `self.sessions` and set `scrambling_drift`, `slope_drift`, and `wg_drift`
        to `False` for all sessions.
        &#39;&#39;&#39;
        self.sessions = {
                s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                for s in sorted({r[&#39;Session&#39;] for r in self})
                }
        for s in self.sessions:
                self.sessions[s][&#39;scrambling_drift&#39;] = False
                self.sessions[s][&#39;slope_drift&#39;] = False
                self.sessions[s][&#39;wg_drift&#39;] = False</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.report"><code class="name flex">
<span>def <span class="ident">report</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Prints a report on the normalization fit.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def report(self):
        &#39;&#39;&#39;
        Prints a report on the normalization fit.
        &#39;&#39;&#39;
        report_fit(self.normalization)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.sample_D47_covar"><code class="name flex">
<span>def <span class="ident">sample_D47_covar</span></span>(<span>self, sample1, sample2='')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_D47_covar(self, sample1, sample2 = &#39;&#39;):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        if sample2 == &#39;&#39;:
                sample2 = sample1
        if self.normalization_method == &#39;integrated_fit&#39;:
                i = self.normalization.var_names.index(f&#39;D47_{pf(sample1)}&#39;)
                j = self.normalization.var_names.index(f&#39;D47_{pf(sample2)}&#39;)
                return self.normalization.covar[i, j]           
        elif self.normalization_method == &#39;independent_sessions&#39;:
                if sample1 == sample2:
                        return self.samples[sample1][&#39;SE_D47&#39;]**2</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.sample_average"><code class="name flex">
<span>def <span class="ident">sample_average</span></span>(<span>self, samples, weights='equal', normalize=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Average Δ47 value of a group of samples, accounting for covariance.</p>
<p>Returns the (weighed, optionally) average Δ47 value and associated SE
of a group of samples. Weights are equal by default. If normalize is
True, weights will be rescaled so that their sum equals 1.</p>
<p><strong>Examples</strong></p>
<pre><code class="python">self.sample_average(['X','Y'], [1, 2])
</code></pre>
<p>returns the value and SE of [Δ<sub>47</sub>(X) + 2 Δ<sub>47</sub>(Y)]/3,
where Δ<sub>47</sub>(X) and Δ<sub>47</sub>(Y) are the average Δ<sub>47</sub>
values of samples X and Y, respectively.</p>
<pre><code class="python">self.sample_average(['X','Y'], [1, -1], normalize = False)
</code></pre>
<p>returns the value and SE of the difference Δ<sub>47</sub>(X) - Δ<sub>47</sub>(Y).</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Average Δ47 value of a group of samples, accounting for covariance.
                
                Returns the (weighed, optionally) average Δ47 value and associated SE
                of a group of samples. Weights are equal by default. If normalize is
                True, weights will be rescaled so that their sum equals 1.
                
                __Examples__

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])
                ```

                returns the value and SE of [Δ&lt;sub&gt;47&lt;/sub&gt;(X) + 2 Δ&lt;sub&gt;47&lt;/sub&gt;(Y)]/3,
                where Δ&lt;sub&gt;47&lt;/sub&gt;(X) and Δ&lt;sub&gt;47&lt;/sub&gt;(Y) are the average Δ&lt;sub&gt;47&lt;/sub&gt;
                values of samples X and Y, respectively.

                ```python
                self.sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                ```

                returns the value and SE of the difference Δ&lt;sub&gt;47&lt;/sub&gt;(X) - Δ&lt;sub&gt;47&lt;/sub&gt;(Y).
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        weights = [w/s for w in weights]

                try:
#                       indices = [self.normalization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.normalization.covar[indices,:][:,indices]
                        C = array([[self.sample_D47_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][&#39;D47&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.split_samples"><code class="name flex">
<span>def <span class="ident">split_samples</span></span>(<span>self, samples_to_split='all', grouping='by_uid')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_uid&#39;):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        if samples_to_split == &#39;all&#39;:
                samples_to_split = [s for s in self.unknowns]
        gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
        self.grouping = grouping.lower()
        if self.grouping in gkeys:
                gkey = gkeys[self.grouping]
        for r in self:
                if r[&#39;Sample&#39;] in samples_to_split:
                        r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                        r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                elif r[&#39;Sample&#39;] in self.unknowns:
                        r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
        self.refresh_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.table_of_analyses"><code class="name flex">
<span>def <span class="ident">table_of_analyses</span></span>(<span>self, dir='results', filename='analyses.csv')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def table_of_analyses(self, dir = &#39;results&#39;, filename = &#39;analyses.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
                extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
                for f in extra_fields:
                        out[-1] += [f[0]]
                out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,&#39;D47&#39;]
                for r in self:
                        out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                        for f in extra_fields:
                                out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                        out[-1] += [
                                f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47&#39;]:.6f}&#34;
                                ]
#                       print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        </code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.table_of_samples"><code class="name flex">
<span>def <span class="ident">table_of_samples</span></span>(<span>self, dir='results', filename='samples.csv')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def table_of_samples(self, dir = &#39;results&#39;, filename = &#39;samples.csv&#39;):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
        for sample in self.anchors:
                out += [[
                        f&#34;{sample}&#34;,
                        f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                        f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                        f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                        ]]
        for sample in self.unknowns:
                out += [[
                        f&#34;{sample}&#34;,
                        f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                        f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,
                        f&#34;{self.samples[sample][&#39;SE_D47&#39;]:.4f}&#34;,
                        f&#34;± {self.samples[sample][&#39;SE_D47&#39;]*self.t95:.4f}&#34;,
                        f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                        f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;
                        ]]
        print(pretty_table(out))
        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                fid.write(make_csv(out))                        </code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.table_of_sessions"><code class="name flex">
<span>def <span class="ident">table_of_sessions</span></span>(<span>self, dir='results', filename='sessions.csv')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def table_of_sessions(self, dir = &#39;results&#39;, filename = &#39;sessions.csv&#39;):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        out = []
        out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
        out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
        out += [[&#39;External reproducibility of δ13C_VPDB&#39;, f&#34;{1000 * self.repro[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
        out += [[&#39;External reproducibility of δ18O_VSMOW&#39;, f&#34;{1000 * self.repro[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
        out += [[&#39;External reproducibility of Δ47 (anchors)&#39;, f&#34;{1000 * self.repro[&#39;r_D47a&#39;]:.1f} ppm&#34;]]
        out += [[&#39;External reproducibility of Δ47 (unknowns)&#39;, f&#34;{1000 * self.repro[&#39;r_D47u&#39;]:.1f} ppm&#34;]]
        out += [[&#39;External reproducibility of Δ47 (all)&#39;, f&#34;{1000 * self.repro[&#39;r_D47&#39;]:.1f} ppm&#34;]]
        out += [[&#39;Degrees of freedom (Student\&#39;s 95% t-factor)&#39;, f&#34;{self.Nf} ({self.t95:.2f})&#34;]]
        out += [[&#39;Standardization method&#39;, self.normalization_method]]
        print(pretty_table(out, header = 0)) 
        
        include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
        include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
        include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])
        out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,&#39;r_D47&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
        if include_a2:
                out[-1] += [&#39;a2 ± SE&#39;]
        if include_b2:
                out[-1] += [&#39;b2 ± SE&#39;]
        if include_c2:
                out[-1] += [&#39;c2 ± SE&#39;]
        for session in self.sessions:
                out += [[
                        session,
                        f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                        f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                        f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][&#39;r_D47&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                        f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                        ]]
                if include_a2:
                        if self.sessions[session][&#39;scrambling_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]
                if include_b2:
                        if self.sessions[session][&#39;slope_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]
                if include_c2:
                        if self.sessions[session][&#39;wg_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]

        print(pretty_table(out))
        if not os.path.exists(dir):
                os.makedirs(dir)
        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                fid.write(make_csv(out))</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.unsplit_samples"><code class="name flex">
<span>def <span class="ident">unsplit_samples</span></span>(<span>self, tables=True)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def unsplit_samples(self, tables = True):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                unknowns_old = sorted({s for s in self.unknowns})
                CM_old = self.normalization.covar[:,:]
                VD_old = self.normalization.params.valuesdict().copy()
                vars_old = self.normalization.var_names

                unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})
                
                Ns = len(vars_old) - len(unknowns_old)
                vars_new = vars_old[:Ns] + [f&#39;D47_{pf(u)}&#39; for u in unknowns_new]
                VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

                W = np.zeros((len(vars_new), len(vars_old)))
                W[:Ns,:Ns] = np.eye(Ns)
                for u in unknowns_new:
                        splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                        if self.grouping == &#39;by_session&#39;:
                                weights = [self.samples[s][&#39;SE_D47&#39;]**-2 for s in splits]
                        elif self.grouping == &#39;by_uid&#39;:
                                weights = [1 for s in splits]
                        sw = sum(weights)
                        weights = [w/sw for w in weights]
                        W[vars_new.index(f&#39;D47_{pf(u)}&#39;),[vars_old.index(f&#39;D47_{pf(s)}&#39;) for s in splits]] = weights[:]
#               print(&#39;\nUnsplitting weights matrix:&#39;)
#               print(&#39;\n&#39;.join([&#39; &#39;.join([f&#39;{x:.1f}&#39; if x else &#39; - &#39; for x in l]) for l in W]))
#               print(&#39;---&#39;)

                CM_new = W @ CM_old @ W.T
                V = W @ np.array([[VD_old[k]] for k in vars_old])
                VD_new = {k:v[0] for k,v in zip(vars_new, V)}
                
                self.normalization.covar = CM_new
                self.normalization.params.valuesdict = lambda : VD_new
                self.normalization.var_names = vars_new

                for r in self:
                        if r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]
                
                self.refresh_samples()
                self.consolidate_samples()
                self.consolidate_repro()

                if tables:
                        self.table_of_analyses()
                        self.table_of_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.vprint"><code class="name flex">
<span>def <span class="ident">vprint</span></span>(<span>self, txt)</span>
</code></dt>
<dd>
<section class="desc"><p>Print verbose message <code>txt</code> to screen if <code>self.verbose == True</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vprint(self, txt):
        &#39;&#39;&#39;
        Print verbose message `txt` to screen if `self.verbose == True`.
        &#39;&#39;&#39;
        if self.verbose:
                print(f&#39;{self.msgcolor}[D47data]   {txt}\033[0m&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.wg"><code class="name flex">
<span>def <span class="ident">wg</span></span>(<span>self, sample='', d13C_vpdb='', d18O_vpdb='', a18_acid='')</span>
</code></dt>
<dd>
<section class="desc"><p>Compute bulk composition of the working gas for each session
based on the average composition, within each session,
of a given sample.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wg(self, sample = &#39;&#39;, d13C_vpdb = &#39;&#39;, d18O_vpdb = &#39;&#39;, a18_acid = &#39;&#39;):
        &#39;&#39;&#39;
        Compute bulk composition of the working gas for each session
        based on the average composition, within each session,
        of a given sample.
        &#39;&#39;&#39;

        self.vprint(f&#34;Computing working gas composition:&#34;)

        if sample == &#39;&#39;:
                sample = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[0]
        if d13C_vpdb == &#39;&#39;:
                d13C_vpdb = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[1]
        if d18O_vpdb == &#39;&#39;:
                d18O_vpdb = self.SAMPLE_CONSTRAINING_WG_COMPOSITION[2]
        if a18_acid == &#39;&#39;:
                a18_acid = self.ALPHA_18O_ACID_REACTION

        R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
        R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
        R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

        C12_s = 1 / (1 + R13_s)
        C13_s = R13_s / (1 + R13_s)
        C16_s = 1 / (1 + R17_s + R18_s)
        C17_s = R17_s / (1 + R17_s + R18_s)
        C18_s = R18_s / (1 + R17_s + R18_s)

        C626_s = C12_s * C16_s ** 2
        C627_s = 2 * C12_s * C16_s * C17_s
        C628_s = 2 * C12_s * C16_s * C18_s
        C636_s = C13_s * C16_s ** 2
        C637_s = 2 * C13_s * C16_s * C17_s
        C727_s = C12_s * C17_s ** 2

        R45_s = (C627_s + C636_s) / C626_s
        R46_s = (C628_s + C637_s + C727_s) / C626_s

        for s in self.sessions:
                db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                d45_s = np.mean([r[&#39;d45&#39;] for r in db])
                d46_s = np.mean([r[&#39;d46&#39;] for r in db])
                R45_wg = R45_s / (1 + d45_s / 1000)
                R46_wg = R46_s / (1 + d46_s / 1000)

                d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_deltas(R45_wg, R46_wg)

                self.vprint(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                for r in self.sessions[s][&#39;data&#39;]:
                        r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="D47crunch.correlated_sum" href="#D47crunch.correlated_sum">correlated_sum</a></code></li>
<li><code><a title="D47crunch.make_csv" href="#D47crunch.make_csv">make_csv</a></code></li>
<li><code><a title="D47crunch.pf" href="#D47crunch.pf">pf</a></code></li>
<li><code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table</a></code></li>
<li><code><a title="D47crunch.smart_type" href="#D47crunch.smart_type">smart_type</a></code></li>
<li><code><a title="D47crunch.transpose_table" href="#D47crunch.transpose_table">transpose_table</a></code></li>
<li><code><a title="D47crunch.w_avg" href="#D47crunch.w_avg">w_avg</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code></h4>
<ul class="">
<li><code><a title="D47crunch.D47data.ALPHA_18O_ACID_REACTION" href="#D47crunch.D47data.ALPHA_18O_ACID_REACTION">ALPHA_18O_ACID_REACTION</a></code></li>
<li><code><a title="D47crunch.D47data.LEVENE_REF_SAMPLE" href="#D47crunch.D47data.LEVENE_REF_SAMPLE">LEVENE_REF_SAMPLE</a></code></li>
<li><code><a title="D47crunch.D47data.Nominal_D47" href="#D47crunch.D47data.Nominal_D47">Nominal_D47</a></code></li>
<li><code><a title="D47crunch.D47data.R13_VPDB" href="#D47crunch.D47data.R13_VPDB">R13_VPDB</a></code></li>
<li><code><a title="D47crunch.D47data.R17_VPDB" href="#D47crunch.D47data.R17_VPDB">R17_VPDB</a></code></li>
<li><code><a title="D47crunch.D47data.R17_VSMOW" href="#D47crunch.D47data.R17_VSMOW">R17_VSMOW</a></code></li>
<li><code><a title="D47crunch.D47data.R18_VPDB" href="#D47crunch.D47data.R18_VPDB">R18_VPDB</a></code></li>
<li><code><a title="D47crunch.D47data.R18_VSMOW" href="#D47crunch.D47data.R18_VSMOW">R18_VSMOW</a></code></li>
<li><code><a title="D47crunch.D47data.SAMPLE_CONSTRAINING_WG_COMPOSITION" href="#D47crunch.D47data.SAMPLE_CONSTRAINING_WG_COMPOSITION">SAMPLE_CONSTRAINING_WG_COMPOSITION</a></code></li>
<li><code><a title="D47crunch.D47data.assign_timestamps" href="#D47crunch.D47data.assign_timestamps">assign_timestamps</a></code></li>
<li><code><a title="D47crunch.D47data.compute_bulk_and_clumping_deltas" href="#D47crunch.D47data.compute_bulk_and_clumping_deltas">compute_bulk_and_clumping_deltas</a></code></li>
<li><code><a title="D47crunch.D47data.compute_bulk_deltas" href="#D47crunch.D47data.compute_bulk_deltas">compute_bulk_deltas</a></code></li>
<li><code><a title="D47crunch.D47data.compute_isobar_ratios" href="#D47crunch.D47data.compute_isobar_ratios">compute_isobar_ratios</a></code></li>
<li><code><a title="D47crunch.D47data.compute_reproducibility" href="#D47crunch.D47data.compute_reproducibility">compute_reproducibility</a></code></li>
<li><code><a title="D47crunch.D47data.consolidate" href="#D47crunch.D47data.consolidate">consolidate</a></code></li>
<li><code><a title="D47crunch.D47data.consolidate_repro" href="#D47crunch.D47data.consolidate_repro">consolidate_repro</a></code></li>
<li><code><a title="D47crunch.D47data.consolidate_samples" href="#D47crunch.D47data.consolidate_samples">consolidate_samples</a></code></li>
<li><code><a title="D47crunch.D47data.consolidate_sessions" href="#D47crunch.D47data.consolidate_sessions">consolidate_sessions</a></code></li>
<li><code><a title="D47crunch.D47data.crunch" href="#D47crunch.D47data.crunch">crunch</a></code></li>
<li><code><a title="D47crunch.D47data.input" href="#D47crunch.D47data.input">input</a></code></li>
<li><code><a title="D47crunch.D47data.lambda_17" href="#D47crunch.D47data.lambda_17">lambda_17</a></code></li>
<li><code><a title="D47crunch.D47data.normalization_error" href="#D47crunch.D47data.normalization_error">normalization_error</a></code></li>
<li><code><a title="D47crunch.D47data.normalize" href="#D47crunch.D47data.normalize">normalize</a></code></li>
<li><code><a title="D47crunch.D47data.plot_sessions" href="#D47crunch.D47data.plot_sessions">plot_sessions</a></code></li>
<li><code><a title="D47crunch.D47data.read" href="#D47crunch.D47data.read">read</a></code></li>
<li><code><a title="D47crunch.D47data.refresh" href="#D47crunch.D47data.refresh">refresh</a></code></li>
<li><code><a title="D47crunch.D47data.refresh_samples" href="#D47crunch.D47data.refresh_samples">refresh_samples</a></code></li>
<li><code><a title="D47crunch.D47data.refresh_sessions" href="#D47crunch.D47data.refresh_sessions">refresh_sessions</a></code></li>
<li><code><a title="D47crunch.D47data.report" href="#D47crunch.D47data.report">report</a></code></li>
<li><code><a title="D47crunch.D47data.sample_D47_covar" href="#D47crunch.D47data.sample_D47_covar">sample_D47_covar</a></code></li>
<li><code><a title="D47crunch.D47data.sample_average" href="#D47crunch.D47data.sample_average">sample_average</a></code></li>
<li><code><a title="D47crunch.D47data.split_samples" href="#D47crunch.D47data.split_samples">split_samples</a></code></li>
<li><code><a title="D47crunch.D47data.table_of_analyses" href="#D47crunch.D47data.table_of_analyses">table_of_analyses</a></code></li>
<li><code><a title="D47crunch.D47data.table_of_samples" href="#D47crunch.D47data.table_of_samples">table_of_samples</a></code></li>
<li><code><a title="D47crunch.D47data.table_of_sessions" href="#D47crunch.D47data.table_of_sessions">table_of_sessions</a></code></li>
<li><code><a title="D47crunch.D47data.unsplit_samples" href="#D47crunch.D47data.unsplit_samples">unsplit_samples</a></code></li>
<li><code><a title="D47crunch.D47data.vprint" href="#D47crunch.D47data.vprint">vprint</a></code></li>
<li><code><a title="D47crunch.D47data.wg" href="#D47crunch.D47data.wg">wg</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>