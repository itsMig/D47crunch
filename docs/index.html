<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>D47crunch API documentation</title>
<meta name="description" content="Carbonate clumped-isotope data processing and error propagation …" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>D47crunch</code></h1>
</header>
<section id="section-intro">
<p>Carbonate clumped-isotope data processing and error propagation</p>
<p>This library is designed to process and standardize carbonate clumped-isotope
analyses, from low-level data out of a dual-inlet mass spectrometer to final,
“absolute” Δ47 values with fully propagated analytical error estimates.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#! /usr/bin/env python3
&#39;&#39;&#39;
Carbonate clumped-isotope data processing and error propagation

This library is designed to process and standardize carbonate clumped-isotope
analyses, from low-level data out of a dual-inlet mass spectrometer to final,
“absolute” Δ47 values with fully propagated analytical error estimates.
&#39;&#39;&#39;

__author__ = &#39;Mathieu Daëron&#39;
__contact__ = &#39;daeron@lsce.ipsl.fr&#39;
__copyright__ = &#39;Copyright (c) 2020 Mathieu Daëron&#39;
__license__ = &#39;Modified BSD License - https://opensource.org/licenses/BSD-3-Clause&#39;
__date__ = &#39;2020-02-08&#39;
__version__ = &#39;0.1&#39;


import os
import numpy as np
from statistics import stdev
from scipy.stats import t as tstudent
from scipy.stats import levene
from numpy import linalg
from lmfit import Minimizer, Parameters, report_fit
from matplotlib import pyplot as ppl
from matplotlib import rcParams

rcParams[&#39;font.family&#39;] = &#39;sans-serif&#39;
rcParams[&#39;font.sans-serif&#39;] = &#39;Helvetica&#39;
rcParams[&#39;font.size&#39;] = 10
rcParams[&#39;mathtext.fontset&#39;] = &#39;custom&#39;
rcParams[&#39;mathtext.rm&#39;] = &#39;sans&#39;
rcParams[&#39;mathtext.bf&#39;] = &#39;sans:bold&#39;
rcParams[&#39;mathtext.it&#39;] = &#39;sans:italic&#39;
rcParams[&#39;mathtext.cal&#39;] = &#39;sans:italic&#39;
rcParams[&#39;mathtext.default&#39;] = &#39;rm&#39;
rcParams[&#39;xtick.major.size&#39;] = 4
rcParams[&#39;xtick.major.width&#39;] = 1
rcParams[&#39;ytick.major.size&#39;] = 4
rcParams[&#39;ytick.major.width&#39;] = 1
rcParams[&#39;axes.grid&#39;] = False
rcParams[&#39;axes.linewidth&#39;] = 1
rcParams[&#39;grid.linewidth&#39;] = .75
rcParams[&#39;grid.linestyle&#39;] = &#39;-&#39;
rcParams[&#39;grid.alpha&#39;] = .15
rcParams[&#39;savefig.dpi&#39;] = 150


def smart_type(x):
        &#39;&#39;&#39;
        Tries to convert a string to a float if it includes &#39;.&#39;,
        or to an integer if it does not. If both attempts fail,
        return the original string unchanged.
        &#39;&#39;&#39;
        try:
                y = float(x)
        except ValueError:
                return x
        if &#39;.&#39; not in x:
                return int(y)
        return y


def pf(txt):
        &#39;&#39;&#39;
        Modify string `txt` to follow `lmfit.Parameter()` naming rules.
        &#39;&#39;&#39;
        return txt.replace(&#39;-&#39;,&#39;_&#39;).replace(&#39;.&#39;,&#39;_&#39;)


def pretty_table(x, header = 1, hsep = &#39;  &#39;, vsep = &#39;-&#39;):
        &#39;&#39;&#39;
        Reads a list of lists of strings and outputs an ascii table.
        &#39;&#39;&#39;
        txt = [&#39;&#39;]
        widths = [np.max([len(e) for e in c]) for c in zip(*x)]
        
        align = &#39;&lt;&#39; + &#39;&gt;&#39;*(len(widths)-1)
        sepline = hsep.join([vsep*w for w in widths])
        txt += [sepline]
        for k,l in enumerate(x):
                if k and k == header:
                        txt += [sepline]
                txt += [hsep.join([f&#39;{e:{a}{w}}&#39; for e, w, a in zip(l, widths, align)])]
        txt += [sepline]
        txt += [&#39;&#39;]
        return &#39;\n&#39;.join(txt)


def make_csv(x, hsep = &#39;,&#39;, vsep = &#39;\n&#39;):
        &#39;&#39;&#39;
        Reads a list of lists of strings and outputs a csv table.
        &#39;&#39;&#39;
        return vsep.join([hsep.join(l) for l in x])


def transpose_table(x):
        &#39;&#39;&#39;
        Transpose a list if lists.
        &#39;&#39;&#39;
        return [[e for e in c] for c in zip(*x)]


def correlated_sum(X,C,f = &#39;&#39;):
        &#39;&#39;&#39;
        Return the mean and SE of the sum of the elements
        of X, optionally weighted by the elements of f,
        accounting for C the covariance matrix of X.
        &#39;&#39;&#39;
        if f == &#39;&#39;: f = [1 for x in X]
        return np.dot(f,X), (np.dot(f,np.dot(C,f)))**.5


def w_avg(X, sX) :
        &#39;&#39;&#39;
        Compute weighted average.
        &#39;&#39;&#39;
        X = [ x for x in X ]
        sX = [ sx for sx in sX ]
        W = [ sx**-2 for sx in sX ]
        W = [ w/sum(W) for w in W ]
        Xavg = sum([ w*x for w,x in zip(W,X) ])
        sXavg = sum([ w**2*sx**2 for w,sx in zip(W,sX) ])**.5
        return Xavg, sXavg


class D47data(list):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ47 analyses.
        &#39;&#39;&#39;

        ### 17O CORRECTION PARAMETERS
        R13_VPDB = 0.01118  # (Chang &amp; Li, 1990)
        R18_VSMOW = 0.0020052  # (Baertschi, 1976)
        lambda_17 = 0.528  # (Barkan &amp; Luz, 2005)
        R17_VSMOW = 0.00038475  # (Assonov &amp; Brenninkmeijer, 2003, rescaled to R13_VPDB)
        R18_VPDB = R18_VSMOW * 1.03092
        R17_VPDB = R17_VSMOW * 1.03092 ** lambda_17

        LEVENE_REF_SAMPLE = &#39;ETH-3&#39;
        SAMPLE_CONSTRAINING_WG_COMPOSITION = &#39;ETH-3&#39;
        d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION = 1.71  # (Bernasconi et al., 2018)
        d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION = -1.78 # (Bernasconi et al., 2018)
        T_ACID = 90.0
        ALPHA_18O_ACID_REACTION = np.exp(3.59 / (T_ACID + 273.15) - 1.79e-3)  # (Kim et al., 2007, calcite)

        Nominal_D47 = {
                &#39;ETH-1&#39;: 0.258,
                &#39;ETH-2&#39;: 0.256,
                &#39;ETH-3&#39;: 0.691,
                }       # (Bernasconi et al., 2018)


        def __init__(self, l = [], verbose = False, msgcolor = &#39;\033[92m&#39;):
                self.verbose = verbose
                self.msgcolor = msgcolor
                list.__init__(self, l)
#               self.R13_VPDB = D47data.R13_VPDB
#               self.R18_VSMOW = D47data.R18_VSMOW
#               self.lambda_17 = D47data.lambda_17
#               self.R18_VPDB = D47data.R18_VPDB
#               self.R17_VPDB = D47data.R17_VPDB
#               self.SAMPLE_CONSTRAINING_WG_COMPOSITION = D47data.SAMPLE_CONSTRAINING_WG_COMPOSITION
#               self.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION = D47data.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
#               self.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION = D47data.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
#               self.ALPHA_18O_ACID_REACTION = D47data.ALPHA_18O_ACID_REACTION
#               self.Nominal_D47 = D47data.Nominal_D47.copy()
                self.Nf = None
                self.repro = {}
                self.refresh()


        def vprint(self, txt):
                &#39;&#39;&#39;
                Print log message to screen if D47data.verbose is true.
                &#39;&#39;&#39;
                if self.verbose:
                        print(f&#39;{self.msgcolor}[D47data]   {txt}\033[0m&#39;)


        def refresh(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.refresh_sessions()
                self.refresh_samples()


        def refresh_sessions(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.sessions = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                        for s in sorted({r[&#39;Session&#39;] for r in self})
                        }
                for s in self.sessions:
                        self.sessions[s][&#39;scrambling_drift&#39;] = False
                        self.sessions[s][&#39;slope_drift&#39;] = False
                        self.sessions[s][&#39;wg_drift&#39;] = False


        def refresh_samples(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.samples = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                        for s in sorted({r[&#39;Sample&#39;] for r in self})
                        }
                self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D47}
                self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D47}


        def read(self, file, sep = &#39;,&#39;):
                &#39;&#39;&#39;
                Read file in csv format to load analysis data into a D47data object.
                Use &#39;sep&#39; argument to define the csv separator.
                &#39;&#39;&#39;
                with open(file) as fid:
                        self.input(fid.read(), sep = sep)


        def input(self, txt, sep = &#39;,&#39;):
                &#39;&#39;&#39;
                Read string in csv format to load analysis data into a D47data object.
                Use &#39;sep&#39; argument to define the csv separator.
                &#39;&#39;&#39;
                txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
                data = [{k: smart_type(v) for k,v in zip(txt[0], l)} for l in txt[1:]]
                self += data
                self.refresh()


        def wg(self):
                &#39;&#39;&#39;
                Compute bulk composition of the working gas for each session
                based on the average composition, within each session,
                of a given sample.
                &#39;&#39;&#39;

                self.vprint(f&#34;Computing working gas composition:&#34;)

                sample = self.SAMPLE_CONSTRAINING_WG_COMPOSITION
                d13C_vpdb = self.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
                d18O_vpdb = self.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
                a18_acid = self.ALPHA_18O_ACID_REACTION

                R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
                R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
                R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

                C12_s = 1 / (1 + R13_s)
                C13_s = R13_s / (1 + R13_s)
                C16_s = 1 / (1 + R17_s + R18_s)
                C17_s = R17_s / (1 + R17_s + R18_s)
                C18_s = R18_s / (1 + R17_s + R18_s)

                C626_s = C12_s * C16_s ** 2
                C627_s = 2 * C12_s * C16_s * C17_s
                C628_s = 2 * C12_s * C16_s * C18_s
                C636_s = C13_s * C16_s ** 2
                C637_s = 2 * C13_s * C16_s * C17_s
                C727_s = C12_s * C17_s ** 2

                R45_s = (C627_s + C636_s) / C626_s
                R46_s = (C628_s + C637_s + C727_s) / C626_s

                for s in self.sessions:
                        db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                        d45_s = np.mean([r[&#39;d45&#39;] for r in db])
                        d46_s = np.mean([r[&#39;d46&#39;] for r in db])
                        R45_wg = R45_s / (1 + d45_s / 1000)
                        R46_wg = R46_s / (1 + d46_s / 1000)

                        d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_deltas(R45_wg, R46_wg)

                        self.vprint(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                        self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                        for r in self.sessions[s][&#39;data&#39;]:
                                r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                                r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW


        def compute_bulk_deltas(self, R45, R46, D17O = 0):
                &#39;&#39;&#39;
                Compute δ13C_VPDB and δ18O_VSMOW, by solving the generalized form of equation (17)
                from Brand et al. (2010), assuming that d18O_VSMOW is not too big ( 0 ± 50 ‰) and
                solving the corresponding second-order Taylor polynomial.
                (Appendix A, Daëron et al., 2016, &lt;https://doi.org/10.1016/j.chemgeo.2016.08.014&gt;)
                &#39;&#39;&#39;

                K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

                A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
                B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
                C = 2 * self.R18_VSMOW
                D = -R46

                aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
                bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
                cc = A + B + C + D

                d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

                R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
                R17 = K * R18 ** self.lambda_17
                R13 = R45 - 2 * R17

                d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

                return d13C_VPDB, d18O_VSMOW


        def crunch(self):
                &#39;&#39;&#39;
                Compute bulk composition and raw clumped isotope anomalies for all analyses.
                &#39;&#39;&#39;
                for i,r in enumerate(self):
                        for k in [&#39;D17O&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                                if k not in r:
                                        r[k] = 0.
                        self.compute_bulk_and_clumping_deltas(r)
                self.vprint(f&#34;Crunched {len(self)} analyses.&#34;)


        def compute_bulk_and_clumping_deltas(self, r):
                &#39;&#39;&#39;
                Compute δ13C_VPDB, δ18O_VSMOW, and raw Δ47, Δ48, Δ49 values for an analysis.
                &#39;&#39;&#39;

                # Compute working gas R13, R18, and isobar ratios
                R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
                R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
                R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

                # Compute analyte isobar ratios
                R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
                R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
                R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
                R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
                R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

                r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_deltas(R45, R46, D17O = r[&#39;D17O&#39;])
                R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
                R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

                # Compute stochastic isobar ratios of the analyte
                R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                        R13, R18, D17O = r[&#39;D17O&#39;]
                )

                # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
                # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
                if (R45 / R45stoch - 1) &gt; 5e-8:
                        self.vprint(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):%.3f} ppm&#39;)
                if (R46 / R46stoch - 1) &gt; 5e-8:
                        self.vprint(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):%.3f} ppm&#39;)

                # Compute raw clumped isotope anomalies
                r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
                r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
                r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)

        def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
                &#39;&#39;&#39;
                Compute isobar ratios for a sample with isotopic ratios R13 and R18,
                optionally accounting for non-zero values of Δ17O and clumped isotope
                anomalies, all expressed in permil.
                &#39;&#39;&#39;

                # Compute R17
                R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

                # Compute isotope concentrations
                C12 = (1 + R13) ** -1
                C13 = C12 * R13
                C16 = (1 + R17 + R18) ** -1
                C17 = C16 * R17
                C18 = C16 * R18

                # Compute stochastic isotopologue concentrations
                C626 = C16 * C12 * C16
                C627 = C16 * C12 * C17 * 2
                C628 = C16 * C12 * C18 * 2
                C636 = C16 * C13 * C16
                C637 = C16 * C13 * C17 * 2
                C638 = C16 * C13 * C18 * 2
                C727 = C17 * C12 * C17
                C728 = C17 * C12 * C18 * 2
                C737 = C17 * C13 * C17
                C738 = C17 * C13 * C18 * 2
                C828 = C18 * C12 * C18
                C838 = C18 * C13 * C18

                # Compute stochastic isobar ratios
                R45 = (C636 + C627) / C626
                R46 = (C628 + C637 + C727) / C626
                R47 = (C638 + C728 + C737) / C626
                R48 = (C738 + C828) / C626
                R49 = C838 / C626

                # Account for stochastic anomalies
                R47 *= 1 + D47 / 1000
                R48 *= 1 + D48 / 1000
                R49 *= 1 + D49 / 1000

                # Return isobar ratios
                return R45, R46, R47, R48, R49

        def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_uid&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if samples_to_split == &#39;all&#39;:
                        samples_to_split = [s for s in self.unknowns]
                gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
                self.grouping = grouping.lower()
                if self.grouping in gkeys:
                        gkey = gkeys[self.grouping]
                for r in self:
                        if r[&#39;Sample&#39;] in samples_to_split:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                        elif r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                self.refresh_samples()


        def unsplit_samples(self, tables = True):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                unknowns_old = sorted({s for s in self.unknowns})
                CM_old = self.normalization.covar[:,:]
                VD_old = self.normalization.params.valuesdict().copy()
                vars_old = self.normalization.var_names

                unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})
                
                Ns = len(vars_old) - len(unknowns_old)
                vars_new = vars_old[:Ns] + [f&#39;D47_{pf(u)}&#39; for u in unknowns_new]
                VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

                W = np.zeros((len(vars_new), len(vars_old)))
                W[:Ns,:Ns] = np.eye(Ns)
                for u in unknowns_new:
                        splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                        if self.grouping == &#39;by_session&#39;:
                                weights = [self.samples[s][&#39;SE_D47&#39;]**-2 for s in splits]
                        elif self.grouping == &#39;by_uid&#39;:
                                weights = [1 for s in splits]
                        sw = sum(weights)
                        weights = [w/sw for w in weights]
                        W[vars_new.index(f&#39;D47_{pf(u)}&#39;),[vars_old.index(f&#39;D47_{pf(s)}&#39;) for s in splits]] = weights[:]
#               print(&#39;\nUnsplitting weights matrix:&#39;)
#               print(&#39;\n&#39;.join([&#39; &#39;.join([f&#39;{x:.1f}&#39; if x else &#39; - &#39; for x in l]) for l in W]))
#               print(&#39;---&#39;)

                CM_new = W @ CM_old @ W.T
                V = W @ np.array([[VD_old[k]] for k in vars_old])
                VD_new = {k:v[0] for k,v in zip(vars_new, V)}
                
                self.normalization.covar = CM_new
                self.normalization.params.valuesdict = lambda : VD_new
                self.normalization.var_names = vars_new

                for r in self:
                        if r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]
                
                self.refresh_samples()
                self.consolidate_samples()
                self.consolidate_repro()

                if tables:
                        self.table_of_analyses()
                        self.table_of_samples()

        def normalize(self,
                method = &#39;lmfit&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = True,
                consolidate_plots = True,
                ):
                &#39;&#39;&#39;
                Compute absolute Δ47 values for all replicate analyses and for sample averages.
                If &#34;method&#34; argument is set to &#34;lmfit&#34;, the normalization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous (i.e. that their true Δ47 value does not change between sessions).
                If &#34;method&#34; argument is set to &#34;indep_sessions&#34;, the normalization processes each
                session independently.
                &#39;&#39;&#39;
                if method == &#39;lmfit&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D47data([r for r in self if r[&#39;Session&#39;] in session_group], verbose = self.verbose)
                                        result = X.normalize(method = &#39;lmfit&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.vprint(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[&#39;wD47raw&#39;] *= w
                        else:
                                self.vprint(&#39;All weights set to 1 ppm&#39;)
                                for r in self:
                                        r[&#39;wD47raw&#39;] = 0.001

                        for s in self.sessions:
                                G = self.sessions[s][&#39;data&#39;]
                                try:
                                        t0 = np.mean([r[&#39;TimeTag&#39;] for r in G])
                                        for r in G:
                                                r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
                                except KeyError:
                                        t0 = (len(G)-1)/2
                                        for t,r in enumerate(G):
                                                r[&#39;t&#39;] = t - t0

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.vprint(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D47_{pf(sample)}&#39;, value=0.6)

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D47:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.leastsq()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[&#39;D47&#39;] = (r[&#39;D47raw&#39;] - c - b * r[&#39;d47&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[&#39;d47&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.normalization = result
                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result

                elif method == &#39;indep_sessions&#39;:
                        pass

        def report(self):
                &#39;&#39;&#39;
                Prints a report on the normalization fit.
                &#39;&#39;&#39;
                report_fit(self.normalization)

        def normalization_error(self, session, d47, D47):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                a = self.sessions[session][&#39;a&#39;]
                b = self.sessions[session][&#39;b&#39;]
                c = self.sessions[session][&#39;c&#39;]
                s = pf(session)
                i = self.normalization.var_names.index(f&#39;a_{s}&#39;)
                j = self.normalization.var_names.index(f&#39;b_{s}&#39;)
                k = self.normalization.var_names.index(f&#39;c_{s}&#39;)
                CM = np.zeros((3,3))
                CM[0,0] = self.normalization.covar[i,i]
                CM[0,1] = self.normalization.covar[i,j]
                CM[0,2] = self.normalization.covar[i,k]
                CM[1,0] = self.normalization.covar[j,i]
                CM[1,1] = self.normalization.covar[j,j]
                CM[1,2] = self.normalization.covar[j,k]
                CM[2,0] = self.normalization.covar[k,i]
                CM[2,1] = self.normalization.covar[k,j]
                CM[2,2] = self.normalization.covar[k,k]

                y, x = d47, D47
                z = a * x + b * y + c
                dxdy = -b / a
                dxdz = a ** -1
                dxda = -x / a
                dxdb = -y / a
                dxdc = -a ** -1
                V = np.array([dxda, dxdb, dxdc])
                sx = (V @ CM @ V.T) ** .5
                return sx


        def table_of_sessions(self, dir = &#39;results&#39;, filename = &#39;sessions.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = []
                out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
                out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
                out += [[&#39;External reproducibility of δ13C_VPDB&#39;, f&#34;{1000 * self.repro[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of δ18O_VSMOW&#39;, f&#34;{1000 * self.repro[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (anchors)&#39;, f&#34;{1000 * self.repro[&#39;r_D47a&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (unknowns)&#39;, f&#34;{1000 * self.repro[&#39;r_D47u&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (all)&#39;, f&#34;{1000 * self.repro[&#39;r_D47&#39;]:.1f} ppm&#34;]]
                out += [[&#39;Degrees of freedom (Student\&#39;s 95% t-factor)&#39;, f&#34;{self.Nf} ({self.t95:.2f})&#34;]]
                print(pretty_table(out, header = 0)) 
                
                include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
                include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
                include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])
                out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,&#39;r_D47&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
                if include_a2:
                        out[-1] += [&#39;a2 ± SE&#39;]
                if include_b2:
                        out[-1] += [&#39;b2 ± SE&#39;]
                if include_c2:
                        out[-1] += [&#39;c2 ± SE&#39;]
                for session in self.sessions:
                        out += [[
                                session,
                                f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_D47&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                                f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                                ]]
                        if include_a2:
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_b2:
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_c2:
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]

                print(pretty_table(out))
                if not os.path.exists(dir):
                        os.makedirs(dir)
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))

        
        def table_of_analyses(self, dir = &#39;results&#39;, filename = &#39;analyses.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
                extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
                for f in extra_fields:
                        out[-1] += [f[0]]
                out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,&#39;D47&#39;]
                for r in self:
                        out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                        for f in extra_fields:
                                out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                        out[-1] += [
                                f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47&#39;]:.6f}&#34;
                                ]
#                       print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        


        def table_of_samples(self, dir = &#39;results&#39;, filename = &#39;samples.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
                for sample in self.anchors:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                                f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                                ]]
                for sample in self.unknowns:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,
                                f&#34;{self.samples[sample][&#39;SE_D47&#39;]:.4f}&#34;,
                                f&#34;± {self.samples[sample][&#39;SE_D47&#39;]*self.t95:.4f}&#34;,
                                f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                                f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;
                                ]]
                print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        


        def plot_sessions(self, dir = &#39;plots&#39;, figsize = (8,8)):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if not os.path.exists(dir):
                        os.makedirs(dir)
                anchor_color = &#39;r&#39;
                unknown_color = &#39;b&#39;

                xmin = min([r[&#39;d47&#39;] for r in self])
                xmax = max([r[&#39;d47&#39;] for r in self])
                xmin -= (xmax - xmin)/10
                xmax += (xmax - xmin)/11

                ymin = min([r[&#39;D47&#39;] for r in self])
                ymax = max([r[&#39;D47&#39;] for r in self])
                ymin -= (ymax - ymin)/10
                ymax += (ymax - ymin)/11

                repl_kw = dict(ls = &#39;None&#39;, marker = &#39;x&#39;, mfc = &#39;None&#39;, ms = 4, mew = .67, alpha = 1)
                avg_kw = dict(ls = &#39;-&#39;, marker = &#39;None&#39;, lw = .67, alpha = .67)
                for session in self.sessions:
                        fig = ppl.figure( figsize = figsize)
                        for sample in self.anchors:
                                db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                                if len(db):
                                        repl_kw[&#39;mec&#39;] = anchor_color
                                        X = [r[&#39;d47&#39;] for r in db]
                                        Y = [r[&#39;D47&#39;] for r in db]
                                        ppl.plot(X, Y, **repl_kw)
                                
                                        avg_kw[&#39;color&#39;] = anchor_color
                                        X = [min(X)-.5, max(X)+.5]
                                        Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                        ppl.plot(X, Y, **avg_kw)
                                
                        for sample in self.unknowns:

                                db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                                if len(db):
                                        repl_kw[&#39;mec&#39;] = unknown_color
                                        X = [r[&#39;d47&#39;] for r in db]
                                        Y = [r[&#39;D47&#39;] for r in db]
                                        ppl.plot(X, Y, **repl_kw)

                                        avg_kw[&#39;color&#39;] = unknown_color
                                        X = [min(X)-.19, max(X)+.19]
                                        Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                        ppl.plot(X, Y, **avg_kw)

                        XI,YI = np.meshgrid(np.linspace(xmin, xmax), np.linspace(ymin, ymax))
                        SI = np.array([[self.normalization_error(session, xi, yi) for xi in XI[0,:]] for yi in YI[:,0]])
                        rng = np.max(SI) - np.min(SI)
                        if rng &lt;= 0.01:
                                cinterval = 0.001
                        elif rng &lt;= 0.03:
                                cinterval = 0.004
                        elif rng &lt;= 0.1:
                                cinterval = 0.01
                        elif rng &lt;= 0.3:
                                cinterval = 0.03
                        else:
                                cinterval = 0.1
                        cval = [np.ceil(SI.min() / .001) * .001 + k * cinterval for k in range(int(np.ceil((SI.max() - SI.min()) / cinterval)))]
                        cs = ppl.contour(XI, YI, SI, cval, colors = anchor_color, alpha = .5)
                        ppl.clabel(cs)

                        ppl.axis([xmin, xmax, ymin, ymax])
                        ppl.xlabel(&#39;δ$_{47}$ (‰ WG)&#39;)
                        ppl.ylabel(&#39;Δ$_{47}$ (‰)&#39;)
                        ppl.grid(alpha = .15)
                        ppl.title(session, weight = &#39;bold&#39;)
                        ppl.savefig(f&#39;{dir}/D47model_{session}.pdf&#39;)
                        ppl.close(fig)


        def sample_D47_covar(self, sample_1, sample_2 = &#39;&#39;):
                &#39;&#39;&#39;
                Covariance between Δ47 values of samples
                
                Returns the covariance (or the variance, if sample_1 == sample_2)
                between the average Δ47 values of two samples. Also returns the
                variance if only sample_1 is specified.
                &#39;&#39;&#39;
                i = self.normalization.var_names.index(f&#39;D47_{pf(sample_1)}&#39;)
                if sample_2 in [sample_1,&#39;&#39;]:
                        return self.normalization.covar[i,i]
                else:
                        j = self.normalization.var_names.index(f&#39;D47_{pf(sample_2)}&#39;)
                        return self.normalization.covar[i,j]
                        

        def consolidate_samples(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                for sample in self.samples:
                        self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                        if self.samples[sample][&#39;N&#39;] &gt; 1:
                                self.samples[sample][&#39;SD_D47&#39;] = stdev([r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]])
                        self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                        self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

                for sample in self.anchors:
                        self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                        self.samples[sample][&#39;SE_D47&#39;] = 0.

                D47_ref_pop = [r[&#39;D47&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]

                for sample in self.unknowns:
                        self.samples[sample][&#39;D47&#39;] = self.normalization.params.valuesdict()[f&#39;D47_{pf(sample)}&#39;]
                        self.samples[sample][&#39;SE_D47&#39;] = self.sample_D47_covar(sample)**.5

                        D47_pop = [r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]]
                        if len(D47_pop) &gt; 1:
                                self.samples[sample][&#39;p_Levene&#39;] = levene(D47_ref_pop, D47_pop, center = &#39;median&#39;)[1]


        def consolidate_sessions(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                for session in self.sessions:
                        self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                        self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])
                        self.sessions[session][&#39;a&#39;] = self.normalization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_a&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;b&#39;] = self.normalization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_b&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;c&#39;] = self.normalization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_c&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;a2&#39;] = self.normalization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;scrambling_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_a2&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;b2&#39;] = self.normalization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;slope_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_b2&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;c2&#39;] = self.normalization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;wg_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_c2&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, sessions = [session])


        def consolidate_repro(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.repro[&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_D47a&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_D47u&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;unknowns&#39;)
                self.repro[&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;all samples&#39;)


        def consolidate(self,
                tables = True,
                plots = True,
                ):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.consolidate_samples()
                self.consolidate_sessions()
                self.consolidate_repro()

                if tables:
                        self.table_of_sessions()
                        self.table_of_analyses()
                        self.table_of_samples()
                
                if plots:
                        self.plot_sessions()


        def compute_reproducibility(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
                &#39;&#39;&#39;
                Compute external reproducibility of r[key].
                &#39;&#39;&#39;
                if samples == &#39;all samples&#39;:
                        mysamples = [k for k in self.samples]
                elif samples == &#39;anchors&#39;:
                        mysamples = [k for k in self.anchors]
                elif samples == &#39;unknowns&#39;:
                        mysamples = [k for k in self.unknowns]
                else:
                        mysamples = samples

                if sessions == &#39;all sessions&#39;:
                        sessions = [k for k in self.sessions]

                chisq, Nf = 0, 0
                for sample in mysamples :
                        X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                        if len(X) &gt; 1 :
                                Nf += len(X) - 1
                                chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
                r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
                self.vprint(f&#39;External reproducibility of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
                return r

        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Average Δ47 value of a group of samples, accounting for covariance.
                
                Returns the (weighed, optionally) average Δ47 value and associated SE
                of a group of samples. Weights are equal by default. If normalize is
                True, weights will be rescaled so that their sum equals 1.
                
                Examples
                --------
                ```sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])```

                will return the value and SE of (Δ47(X) + 2*Δ47(Y)/3, where Δ47(X)
                and Δ47(Y) are the average Δ47 of samples X and Y, respectively.

                &gt; sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                
                will return the value and SE of the difference Δ47(X) - Δ47(Y)
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        weights = [w/s for w in weights]

                try:
#                       indices = [self.normalization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.normalization.covar[indices,:][:,indices]
                        C = array([[self.sample_D47_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][&#39;D47&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="D47crunch.correlated_sum"><code class="name flex">
<span>def <span class="ident">correlated_sum</span></span>(<span>X, C, f='')</span>
</code></dt>
<dd>
<section class="desc"><p>Return the mean and SE of the sum of the elements
of X, optionally weighted by the elements of f,
accounting for C the covariance matrix of X.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correlated_sum(X,C,f = &#39;&#39;):
        &#39;&#39;&#39;
        Return the mean and SE of the sum of the elements
        of X, optionally weighted by the elements of f,
        accounting for C the covariance matrix of X.
        &#39;&#39;&#39;
        if f == &#39;&#39;: f = [1 for x in X]
        return np.dot(f,X), (np.dot(f,np.dot(C,f)))**.5</code></pre>
</details>
</dd>
<dt id="D47crunch.make_csv"><code class="name flex">
<span>def <span class="ident">make_csv</span></span>(<span>x, hsep=',', vsep='\n')</span>
</code></dt>
<dd>
<section class="desc"><p>Reads a list of lists of strings and outputs a csv table.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_csv(x, hsep = &#39;,&#39;, vsep = &#39;\n&#39;):
        &#39;&#39;&#39;
        Reads a list of lists of strings and outputs a csv table.
        &#39;&#39;&#39;
        return vsep.join([hsep.join(l) for l in x])</code></pre>
</details>
</dd>
<dt id="D47crunch.pf"><code class="name flex">
<span>def <span class="ident">pf</span></span>(<span>txt)</span>
</code></dt>
<dd>
<section class="desc"><p>Modify string <code>txt</code> to follow <code>lmfit.Parameter()</code> naming rules.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pf(txt):
        &#39;&#39;&#39;
        Modify string `txt` to follow `lmfit.Parameter()` naming rules.
        &#39;&#39;&#39;
        return txt.replace(&#39;-&#39;,&#39;_&#39;).replace(&#39;.&#39;,&#39;_&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.pretty_table"><code class="name flex">
<span>def <span class="ident">pretty_table</span></span>(<span>x, header=1, hsep='
', vsep='-')</span>
</code></dt>
<dd>
<section class="desc"><p>Reads a list of lists of strings and outputs an ascii table.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pretty_table(x, header = 1, hsep = &#39;  &#39;, vsep = &#39;-&#39;):
        &#39;&#39;&#39;
        Reads a list of lists of strings and outputs an ascii table.
        &#39;&#39;&#39;
        txt = [&#39;&#39;]
        widths = [np.max([len(e) for e in c]) for c in zip(*x)]
        
        align = &#39;&lt;&#39; + &#39;&gt;&#39;*(len(widths)-1)
        sepline = hsep.join([vsep*w for w in widths])
        txt += [sepline]
        for k,l in enumerate(x):
                if k and k == header:
                        txt += [sepline]
                txt += [hsep.join([f&#39;{e:{a}{w}}&#39; for e, w, a in zip(l, widths, align)])]
        txt += [sepline]
        txt += [&#39;&#39;]
        return &#39;\n&#39;.join(txt)</code></pre>
</details>
</dd>
<dt id="D47crunch.smart_type"><code class="name flex">
<span>def <span class="ident">smart_type</span></span>(<span>x)</span>
</code></dt>
<dd>
<section class="desc"><p>Tries to convert a string to a float if it includes '.',
or to an integer if it does not. If both attempts fail,
return the original string unchanged.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def smart_type(x):
        &#39;&#39;&#39;
        Tries to convert a string to a float if it includes &#39;.&#39;,
        or to an integer if it does not. If both attempts fail,
        return the original string unchanged.
        &#39;&#39;&#39;
        try:
                y = float(x)
        except ValueError:
                return x
        if &#39;.&#39; not in x:
                return int(y)
        return y</code></pre>
</details>
</dd>
<dt id="D47crunch.transpose_table"><code class="name flex">
<span>def <span class="ident">transpose_table</span></span>(<span>x)</span>
</code></dt>
<dd>
<section class="desc"><p>Transpose a list if lists.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transpose_table(x):
        &#39;&#39;&#39;
        Transpose a list if lists.
        &#39;&#39;&#39;
        return [[e for e in c] for c in zip(*x)]</code></pre>
</details>
</dd>
<dt id="D47crunch.w_avg"><code class="name flex">
<span>def <span class="ident">w_avg</span></span>(<span>X, sX)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute weighted average.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def w_avg(X, sX) :
        &#39;&#39;&#39;
        Compute weighted average.
        &#39;&#39;&#39;
        X = [ x for x in X ]
        sX = [ sx for sx in sX ]
        W = [ sx**-2 for sx in sX ]
        W = [ w/sum(W) for w in W ]
        Xavg = sum([ w*x for w,x in zip(W,X) ])
        sXavg = sum([ w**2*sx**2 for w,sx in zip(W,sX) ])**.5
        return Xavg, sXavg</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="D47crunch.D47data"><code class="flex name class">
<span>class <span class="ident">D47data</span></span>
<span>(</span><span>l=[], verbose=False, msgcolor='\x1b[92m')</span>
</code></dt>
<dd>
<section class="desc"><p>Store and process data for a large set of Δ47 analyses.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class D47data(list):
        &#39;&#39;&#39;
        Store and process data for a large set of Δ47 analyses.
        &#39;&#39;&#39;

        ### 17O CORRECTION PARAMETERS
        R13_VPDB = 0.01118  # (Chang &amp; Li, 1990)
        R18_VSMOW = 0.0020052  # (Baertschi, 1976)
        lambda_17 = 0.528  # (Barkan &amp; Luz, 2005)
        R17_VSMOW = 0.00038475  # (Assonov &amp; Brenninkmeijer, 2003, rescaled to R13_VPDB)
        R18_VPDB = R18_VSMOW * 1.03092
        R17_VPDB = R17_VSMOW * 1.03092 ** lambda_17

        LEVENE_REF_SAMPLE = &#39;ETH-3&#39;
        SAMPLE_CONSTRAINING_WG_COMPOSITION = &#39;ETH-3&#39;
        d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION = 1.71  # (Bernasconi et al., 2018)
        d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION = -1.78 # (Bernasconi et al., 2018)
        T_ACID = 90.0
        ALPHA_18O_ACID_REACTION = np.exp(3.59 / (T_ACID + 273.15) - 1.79e-3)  # (Kim et al., 2007, calcite)

        Nominal_D47 = {
                &#39;ETH-1&#39;: 0.258,
                &#39;ETH-2&#39;: 0.256,
                &#39;ETH-3&#39;: 0.691,
                }       # (Bernasconi et al., 2018)


        def __init__(self, l = [], verbose = False, msgcolor = &#39;\033[92m&#39;):
                self.verbose = verbose
                self.msgcolor = msgcolor
                list.__init__(self, l)
#               self.R13_VPDB = D47data.R13_VPDB
#               self.R18_VSMOW = D47data.R18_VSMOW
#               self.lambda_17 = D47data.lambda_17
#               self.R18_VPDB = D47data.R18_VPDB
#               self.R17_VPDB = D47data.R17_VPDB
#               self.SAMPLE_CONSTRAINING_WG_COMPOSITION = D47data.SAMPLE_CONSTRAINING_WG_COMPOSITION
#               self.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION = D47data.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
#               self.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION = D47data.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
#               self.ALPHA_18O_ACID_REACTION = D47data.ALPHA_18O_ACID_REACTION
#               self.Nominal_D47 = D47data.Nominal_D47.copy()
                self.Nf = None
                self.repro = {}
                self.refresh()


        def vprint(self, txt):
                &#39;&#39;&#39;
                Print log message to screen if D47data.verbose is true.
                &#39;&#39;&#39;
                if self.verbose:
                        print(f&#39;{self.msgcolor}[D47data]   {txt}\033[0m&#39;)


        def refresh(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.refresh_sessions()
                self.refresh_samples()


        def refresh_sessions(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.sessions = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                        for s in sorted({r[&#39;Session&#39;] for r in self})
                        }
                for s in self.sessions:
                        self.sessions[s][&#39;scrambling_drift&#39;] = False
                        self.sessions[s][&#39;slope_drift&#39;] = False
                        self.sessions[s][&#39;wg_drift&#39;] = False


        def refresh_samples(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.samples = {
                        s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                        for s in sorted({r[&#39;Sample&#39;] for r in self})
                        }
                self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D47}
                self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D47}


        def read(self, file, sep = &#39;,&#39;):
                &#39;&#39;&#39;
                Read file in csv format to load analysis data into a D47data object.
                Use &#39;sep&#39; argument to define the csv separator.
                &#39;&#39;&#39;
                with open(file) as fid:
                        self.input(fid.read(), sep = sep)


        def input(self, txt, sep = &#39;,&#39;):
                &#39;&#39;&#39;
                Read string in csv format to load analysis data into a D47data object.
                Use &#39;sep&#39; argument to define the csv separator.
                &#39;&#39;&#39;
                txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
                data = [{k: smart_type(v) for k,v in zip(txt[0], l)} for l in txt[1:]]
                self += data
                self.refresh()


        def wg(self):
                &#39;&#39;&#39;
                Compute bulk composition of the working gas for each session
                based on the average composition, within each session,
                of a given sample.
                &#39;&#39;&#39;

                self.vprint(f&#34;Computing working gas composition:&#34;)

                sample = self.SAMPLE_CONSTRAINING_WG_COMPOSITION
                d13C_vpdb = self.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
                d18O_vpdb = self.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
                a18_acid = self.ALPHA_18O_ACID_REACTION

                R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
                R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
                R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

                C12_s = 1 / (1 + R13_s)
                C13_s = R13_s / (1 + R13_s)
                C16_s = 1 / (1 + R17_s + R18_s)
                C17_s = R17_s / (1 + R17_s + R18_s)
                C18_s = R18_s / (1 + R17_s + R18_s)

                C626_s = C12_s * C16_s ** 2
                C627_s = 2 * C12_s * C16_s * C17_s
                C628_s = 2 * C12_s * C16_s * C18_s
                C636_s = C13_s * C16_s ** 2
                C637_s = 2 * C13_s * C16_s * C17_s
                C727_s = C12_s * C17_s ** 2

                R45_s = (C627_s + C636_s) / C626_s
                R46_s = (C628_s + C637_s + C727_s) / C626_s

                for s in self.sessions:
                        db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                        d45_s = np.mean([r[&#39;d45&#39;] for r in db])
                        d46_s = np.mean([r[&#39;d46&#39;] for r in db])
                        R45_wg = R45_s / (1 + d45_s / 1000)
                        R46_wg = R46_s / (1 + d46_s / 1000)

                        d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_deltas(R45_wg, R46_wg)

                        self.vprint(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                        self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                        for r in self.sessions[s][&#39;data&#39;]:
                                r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                                r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW


        def compute_bulk_deltas(self, R45, R46, D17O = 0):
                &#39;&#39;&#39;
                Compute δ13C_VPDB and δ18O_VSMOW, by solving the generalized form of equation (17)
                from Brand et al. (2010), assuming that d18O_VSMOW is not too big ( 0 ± 50 ‰) and
                solving the corresponding second-order Taylor polynomial.
                (Appendix A, Daëron et al., 2016, &lt;https://doi.org/10.1016/j.chemgeo.2016.08.014&gt;)
                &#39;&#39;&#39;

                K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

                A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
                B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
                C = 2 * self.R18_VSMOW
                D = -R46

                aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
                bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
                cc = A + B + C + D

                d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

                R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
                R17 = K * R18 ** self.lambda_17
                R13 = R45 - 2 * R17

                d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

                return d13C_VPDB, d18O_VSMOW


        def crunch(self):
                &#39;&#39;&#39;
                Compute bulk composition and raw clumped isotope anomalies for all analyses.
                &#39;&#39;&#39;
                for i,r in enumerate(self):
                        for k in [&#39;D17O&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                                if k not in r:
                                        r[k] = 0.
                        self.compute_bulk_and_clumping_deltas(r)
                self.vprint(f&#34;Crunched {len(self)} analyses.&#34;)


        def compute_bulk_and_clumping_deltas(self, r):
                &#39;&#39;&#39;
                Compute δ13C_VPDB, δ18O_VSMOW, and raw Δ47, Δ48, Δ49 values for an analysis.
                &#39;&#39;&#39;

                # Compute working gas R13, R18, and isobar ratios
                R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
                R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
                R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

                # Compute analyte isobar ratios
                R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
                R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
                R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
                R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
                R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

                r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_deltas(R45, R46, D17O = r[&#39;D17O&#39;])
                R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
                R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

                # Compute stochastic isobar ratios of the analyte
                R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                        R13, R18, D17O = r[&#39;D17O&#39;]
                )

                # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
                # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
                if (R45 / R45stoch - 1) &gt; 5e-8:
                        self.vprint(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):%.3f} ppm&#39;)
                if (R46 / R46stoch - 1) &gt; 5e-8:
                        self.vprint(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):%.3f} ppm&#39;)

                # Compute raw clumped isotope anomalies
                r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
                r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
                r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)

        def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
                &#39;&#39;&#39;
                Compute isobar ratios for a sample with isotopic ratios R13 and R18,
                optionally accounting for non-zero values of Δ17O and clumped isotope
                anomalies, all expressed in permil.
                &#39;&#39;&#39;

                # Compute R17
                R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

                # Compute isotope concentrations
                C12 = (1 + R13) ** -1
                C13 = C12 * R13
                C16 = (1 + R17 + R18) ** -1
                C17 = C16 * R17
                C18 = C16 * R18

                # Compute stochastic isotopologue concentrations
                C626 = C16 * C12 * C16
                C627 = C16 * C12 * C17 * 2
                C628 = C16 * C12 * C18 * 2
                C636 = C16 * C13 * C16
                C637 = C16 * C13 * C17 * 2
                C638 = C16 * C13 * C18 * 2
                C727 = C17 * C12 * C17
                C728 = C17 * C12 * C18 * 2
                C737 = C17 * C13 * C17
                C738 = C17 * C13 * C18 * 2
                C828 = C18 * C12 * C18
                C838 = C18 * C13 * C18

                # Compute stochastic isobar ratios
                R45 = (C636 + C627) / C626
                R46 = (C628 + C637 + C727) / C626
                R47 = (C638 + C728 + C737) / C626
                R48 = (C738 + C828) / C626
                R49 = C838 / C626

                # Account for stochastic anomalies
                R47 *= 1 + D47 / 1000
                R48 *= 1 + D48 / 1000
                R49 *= 1 + D49 / 1000

                # Return isobar ratios
                return R45, R46, R47, R48, R49

        def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_uid&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if samples_to_split == &#39;all&#39;:
                        samples_to_split = [s for s in self.unknowns]
                gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
                self.grouping = grouping.lower()
                if self.grouping in gkeys:
                        gkey = gkeys[self.grouping]
                for r in self:
                        if r[&#39;Sample&#39;] in samples_to_split:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                        elif r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                self.refresh_samples()


        def unsplit_samples(self, tables = True):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                unknowns_old = sorted({s for s in self.unknowns})
                CM_old = self.normalization.covar[:,:]
                VD_old = self.normalization.params.valuesdict().copy()
                vars_old = self.normalization.var_names

                unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})
                
                Ns = len(vars_old) - len(unknowns_old)
                vars_new = vars_old[:Ns] + [f&#39;D47_{pf(u)}&#39; for u in unknowns_new]
                VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

                W = np.zeros((len(vars_new), len(vars_old)))
                W[:Ns,:Ns] = np.eye(Ns)
                for u in unknowns_new:
                        splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                        if self.grouping == &#39;by_session&#39;:
                                weights = [self.samples[s][&#39;SE_D47&#39;]**-2 for s in splits]
                        elif self.grouping == &#39;by_uid&#39;:
                                weights = [1 for s in splits]
                        sw = sum(weights)
                        weights = [w/sw for w in weights]
                        W[vars_new.index(f&#39;D47_{pf(u)}&#39;),[vars_old.index(f&#39;D47_{pf(s)}&#39;) for s in splits]] = weights[:]
#               print(&#39;\nUnsplitting weights matrix:&#39;)
#               print(&#39;\n&#39;.join([&#39; &#39;.join([f&#39;{x:.1f}&#39; if x else &#39; - &#39; for x in l]) for l in W]))
#               print(&#39;---&#39;)

                CM_new = W @ CM_old @ W.T
                V = W @ np.array([[VD_old[k]] for k in vars_old])
                VD_new = {k:v[0] for k,v in zip(vars_new, V)}
                
                self.normalization.covar = CM_new
                self.normalization.params.valuesdict = lambda : VD_new
                self.normalization.var_names = vars_new

                for r in self:
                        if r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]
                
                self.refresh_samples()
                self.consolidate_samples()
                self.consolidate_repro()

                if tables:
                        self.table_of_analyses()
                        self.table_of_samples()

        def normalize(self,
                method = &#39;lmfit&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = True,
                consolidate_plots = True,
                ):
                &#39;&#39;&#39;
                Compute absolute Δ47 values for all replicate analyses and for sample averages.
                If &#34;method&#34; argument is set to &#34;lmfit&#34;, the normalization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous (i.e. that their true Δ47 value does not change between sessions).
                If &#34;method&#34; argument is set to &#34;indep_sessions&#34;, the normalization processes each
                session independently.
                &#39;&#39;&#39;
                if method == &#39;lmfit&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D47data([r for r in self if r[&#39;Session&#39;] in session_group], verbose = self.verbose)
                                        result = X.normalize(method = &#39;lmfit&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.vprint(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[&#39;wD47raw&#39;] *= w
                        else:
                                self.vprint(&#39;All weights set to 1 ppm&#39;)
                                for r in self:
                                        r[&#39;wD47raw&#39;] = 0.001

                        for s in self.sessions:
                                G = self.sessions[s][&#39;data&#39;]
                                try:
                                        t0 = np.mean([r[&#39;TimeTag&#39;] for r in G])
                                        for r in G:
                                                r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
                                except KeyError:
                                        t0 = (len(G)-1)/2
                                        for t,r in enumerate(G):
                                                r[&#39;t&#39;] = t - t0

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.vprint(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D47_{pf(sample)}&#39;, value=0.6)

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D47:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.leastsq()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[&#39;D47&#39;] = (r[&#39;D47raw&#39;] - c - b * r[&#39;d47&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[&#39;d47&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.normalization = result
                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result

                elif method == &#39;indep_sessions&#39;:
                        pass

        def report(self):
                &#39;&#39;&#39;
                Prints a report on the normalization fit.
                &#39;&#39;&#39;
                report_fit(self.normalization)

        def normalization_error(self, session, d47, D47):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                a = self.sessions[session][&#39;a&#39;]
                b = self.sessions[session][&#39;b&#39;]
                c = self.sessions[session][&#39;c&#39;]
                s = pf(session)
                i = self.normalization.var_names.index(f&#39;a_{s}&#39;)
                j = self.normalization.var_names.index(f&#39;b_{s}&#39;)
                k = self.normalization.var_names.index(f&#39;c_{s}&#39;)
                CM = np.zeros((3,3))
                CM[0,0] = self.normalization.covar[i,i]
                CM[0,1] = self.normalization.covar[i,j]
                CM[0,2] = self.normalization.covar[i,k]
                CM[1,0] = self.normalization.covar[j,i]
                CM[1,1] = self.normalization.covar[j,j]
                CM[1,2] = self.normalization.covar[j,k]
                CM[2,0] = self.normalization.covar[k,i]
                CM[2,1] = self.normalization.covar[k,j]
                CM[2,2] = self.normalization.covar[k,k]

                y, x = d47, D47
                z = a * x + b * y + c
                dxdy = -b / a
                dxdz = a ** -1
                dxda = -x / a
                dxdb = -y / a
                dxdc = -a ** -1
                V = np.array([dxda, dxdb, dxdc])
                sx = (V @ CM @ V.T) ** .5
                return sx


        def table_of_sessions(self, dir = &#39;results&#39;, filename = &#39;sessions.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = []
                out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
                out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
                out += [[&#39;External reproducibility of δ13C_VPDB&#39;, f&#34;{1000 * self.repro[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of δ18O_VSMOW&#39;, f&#34;{1000 * self.repro[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (anchors)&#39;, f&#34;{1000 * self.repro[&#39;r_D47a&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (unknowns)&#39;, f&#34;{1000 * self.repro[&#39;r_D47u&#39;]:.1f} ppm&#34;]]
                out += [[&#39;External reproducibility of Δ47 (all)&#39;, f&#34;{1000 * self.repro[&#39;r_D47&#39;]:.1f} ppm&#34;]]
                out += [[&#39;Degrees of freedom (Student\&#39;s 95% t-factor)&#39;, f&#34;{self.Nf} ({self.t95:.2f})&#34;]]
                print(pretty_table(out, header = 0)) 
                
                include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
                include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
                include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])
                out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,&#39;r_D47&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
                if include_a2:
                        out[-1] += [&#39;a2 ± SE&#39;]
                if include_b2:
                        out[-1] += [&#39;b2 ± SE&#39;]
                if include_c2:
                        out[-1] += [&#39;c2 ± SE&#39;]
                for session in self.sessions:
                        out += [[
                                session,
                                f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                                f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;r_D47&#39;]:.4f}&#34;,
                                f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                                f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                                f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                                ]]
                        if include_a2:
                                if self.sessions[session][&#39;scrambling_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_b2:
                                if self.sessions[session][&#39;slope_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]
                        if include_c2:
                                if self.sessions[session][&#39;wg_drift&#39;]:
                                        out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                                else:
                                        out[-1] += [&#39;&#39;]

                print(pretty_table(out))
                if not os.path.exists(dir):
                        os.makedirs(dir)
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))

        
        def table_of_analyses(self, dir = &#39;results&#39;, filename = &#39;analyses.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
                extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
                for f in extra_fields:
                        out[-1] += [f[0]]
                out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,&#39;D47&#39;]
                for r in self:
                        out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                        for f in extra_fields:
                                out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                        out[-1] += [
                                f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47&#39;]:.6f}&#34;
                                ]
#                       print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        


        def table_of_samples(self, dir = &#39;results&#39;, filename = &#39;samples.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
                for sample in self.anchors:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                                f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                                ]]
                for sample in self.unknowns:
                        out += [[
                                f&#34;{sample}&#34;,
                                f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                                f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                                f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,
                                f&#34;{self.samples[sample][&#39;SE_D47&#39;]:.4f}&#34;,
                                f&#34;± {self.samples[sample][&#39;SE_D47&#39;]*self.t95:.4f}&#34;,
                                f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                                f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;
                                ]]
                print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        


        def plot_sessions(self, dir = &#39;plots&#39;, figsize = (8,8)):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                if not os.path.exists(dir):
                        os.makedirs(dir)
                anchor_color = &#39;r&#39;
                unknown_color = &#39;b&#39;

                xmin = min([r[&#39;d47&#39;] for r in self])
                xmax = max([r[&#39;d47&#39;] for r in self])
                xmin -= (xmax - xmin)/10
                xmax += (xmax - xmin)/11

                ymin = min([r[&#39;D47&#39;] for r in self])
                ymax = max([r[&#39;D47&#39;] for r in self])
                ymin -= (ymax - ymin)/10
                ymax += (ymax - ymin)/11

                repl_kw = dict(ls = &#39;None&#39;, marker = &#39;x&#39;, mfc = &#39;None&#39;, ms = 4, mew = .67, alpha = 1)
                avg_kw = dict(ls = &#39;-&#39;, marker = &#39;None&#39;, lw = .67, alpha = .67)
                for session in self.sessions:
                        fig = ppl.figure( figsize = figsize)
                        for sample in self.anchors:
                                db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                                if len(db):
                                        repl_kw[&#39;mec&#39;] = anchor_color
                                        X = [r[&#39;d47&#39;] for r in db]
                                        Y = [r[&#39;D47&#39;] for r in db]
                                        ppl.plot(X, Y, **repl_kw)
                                
                                        avg_kw[&#39;color&#39;] = anchor_color
                                        X = [min(X)-.5, max(X)+.5]
                                        Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                        ppl.plot(X, Y, **avg_kw)
                                
                        for sample in self.unknowns:

                                db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                                if len(db):
                                        repl_kw[&#39;mec&#39;] = unknown_color
                                        X = [r[&#39;d47&#39;] for r in db]
                                        Y = [r[&#39;D47&#39;] for r in db]
                                        ppl.plot(X, Y, **repl_kw)

                                        avg_kw[&#39;color&#39;] = unknown_color
                                        X = [min(X)-.19, max(X)+.19]
                                        Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                        ppl.plot(X, Y, **avg_kw)

                        XI,YI = np.meshgrid(np.linspace(xmin, xmax), np.linspace(ymin, ymax))
                        SI = np.array([[self.normalization_error(session, xi, yi) for xi in XI[0,:]] for yi in YI[:,0]])
                        rng = np.max(SI) - np.min(SI)
                        if rng &lt;= 0.01:
                                cinterval = 0.001
                        elif rng &lt;= 0.03:
                                cinterval = 0.004
                        elif rng &lt;= 0.1:
                                cinterval = 0.01
                        elif rng &lt;= 0.3:
                                cinterval = 0.03
                        else:
                                cinterval = 0.1
                        cval = [np.ceil(SI.min() / .001) * .001 + k * cinterval for k in range(int(np.ceil((SI.max() - SI.min()) / cinterval)))]
                        cs = ppl.contour(XI, YI, SI, cval, colors = anchor_color, alpha = .5)
                        ppl.clabel(cs)

                        ppl.axis([xmin, xmax, ymin, ymax])
                        ppl.xlabel(&#39;δ$_{47}$ (‰ WG)&#39;)
                        ppl.ylabel(&#39;Δ$_{47}$ (‰)&#39;)
                        ppl.grid(alpha = .15)
                        ppl.title(session, weight = &#39;bold&#39;)
                        ppl.savefig(f&#39;{dir}/D47model_{session}.pdf&#39;)
                        ppl.close(fig)


        def sample_D47_covar(self, sample_1, sample_2 = &#39;&#39;):
                &#39;&#39;&#39;
                Covariance between Δ47 values of samples
                
                Returns the covariance (or the variance, if sample_1 == sample_2)
                between the average Δ47 values of two samples. Also returns the
                variance if only sample_1 is specified.
                &#39;&#39;&#39;
                i = self.normalization.var_names.index(f&#39;D47_{pf(sample_1)}&#39;)
                if sample_2 in [sample_1,&#39;&#39;]:
                        return self.normalization.covar[i,i]
                else:
                        j = self.normalization.var_names.index(f&#39;D47_{pf(sample_2)}&#39;)
                        return self.normalization.covar[i,j]
                        

        def consolidate_samples(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                for sample in self.samples:
                        self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                        if self.samples[sample][&#39;N&#39;] &gt; 1:
                                self.samples[sample][&#39;SD_D47&#39;] = stdev([r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]])
                        self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                        self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

                for sample in self.anchors:
                        self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                        self.samples[sample][&#39;SE_D47&#39;] = 0.

                D47_ref_pop = [r[&#39;D47&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]

                for sample in self.unknowns:
                        self.samples[sample][&#39;D47&#39;] = self.normalization.params.valuesdict()[f&#39;D47_{pf(sample)}&#39;]
                        self.samples[sample][&#39;SE_D47&#39;] = self.sample_D47_covar(sample)**.5

                        D47_pop = [r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]]
                        if len(D47_pop) &gt; 1:
                                self.samples[sample][&#39;p_Levene&#39;] = levene(D47_ref_pop, D47_pop, center = &#39;median&#39;)[1]


        def consolidate_sessions(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                for session in self.sessions:
                        self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                        self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])
                        self.sessions[session][&#39;a&#39;] = self.normalization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_a&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;b&#39;] = self.normalization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_b&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;c&#39;] = self.normalization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                        i = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_c&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;a2&#39;] = self.normalization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;scrambling_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_a2&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;b2&#39;] = self.normalization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;slope_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_b2&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;c2&#39;] = self.normalization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                        if self.sessions[session][&#39;wg_drift&#39;]:
                                i = self.normalization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                                self.sessions[session][&#39;SE_c2&#39;] = self.normalization.covar[i,i]**.5
                        self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                        self.sessions[session][&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, sessions = [session])


        def consolidate_repro(self):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.repro[&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_D47a&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;anchors&#39;)
                self.repro[&#39;r_D47u&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;unknowns&#39;)
                self.repro[&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;all samples&#39;)


        def consolidate(self,
                tables = True,
                plots = True,
                ):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                self.consolidate_samples()
                self.consolidate_sessions()
                self.consolidate_repro()

                if tables:
                        self.table_of_sessions()
                        self.table_of_analyses()
                        self.table_of_samples()
                
                if plots:
                        self.plot_sessions()


        def compute_reproducibility(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
                &#39;&#39;&#39;
                Compute external reproducibility of r[key].
                &#39;&#39;&#39;
                if samples == &#39;all samples&#39;:
                        mysamples = [k for k in self.samples]
                elif samples == &#39;anchors&#39;:
                        mysamples = [k for k in self.anchors]
                elif samples == &#39;unknowns&#39;:
                        mysamples = [k for k in self.unknowns]
                else:
                        mysamples = samples

                if sessions == &#39;all sessions&#39;:
                        sessions = [k for k in self.sessions]

                chisq, Nf = 0, 0
                for sample in mysamples :
                        X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                        if len(X) &gt; 1 :
                                Nf += len(X) - 1
                                chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
                r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
                self.vprint(f&#39;External reproducibility of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
                return r

        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Average Δ47 value of a group of samples, accounting for covariance.
                
                Returns the (weighed, optionally) average Δ47 value and associated SE
                of a group of samples. Weights are equal by default. If normalize is
                True, weights will be rescaled so that their sum equals 1.
                
                Examples
                --------
                ```sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])```

                will return the value and SE of (Δ47(X) + 2*Δ47(Y)/3, where Δ47(X)
                and Δ47(Y) are the average Δ47 of samples X and Y, respectively.

                &gt; sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                
                will return the value and SE of the difference Δ47(X) - Δ47(Y)
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        weights = [w/s for w in weights]

                try:
#                       indices = [self.normalization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.normalization.covar[indices,:][:,indices]
                        C = array([[self.sample_D47_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][&#39;D47&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.list</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="D47crunch.D47data.ALPHA_18O_ACID_REACTION"><code class="name">var <span class="ident">ALPHA_18O_ACID_REACTION</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.LEVENE_REF_SAMPLE"><code class="name">var <span class="ident">LEVENE_REF_SAMPLE</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.Nominal_D47"><code class="name">var <span class="ident">Nominal_D47</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.R13_VPDB"><code class="name">var <span class="ident">R13_VPDB</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.R17_VPDB"><code class="name">var <span class="ident">R17_VPDB</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.R17_VSMOW"><code class="name">var <span class="ident">R17_VSMOW</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.R18_VPDB"><code class="name">var <span class="ident">R18_VPDB</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.R18_VSMOW"><code class="name">var <span class="ident">R18_VSMOW</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.SAMPLE_CONSTRAINING_WG_COMPOSITION"><code class="name">var <span class="ident">SAMPLE_CONSTRAINING_WG_COMPOSITION</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.T_ACID"><code class="name">var <span class="ident">T_ACID</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION"><code class="name">var <span class="ident">d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION"><code class="name">var <span class="ident">d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="D47crunch.D47data.lambda_17"><code class="name">var <span class="ident">lambda_17</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="D47crunch.D47data.compute_bulk_and_clumping_deltas"><code class="name flex">
<span>def <span class="ident">compute_bulk_and_clumping_deltas</span></span>(<span>self, r)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute δ13C_VPDB, δ18O_VSMOW, and raw Δ47, Δ48, Δ49 values for an analysis.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_bulk_and_clumping_deltas(self, r):
        &#39;&#39;&#39;
        Compute δ13C_VPDB, δ18O_VSMOW, and raw Δ47, Δ48, Δ49 values for an analysis.
        &#39;&#39;&#39;

        # Compute working gas R13, R18, and isobar ratios
        R13_wg = self.R13_VPDB * (1 + r[&#39;d13Cwg_VPDB&#39;] / 1000)
        R18_wg = self.R18_VSMOW * (1 + r[&#39;d18Owg_VSMOW&#39;] / 1000)
        R45_wg, R46_wg, R47_wg, R48_wg, R49_wg = self.compute_isobar_ratios(R13_wg, R18_wg)

        # Compute analyte isobar ratios
        R45 = (1 + r[&#39;d45&#39;] / 1000) * R45_wg
        R46 = (1 + r[&#39;d46&#39;] / 1000) * R46_wg
        R47 = (1 + r[&#39;d47&#39;] / 1000) * R47_wg
        R48 = (1 + r[&#39;d48&#39;] / 1000) * R48_wg
        R49 = (1 + r[&#39;d49&#39;] / 1000) * R49_wg

        r[&#39;d13C_VPDB&#39;], r[&#39;d18O_VSMOW&#39;] = self.compute_bulk_deltas(R45, R46, D17O = r[&#39;D17O&#39;])
        R13 = (1 + r[&#39;d13C_VPDB&#39;] / 1000) * self.R13_VPDB
        R18 = (1 + r[&#39;d18O_VSMOW&#39;] / 1000) * self.R18_VSMOW

        # Compute stochastic isobar ratios of the analyte
        R45stoch, R46stoch, R47stoch, R48stoch, R49stoch = self.compute_isobar_ratios(
                R13, R18, D17O = r[&#39;D17O&#39;]
        )

        # Check that R45/R45stoch and R46/R46stoch are undistinguishable from 1,
        # and raise a warning if the corresponding anomalies exceed 0.02 ppm.
        if (R45 / R45stoch - 1) &gt; 5e-8:
                self.vprint(f&#39;This is unexpected: R45/R45stoch - 1 = {1e6 * (R45 / R45stoch - 1):%.3f} ppm&#39;)
        if (R46 / R46stoch - 1) &gt; 5e-8:
                self.vprint(f&#39;This is unexpected: R46/R46stoch - 1 = {1e6 * (R46 / R46stoch - 1):%.3f} ppm&#39;)

        # Compute raw clumped isotope anomalies
        r[&#39;D47raw&#39;] = 1000 * (R47 / R47stoch - 1)
        r[&#39;D48raw&#39;] = 1000 * (R48 / R48stoch - 1)
        r[&#39;D49raw&#39;] = 1000 * (R49 / R49stoch - 1)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.compute_bulk_deltas"><code class="name flex">
<span>def <span class="ident">compute_bulk_deltas</span></span>(<span>self, R45, R46, D17O=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute δ13C_VPDB and δ18O_VSMOW, by solving the generalized form of equation (17)
from Brand et al. (2010), assuming that d18O_VSMOW is not too big ( 0 ± 50 ‰) and
solving the corresponding second-order Taylor polynomial.
(Appendix A, Daëron et al., 2016, <a href="https://doi.org/10.1016/j.chemgeo.2016.08.014">https://doi.org/10.1016/j.chemgeo.2016.08.014</a>)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_bulk_deltas(self, R45, R46, D17O = 0):
        &#39;&#39;&#39;
        Compute δ13C_VPDB and δ18O_VSMOW, by solving the generalized form of equation (17)
        from Brand et al. (2010), assuming that d18O_VSMOW is not too big ( 0 ± 50 ‰) and
        solving the corresponding second-order Taylor polynomial.
        (Appendix A, Daëron et al., 2016, &lt;https://doi.org/10.1016/j.chemgeo.2016.08.014&gt;)
        &#39;&#39;&#39;

        K = np.exp(D17O / 1000) * self.R17_VSMOW * self.R18_VSMOW ** -self.lambda_17

        A = -3 * K ** 2 * self.R18_VSMOW ** (2 * self.lambda_17)
        B = 2 * K * R45 * self.R18_VSMOW ** self.lambda_17
        C = 2 * self.R18_VSMOW
        D = -R46

        aa = A * self.lambda_17 * (2 * self.lambda_17 - 1) + B * self.lambda_17 * (self.lambda_17 - 1) / 2
        bb = 2 * A * self.lambda_17 + B * self.lambda_17 + C
        cc = A + B + C + D

        d18O_VSMOW = 1000 * (-bb + (bb ** 2 - 4 * aa * cc) ** .5) / (2 * aa)

        R18 = (1 + d18O_VSMOW / 1000) * self.R18_VSMOW
        R17 = K * R18 ** self.lambda_17
        R13 = R45 - 2 * R17

        d13C_VPDB = 1000 * (R13 / self.R13_VPDB - 1)

        return d13C_VPDB, d18O_VSMOW</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.compute_isobar_ratios"><code class="name flex">
<span>def <span class="ident">compute_isobar_ratios</span></span>(<span>self, R13, R18, D17O=0, D47=0, D48=0, D49=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute isobar ratios for a sample with isotopic ratios R13 and R18,
optionally accounting for non-zero values of Δ17O and clumped isotope
anomalies, all expressed in permil.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_isobar_ratios(self, R13, R18, D17O=0, D47=0, D48=0, D49=0):
        &#39;&#39;&#39;
        Compute isobar ratios for a sample with isotopic ratios R13 and R18,
        optionally accounting for non-zero values of Δ17O and clumped isotope
        anomalies, all expressed in permil.
        &#39;&#39;&#39;

        # Compute R17
        R17 = self.R17_VSMOW * np.exp(D17O / 1000) * (R18 / self.R18_VSMOW) ** self.lambda_17

        # Compute isotope concentrations
        C12 = (1 + R13) ** -1
        C13 = C12 * R13
        C16 = (1 + R17 + R18) ** -1
        C17 = C16 * R17
        C18 = C16 * R18

        # Compute stochastic isotopologue concentrations
        C626 = C16 * C12 * C16
        C627 = C16 * C12 * C17 * 2
        C628 = C16 * C12 * C18 * 2
        C636 = C16 * C13 * C16
        C637 = C16 * C13 * C17 * 2
        C638 = C16 * C13 * C18 * 2
        C727 = C17 * C12 * C17
        C728 = C17 * C12 * C18 * 2
        C737 = C17 * C13 * C17
        C738 = C17 * C13 * C18 * 2
        C828 = C18 * C12 * C18
        C838 = C18 * C13 * C18

        # Compute stochastic isobar ratios
        R45 = (C636 + C627) / C626
        R46 = (C628 + C637 + C727) / C626
        R47 = (C638 + C728 + C737) / C626
        R48 = (C738 + C828) / C626
        R49 = C838 / C626

        # Account for stochastic anomalies
        R47 *= 1 + D47 / 1000
        R48 *= 1 + D48 / 1000
        R49 *= 1 + D49 / 1000

        # Return isobar ratios
        return R45, R46, R47, R48, R49</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.compute_reproducibility"><code class="name flex">
<span>def <span class="ident">compute_reproducibility</span></span>(<span>self, key, samples='all samples', sessions='all sessions')</span>
</code></dt>
<dd>
<section class="desc"><p>Compute external reproducibility of r[key].</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_reproducibility(self, key, samples = &#39;all samples&#39;, sessions = &#39;all sessions&#39;):
        &#39;&#39;&#39;
        Compute external reproducibility of r[key].
        &#39;&#39;&#39;
        if samples == &#39;all samples&#39;:
                mysamples = [k for k in self.samples]
        elif samples == &#39;anchors&#39;:
                mysamples = [k for k in self.anchors]
        elif samples == &#39;unknowns&#39;:
                mysamples = [k for k in self.unknowns]
        else:
                mysamples = samples

        if sessions == &#39;all sessions&#39;:
                sessions = [k for k in self.sessions]

        chisq, Nf = 0, 0
        for sample in mysamples :
                X = [ r[key] for r in self if r[&#39;Sample&#39;] == sample and r[&#39;Session&#39;] in sessions ]
                if len(X) &gt; 1 :
                        Nf += len(X) - 1
                        chisq += np.sum([ (x-np.mean(X))**2 for x in X ])
        r = (chisq / Nf)**.5 if Nf &gt; 0 else 0
        self.vprint(f&#39;External reproducibility of r[&#34;{key}&#34;] is {1000*r:.1f} ppm for {samples}.&#39;)
        return r</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.consolidate"><code class="name flex">
<span>def <span class="ident">consolidate</span></span>(<span>self, tables=True, plots=True)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate(self,
        tables = True,
        plots = True,
        ):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        self.consolidate_samples()
        self.consolidate_sessions()
        self.consolidate_repro()

        if tables:
                self.table_of_sessions()
                self.table_of_analyses()
                self.table_of_samples()
        
        if plots:
                self.plot_sessions()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.consolidate_repro"><code class="name flex">
<span>def <span class="ident">consolidate_repro</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate_repro(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        self.repro[&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;)
        self.repro[&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;)
        self.repro[&#39;r_D47a&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;anchors&#39;)
        self.repro[&#39;r_D47u&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;unknowns&#39;)
        self.repro[&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, samples = &#39;all samples&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.consolidate_samples"><code class="name flex">
<span>def <span class="ident">consolidate_samples</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate_samples(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        for sample in self.samples:
                self.samples[sample][&#39;N&#39;] = len(self.samples[sample][&#39;data&#39;])
                if self.samples[sample][&#39;N&#39;] &gt; 1:
                        self.samples[sample][&#39;SD_D47&#39;] = stdev([r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]])
                self.samples[sample][&#39;d13C_VPDB&#39;] = np.mean([r[&#39;d13C_VPDB&#39;] for r in self.samples[sample][&#39;data&#39;]])
                self.samples[sample][&#39;d18O_VSMOW&#39;] = np.mean([r[&#39;d18O_VSMOW&#39;] for r in self.samples[sample][&#39;data&#39;]])

        for sample in self.anchors:
                self.samples[sample][&#39;D47&#39;] = self.Nominal_D47[sample]
                self.samples[sample][&#39;SE_D47&#39;] = 0.

        D47_ref_pop = [r[&#39;D47&#39;] for r in self.samples[self.LEVENE_REF_SAMPLE][&#39;data&#39;]]

        for sample in self.unknowns:
                self.samples[sample][&#39;D47&#39;] = self.normalization.params.valuesdict()[f&#39;D47_{pf(sample)}&#39;]
                self.samples[sample][&#39;SE_D47&#39;] = self.sample_D47_covar(sample)**.5

                D47_pop = [r[&#39;D47&#39;] for r in self.samples[sample][&#39;data&#39;]]
                if len(D47_pop) &gt; 1:
                        self.samples[sample][&#39;p_Levene&#39;] = levene(D47_ref_pop, D47_pop, center = &#39;median&#39;)[1]</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.consolidate_sessions"><code class="name flex">
<span>def <span class="ident">consolidate_sessions</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def consolidate_sessions(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        for session in self.sessions:
                self.sessions[session][&#39;Na&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.anchors])
                self.sessions[session][&#39;Nu&#39;] = len([r for r in self.sessions[session][&#39;data&#39;] if r[&#39;Sample&#39;] in self.unknowns])
                self.sessions[session][&#39;a&#39;] = self.normalization.params.valuesdict()[f&#39;a_{pf(session)}&#39;]
                i = self.normalization.var_names.index(f&#39;a_{pf(session)}&#39;)
                self.sessions[session][&#39;SE_a&#39;] = self.normalization.covar[i,i]**.5
                self.sessions[session][&#39;b&#39;] = self.normalization.params.valuesdict()[f&#39;b_{pf(session)}&#39;]
                i = self.normalization.var_names.index(f&#39;b_{pf(session)}&#39;)
                self.sessions[session][&#39;SE_b&#39;] = self.normalization.covar[i,i]**.5
                self.sessions[session][&#39;c&#39;] = self.normalization.params.valuesdict()[f&#39;c_{pf(session)}&#39;]
                i = self.normalization.var_names.index(f&#39;c_{pf(session)}&#39;)
                self.sessions[session][&#39;SE_c&#39;] = self.normalization.covar[i,i]**.5
                self.sessions[session][&#39;a2&#39;] = self.normalization.params.valuesdict()[f&#39;a2_{pf(session)}&#39;]
                if self.sessions[session][&#39;scrambling_drift&#39;]:
                        i = self.normalization.var_names.index(f&#39;a2_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_a2&#39;] = self.normalization.covar[i,i]**.5
                self.sessions[session][&#39;b2&#39;] = self.normalization.params.valuesdict()[f&#39;b2_{pf(session)}&#39;]
                if self.sessions[session][&#39;slope_drift&#39;]:
                        i = self.normalization.var_names.index(f&#39;b2_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_b2&#39;] = self.normalization.covar[i,i]**.5
                self.sessions[session][&#39;c2&#39;] = self.normalization.params.valuesdict()[f&#39;c2_{pf(session)}&#39;]
                if self.sessions[session][&#39;wg_drift&#39;]:
                        i = self.normalization.var_names.index(f&#39;c2_{pf(session)}&#39;)
                        self.sessions[session][&#39;SE_c2&#39;] = self.normalization.covar[i,i]**.5
                self.sessions[session][&#39;r_d13C_VPDB&#39;] = self.compute_reproducibility(&#39;d13C_VPDB&#39;, samples = &#39;anchors&#39;, sessions = [session])
                self.sessions[session][&#39;r_d18O_VSMOW&#39;] = self.compute_reproducibility(&#39;d18O_VSMOW&#39;, samples = &#39;anchors&#39;, sessions = [session])
                self.sessions[session][&#39;r_D47&#39;] = self.compute_reproducibility(&#39;D47&#39;, sessions = [session])</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.crunch"><code class="name flex">
<span>def <span class="ident">crunch</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute bulk composition and raw clumped isotope anomalies for all analyses.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crunch(self):
        &#39;&#39;&#39;
        Compute bulk composition and raw clumped isotope anomalies for all analyses.
        &#39;&#39;&#39;
        for i,r in enumerate(self):
                for k in [&#39;D17O&#39;, &#39;d48&#39;, &#39;d49&#39;]:
                        if k not in r:
                                r[k] = 0.
                self.compute_bulk_and_clumping_deltas(r)
        self.vprint(f&#34;Crunched {len(self)} analyses.&#34;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.input"><code class="name flex">
<span>def <span class="ident">input</span></span>(<span>self, txt, sep=',')</span>
</code></dt>
<dd>
<section class="desc"><p>Read string in csv format to load analysis data into a D47data object.
Use 'sep' argument to define the csv separator.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def input(self, txt, sep = &#39;,&#39;):
        &#39;&#39;&#39;
        Read string in csv format to load analysis data into a D47data object.
        Use &#39;sep&#39; argument to define the csv separator.
        &#39;&#39;&#39;
        txt = [[x.strip() for x in l.split(sep)] for l in txt.splitlines() if l.strip()]
        data = [{k: smart_type(v) for k,v in zip(txt[0], l)} for l in txt[1:]]
        self += data
        self.refresh()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.normalization_error"><code class="name flex">
<span>def <span class="ident">normalization_error</span></span>(<span>self, session, d47, D47)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalization_error(self, session, d47, D47):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        a = self.sessions[session][&#39;a&#39;]
        b = self.sessions[session][&#39;b&#39;]
        c = self.sessions[session][&#39;c&#39;]
        s = pf(session)
        i = self.normalization.var_names.index(f&#39;a_{s}&#39;)
        j = self.normalization.var_names.index(f&#39;b_{s}&#39;)
        k = self.normalization.var_names.index(f&#39;c_{s}&#39;)
        CM = np.zeros((3,3))
        CM[0,0] = self.normalization.covar[i,i]
        CM[0,1] = self.normalization.covar[i,j]
        CM[0,2] = self.normalization.covar[i,k]
        CM[1,0] = self.normalization.covar[j,i]
        CM[1,1] = self.normalization.covar[j,j]
        CM[1,2] = self.normalization.covar[j,k]
        CM[2,0] = self.normalization.covar[k,i]
        CM[2,1] = self.normalization.covar[k,j]
        CM[2,2] = self.normalization.covar[k,k]

        y, x = d47, D47
        z = a * x + b * y + c
        dxdy = -b / a
        dxdz = a ** -1
        dxda = -x / a
        dxdb = -y / a
        dxdc = -a ** -1
        V = np.array([dxda, dxdb, dxdc])
        sx = (V @ CM @ V.T) ** .5
        return sx</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>self, method='lmfit', weighted_sessions=[], consolidate=True, consolidate_tables=True, consolidate_plots=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute absolute Δ47 values for all replicate analyses and for sample averages.
If "method" argument is set to "lmfit", the normalization processes all sessions
in a single step, assuming that all samples (anchors and unknowns alike) are
homogeneous (i.e. that their true Δ47 value does not change between sessions).
If "method" argument is set to "indep_sessions", the normalization processes each
session independently.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def normalize(self,
                method = &#39;lmfit&#39;,
                weighted_sessions = [],
                consolidate = True,
                consolidate_tables = True,
                consolidate_plots = True,
                ):
                &#39;&#39;&#39;
                Compute absolute Δ47 values for all replicate analyses and for sample averages.
                If &#34;method&#34; argument is set to &#34;lmfit&#34;, the normalization processes all sessions
                in a single step, assuming that all samples (anchors and unknowns alike) are
                homogeneous (i.e. that their true Δ47 value does not change between sessions).
                If &#34;method&#34; argument is set to &#34;indep_sessions&#34;, the normalization processes each
                session independently.
                &#39;&#39;&#39;
                if method == &#39;lmfit&#39;:
                        if weighted_sessions:
                                for session_group in weighted_sessions:
                                        X = D47data([r for r in self if r[&#39;Session&#39;] in session_group], verbose = self.verbose)
                                        result = X.normalize(method = &#39;lmfit&#39;, weighted_sessions = [], consolidate = False)
                                        w = np.sqrt(result.redchi)
                                        self.vprint(f&#39;Session group {session_group} MRSWD = {w:.4f}&#39;)
                                        for r in X:
                                                r[&#39;wD47raw&#39;] *= w
                        else:
                                self.vprint(&#39;All weights set to 1 ppm&#39;)
                                for r in self:
                                        r[&#39;wD47raw&#39;] = 0.001

                        for s in self.sessions:
                                G = self.sessions[s][&#39;data&#39;]
                                try:
                                        t0 = np.mean([r[&#39;TimeTag&#39;] for r in G])
                                        for r in G:
                                                r[&#39;t&#39;] = r[&#39;TimeTag&#39;] - t0
                                except KeyError:
                                        t0 = (len(G)-1)/2
                                        for t,r in enumerate(G):
                                                r[&#39;t&#39;] = t - t0

                        params = Parameters()
                        for k,session in enumerate(self.sessions):
                                self.vprint(f&#34;Session {session}: scrambling_drift is {self.sessions[session][&#39;scrambling_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: slope_drift is {self.sessions[session][&#39;slope_drift&#39;]}.&#34;)
                                self.vprint(f&#34;Session {session}: wg_drift is {self.sessions[session][&#39;wg_drift&#39;]}.&#34;)
                                s = pf(session)
                                params.add(f&#39;a_{s}&#39;, value = 0.9)
                                params.add(f&#39;b_{s}&#39;, value = 0.)
                                params.add(f&#39;c_{s}&#39;, value = -0.9)
                                params.add(f&#39;a2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;scrambling_drift&#39;])
                                params.add(f&#39;b2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;slope_drift&#39;])
                                params.add(f&#39;c2_{s}&#39;, value = 0., vary = self.sessions[session][&#39;wg_drift&#39;])
                        for sample in self.unknowns:
                                params.add(f&#39;D47_{pf(sample)}&#39;, value=0.6)

                        def residuals(p):
                                R = []
                                for r in self:
                                        session = pf(r[&#39;Session&#39;])
                                        sample = pf(r[&#39;Sample&#39;])
                                        if r[&#39;Sample&#39;] in self.Nominal_D47:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * self.Nominal_D47[r[&#39;Sample&#39;]]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                        else:
                                                R += [ (
                                                        r[&#39;D47raw&#39;] - (
                                                                p[f&#39;a_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                + p[f&#39;b_{session}&#39;] * r[&#39;d47&#39;]
                                                                +       p[f&#39;c_{session}&#39;]
                                                                + r[&#39;t&#39;] * (
                                                                        p[f&#39;a2_{session}&#39;] * p[f&#39;D47_{sample}&#39;]
                                                                        + p[f&#39;b2_{session}&#39;] * r[&#39;d47&#39;]
                                                                        +       p[f&#39;c2_{session}&#39;]
                                                                        )
                                                                )
                                                        ) / r[&#39;wD47raw&#39;] ]
                                return R

                        M = Minimizer(residuals, params)
                        result = M.leastsq()
                        self.Nf = result.nfree
                        self.t95 = tstudent.ppf(1 - 0.05/2, self.Nf)
#                       if self.verbose:
#                               report_fit(result)

                        for r in self:
                                s = pf(r[&#34;Session&#34;])
                                a = result.params.valuesdict()[f&#39;a_{s}&#39;]
                                b = result.params.valuesdict()[f&#39;b_{s}&#39;]
                                c = result.params.valuesdict()[f&#39;c_{s}&#39;]
                                a2 = result.params.valuesdict()[f&#39;a2_{s}&#39;]
                                b2 = result.params.valuesdict()[f&#39;b2_{s}&#39;]
                                c2 = result.params.valuesdict()[f&#39;c2_{s}&#39;]
                                r[&#39;D47&#39;] = (r[&#39;D47raw&#39;] - c - b * r[&#39;d47&#39;] - c2 * r[&#39;t&#39;] - b2 * r[&#39;t&#39;] * r[&#39;d47&#39;]) / (a + a2 * r[&#39;t&#39;])

                        self.normalization = result
                        if consolidate:
                                self.consolidate(tables = consolidate_tables, plots = consolidate_plots)
                        return result

                elif method == &#39;indep_sessions&#39;:
                        pass</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.plot_sessions"><code class="name flex">
<span>def <span class="ident">plot_sessions</span></span>(<span>self, dir='plots', figsize=(8, 8))</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_sessions(self, dir = &#39;plots&#39;, figsize = (8,8)):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        if not os.path.exists(dir):
                os.makedirs(dir)
        anchor_color = &#39;r&#39;
        unknown_color = &#39;b&#39;

        xmin = min([r[&#39;d47&#39;] for r in self])
        xmax = max([r[&#39;d47&#39;] for r in self])
        xmin -= (xmax - xmin)/10
        xmax += (xmax - xmin)/11

        ymin = min([r[&#39;D47&#39;] for r in self])
        ymax = max([r[&#39;D47&#39;] for r in self])
        ymin -= (ymax - ymin)/10
        ymax += (ymax - ymin)/11

        repl_kw = dict(ls = &#39;None&#39;, marker = &#39;x&#39;, mfc = &#39;None&#39;, ms = 4, mew = .67, alpha = 1)
        avg_kw = dict(ls = &#39;-&#39;, marker = &#39;None&#39;, lw = .67, alpha = .67)
        for session in self.sessions:
                fig = ppl.figure( figsize = figsize)
                for sample in self.anchors:
                        db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                        if len(db):
                                repl_kw[&#39;mec&#39;] = anchor_color
                                X = [r[&#39;d47&#39;] for r in db]
                                Y = [r[&#39;D47&#39;] for r in db]
                                ppl.plot(X, Y, **repl_kw)
                        
                                avg_kw[&#39;color&#39;] = anchor_color
                                X = [min(X)-.5, max(X)+.5]
                                Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                ppl.plot(X, Y, **avg_kw)
                        
                for sample in self.unknowns:

                        db = [r for r in self.samples[sample][&#39;data&#39;] if r[&#39;Session&#39;] == session]
                        if len(db):
                                repl_kw[&#39;mec&#39;] = unknown_color
                                X = [r[&#39;d47&#39;] for r in db]
                                Y = [r[&#39;D47&#39;] for r in db]
                                ppl.plot(X, Y, **repl_kw)

                                avg_kw[&#39;color&#39;] = unknown_color
                                X = [min(X)-.19, max(X)+.19]
                                Y = [self.samples[sample][&#39;D47&#39;]] * 2
                                ppl.plot(X, Y, **avg_kw)

                XI,YI = np.meshgrid(np.linspace(xmin, xmax), np.linspace(ymin, ymax))
                SI = np.array([[self.normalization_error(session, xi, yi) for xi in XI[0,:]] for yi in YI[:,0]])
                rng = np.max(SI) - np.min(SI)
                if rng &lt;= 0.01:
                        cinterval = 0.001
                elif rng &lt;= 0.03:
                        cinterval = 0.004
                elif rng &lt;= 0.1:
                        cinterval = 0.01
                elif rng &lt;= 0.3:
                        cinterval = 0.03
                else:
                        cinterval = 0.1
                cval = [np.ceil(SI.min() / .001) * .001 + k * cinterval for k in range(int(np.ceil((SI.max() - SI.min()) / cinterval)))]
                cs = ppl.contour(XI, YI, SI, cval, colors = anchor_color, alpha = .5)
                ppl.clabel(cs)

                ppl.axis([xmin, xmax, ymin, ymax])
                ppl.xlabel(&#39;δ$_{47}$ (‰ WG)&#39;)
                ppl.ylabel(&#39;Δ$_{47}$ (‰)&#39;)
                ppl.grid(alpha = .15)
                ppl.title(session, weight = &#39;bold&#39;)
                ppl.savefig(f&#39;{dir}/D47model_{session}.pdf&#39;)
                ppl.close(fig)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, file, sep=',')</span>
</code></dt>
<dd>
<section class="desc"><p>Read file in csv format to load analysis data into a D47data object.
Use 'sep' argument to define the csv separator.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, file, sep = &#39;,&#39;):
        &#39;&#39;&#39;
        Read file in csv format to load analysis data into a D47data object.
        Use &#39;sep&#39; argument to define the csv separator.
        &#39;&#39;&#39;
        with open(file) as fid:
                self.input(fid.read(), sep = sep)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.refresh"><code class="name flex">
<span>def <span class="ident">refresh</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        self.refresh_sessions()
        self.refresh_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.refresh_samples"><code class="name flex">
<span>def <span class="ident">refresh_samples</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh_samples(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        self.samples = {
                s: {&#39;data&#39;: [r for r in self if r[&#39;Sample&#39;] == s]}
                for s in sorted({r[&#39;Sample&#39;] for r in self})
                }
        self.anchors = {s: self.samples[s] for s in self.samples if s in self.Nominal_D47}
        self.unknowns = {s: self.samples[s] for s in self.samples if s not in self.Nominal_D47}</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.refresh_sessions"><code class="name flex">
<span>def <span class="ident">refresh_sessions</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh_sessions(self):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        self.sessions = {
                s: {&#39;data&#39;: [r for r in self if r[&#39;Session&#39;] == s]}
                for s in sorted({r[&#39;Session&#39;] for r in self})
                }
        for s in self.sessions:
                self.sessions[s][&#39;scrambling_drift&#39;] = False
                self.sessions[s][&#39;slope_drift&#39;] = False
                self.sessions[s][&#39;wg_drift&#39;] = False</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.report"><code class="name flex">
<span>def <span class="ident">report</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Prints a report on the normalization fit.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def report(self):
        &#39;&#39;&#39;
        Prints a report on the normalization fit.
        &#39;&#39;&#39;
        report_fit(self.normalization)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.sample_D47_covar"><code class="name flex">
<span>def <span class="ident">sample_D47_covar</span></span>(<span>self, sample_1, sample_2='')</span>
</code></dt>
<dd>
<section class="desc"><p>Covariance between Δ47 values of samples</p>
<p>Returns the covariance (or the variance, if sample_1 == sample_2)
between the average Δ47 values of two samples. Also returns the
variance if only sample_1 is specified.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_D47_covar(self, sample_1, sample_2 = &#39;&#39;):
        &#39;&#39;&#39;
        Covariance between Δ47 values of samples
        
        Returns the covariance (or the variance, if sample_1 == sample_2)
        between the average Δ47 values of two samples. Also returns the
        variance if only sample_1 is specified.
        &#39;&#39;&#39;
        i = self.normalization.var_names.index(f&#39;D47_{pf(sample_1)}&#39;)
        if sample_2 in [sample_1,&#39;&#39;]:
                return self.normalization.covar[i,i]
        else:
                j = self.normalization.var_names.index(f&#39;D47_{pf(sample_2)}&#39;)
                return self.normalization.covar[i,j]</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.sample_average"><code class="name flex">
<span>def <span class="ident">sample_average</span></span>(<span>self, samples, weights='equal', normalize=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Average Δ47 value of a group of samples, accounting for covariance.</p>
<p>Returns the (weighed, optionally) average Δ47 value and associated SE
of a group of samples. Weights are equal by default. If normalize is
True, weights will be rescaled so that their sum equals 1.</p>
<h2 id="examples">Examples</h2>
<p><code>sample_average(['X','Y'], [1, 2])</code></p>
<p>will return the value and SE of (Δ47(X) + 2*Δ47(Y)/3, where Δ47(X)
and Δ47(Y) are the average Δ47 of samples X and Y, respectively.</p>
<blockquote>
<p>sample_average(['X','Y'], [1, -1], normalize = False)</p>
</blockquote>
<p>will return the value and SE of the difference Δ47(X) - Δ47(Y)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def sample_average(self, samples, weights = &#39;equal&#39;, normalize = True):
                &#39;&#39;&#39;
                Average Δ47 value of a group of samples, accounting for covariance.
                
                Returns the (weighed, optionally) average Δ47 value and associated SE
                of a group of samples. Weights are equal by default. If normalize is
                True, weights will be rescaled so that their sum equals 1.
                
                Examples
                --------
                ```sample_average([&#39;X&#39;,&#39;Y&#39;], [1, 2])```

                will return the value and SE of (Δ47(X) + 2*Δ47(Y)/3, where Δ47(X)
                and Δ47(Y) are the average Δ47 of samples X and Y, respectively.

                &gt; sample_average([&#39;X&#39;,&#39;Y&#39;], [1, -1], normalize = False)
                
                will return the value and SE of the difference Δ47(X) - Δ47(Y)
                &#39;&#39;&#39;
                if weights == &#39;equal&#39;:
                        weights = [1/len(samples)] * len(samples)

                if normalize:
                        s = sum(weights)
                        weights = [w/s for w in weights]

                try:
#                       indices = [self.normalization.var_names.index(f&#39;D47_{pf(sample)}&#39;) for sample in samples]
#                       C = self.normalization.covar[indices,:][:,indices]
                        C = array([[self.sample_D47_covar(x, y) for x in samples] for y in samples])
                        X = [self.samples[sample][&#39;D47&#39;] for sample in samples]
                        return correlated_sum(X, C, weights)
                except ValueError:
                        return (0., 0.)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.split_samples"><code class="name flex">
<span>def <span class="ident">split_samples</span></span>(<span>self, samples_to_split='all', grouping='by_uid')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_samples(self, samples_to_split = &#39;all&#39;, grouping = &#39;by_uid&#39;):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        if samples_to_split == &#39;all&#39;:
                samples_to_split = [s for s in self.unknowns]
        gkeys = {&#39;by_uid&#39;:&#39;UID&#39;, &#39;by_session&#39;:&#39;Session&#39;}
        self.grouping = grouping.lower()
        if self.grouping in gkeys:
                gkey = gkeys[self.grouping]
        for r in self:
                if r[&#39;Sample&#39;] in samples_to_split:
                        r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
                        r[&#39;Sample&#39;] = f&#34;{r[&#39;Sample&#39;]}__{r[gkey]}&#34;
                elif r[&#39;Sample&#39;] in self.unknowns:
                        r[&#39;Sample_original&#39;] = r[&#39;Sample&#39;]
        self.refresh_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.table_of_analyses"><code class="name flex">
<span>def <span class="ident">table_of_analyses</span></span>(<span>self, dir='results', filename='analyses.csv')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def table_of_analyses(self, dir = &#39;results&#39;, filename = &#39;analyses.csv&#39;):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                out = [[&#39;UID&#39;,&#39;Session&#39;,&#39;Sample&#39;]]
                extra_fields = [f for f in [(&#39;SampleMass&#39;,&#39;.2f&#39;),(&#39;ColdFingerPressure&#39;,&#39;.1f&#39;),(&#39;AcidReactionYield&#39;,&#39;.3f&#39;)] if f[0] in {k for r in self for k in r}]
                for f in extra_fields:
                        out[-1] += [f[0]]
                out[-1] += [&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;d45&#39;,&#39;d46&#39;,&#39;d47&#39;,&#39;d48&#39;,&#39;d49&#39;,&#39;D47raw&#39;,&#39;D48raw&#39;,&#39;D49raw&#39;,&#39;D47&#39;]
                for r in self:
                        out += [[f&#34;{r[&#39;UID&#39;]}&#34;,f&#34;{r[&#39;Session&#39;]}&#34;,f&#34;{r[&#39;Sample&#39;]}&#34;]]
                        for f in extra_fields:
                                out[-1] += [f&#34;{r[f[0]]:{f[1]}}&#34;]
                        out[-1] += [
                                f&#34;{r[&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                                f&#34;{r[&#39;d45&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d46&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d47&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d48&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;d49&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D48raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D49raw&#39;]:.6f}&#34;,
                                f&#34;{r[&#39;D47&#39;]:.6f}&#34;
                                ]
#                       print(pretty_table(out))
                with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                        fid.write(make_csv(out))                        </code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.table_of_samples"><code class="name flex">
<span>def <span class="ident">table_of_samples</span></span>(<span>self, dir='results', filename='samples.csv')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def table_of_samples(self, dir = &#39;results&#39;, filename = &#39;samples.csv&#39;):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        out = [[&#39;Sample&#39;,&#39;N&#39;,&#39;d13C_VPDB&#39;,&#39;d18O_VSMOW&#39;,&#39;D47&#39;,&#39;SE&#39;,&#39;95% CL&#39;,&#39;SD&#39;,&#39;p_Levene&#39;]]
        for sample in self.anchors:
                out += [[
                        f&#34;{sample}&#34;,
                        f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                        f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,&#39;&#39;,&#39;&#39;,
                        f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;, &#39;&#39;
                        ]]
        for sample in self.unknowns:
                out += [[
                        f&#34;{sample}&#34;,
                        f&#34;{self.samples[sample][&#39;N&#39;]}&#34;,
                        f&#34;{self.samples[sample][&#39;d13C_VPDB&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;d18O_VSMOW&#39;]:.2f}&#34;,
                        f&#34;{self.samples[sample][&#39;D47&#39;]:.4f}&#34;,
                        f&#34;{self.samples[sample][&#39;SE_D47&#39;]:.4f}&#34;,
                        f&#34;± {self.samples[sample][&#39;SE_D47&#39;]*self.t95:.4f}&#34;,
                        f&#34;{self.samples[sample][&#39;SD_D47&#39;]:.4f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;,
                        f&#34;{self.samples[sample][&#39;p_Levene&#39;]:.3f}&#34; if self.samples[sample][&#39;N&#39;] &gt; 1 else &#39;&#39;
                        ]]
        print(pretty_table(out))
        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                fid.write(make_csv(out))                        </code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.table_of_sessions"><code class="name flex">
<span>def <span class="ident">table_of_sessions</span></span>(<span>self, dir='results', filename='sessions.csv')</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def table_of_sessions(self, dir = &#39;results&#39;, filename = &#39;sessions.csv&#39;):
        &#39;&#39;&#39;
        &gt;&gt;&gt; Missing docstring
        &#39;&#39;&#39;
        out = []
        out += [[&#39;N samples (anchors + unknowns)&#39;, f&#34;{len(self.samples)} ({len(self.anchors)} + {len(self.unknowns)})&#34;]]
        out += [[&#39;N analyses (anchors + unknowns)&#39;, f&#34;{len(self)} ({len([r for r in self if r[&#39;Sample&#39;] in self.anchors])} + {len([r for r in self if r[&#39;Sample&#39;] in self.unknowns])})&#34;]]
        out += [[&#39;External reproducibility of δ13C_VPDB&#39;, f&#34;{1000 * self.repro[&#39;r_d13C_VPDB&#39;]:.1f} ppm&#34;]]
        out += [[&#39;External reproducibility of δ18O_VSMOW&#39;, f&#34;{1000 * self.repro[&#39;r_d18O_VSMOW&#39;]:.1f} ppm&#34;]]
        out += [[&#39;External reproducibility of Δ47 (anchors)&#39;, f&#34;{1000 * self.repro[&#39;r_D47a&#39;]:.1f} ppm&#34;]]
        out += [[&#39;External reproducibility of Δ47 (unknowns)&#39;, f&#34;{1000 * self.repro[&#39;r_D47u&#39;]:.1f} ppm&#34;]]
        out += [[&#39;External reproducibility of Δ47 (all)&#39;, f&#34;{1000 * self.repro[&#39;r_D47&#39;]:.1f} ppm&#34;]]
        out += [[&#39;Degrees of freedom (Student\&#39;s 95% t-factor)&#39;, f&#34;{self.Nf} ({self.t95:.2f})&#34;]]
        print(pretty_table(out, header = 0)) 
        
        include_a2 = any([self.sessions[session][&#39;scrambling_drift&#39;] for session in self.sessions])
        include_b2 = any([self.sessions[session][&#39;slope_drift&#39;] for session in self.sessions])
        include_c2 = any([self.sessions[session][&#39;wg_drift&#39;] for session in self.sessions])
        out = [[&#39;Session&#39;,&#39;Na&#39;,&#39;Nu&#39;,&#39;d13Cwg_VPDB&#39;,&#39;d18Owg_VSMOW&#39;,&#39;r_d13C&#39;,&#39;r_d18O&#39;,&#39;r_D47&#39;,&#39;a ± SE&#39;,&#39;1e3 x b ± SE&#39;,&#39;c ± SE&#39;]]
        if include_a2:
                out[-1] += [&#39;a2 ± SE&#39;]
        if include_b2:
                out[-1] += [&#39;b2 ± SE&#39;]
        if include_c2:
                out[-1] += [&#39;c2 ± SE&#39;]
        for session in self.sessions:
                out += [[
                        session,
                        f&#34;{self.sessions[session][&#39;Na&#39;]}&#34;,
                        f&#34;{self.sessions[session][&#39;Nu&#39;]}&#34;,
                        f&#34;{self.sessions[session][&#39;d13Cwg_VPDB&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;d18Owg_VSMOW&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;r_d13C_VPDB&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][&#39;r_d18O_VSMOW&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][&#39;r_D47&#39;]:.4f}&#34;,
                        f&#34;{self.sessions[session][&#39;a&#39;]:.3f} ± {self.sessions[session][&#39;SE_a&#39;]:.3f}&#34;,
                        f&#34;{1e3*self.sessions[session][&#39;b&#39;]:.3f} ± {1e3*self.sessions[session][&#39;SE_b&#39;]:.3f}&#34;,
                        f&#34;{self.sessions[session][&#39;c&#39;]:.3f} ± {self.sessions[session][&#39;SE_c&#39;]:.3f}&#34;,
                        ]]
                if include_a2:
                        if self.sessions[session][&#39;scrambling_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;a2&#39;]:.1e} ± {self.sessions[session][&#39;SE_a2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]
                if include_b2:
                        if self.sessions[session][&#39;slope_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;b2&#39;]:.1e} ± {self.sessions[session][&#39;SE_b2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]
                if include_c2:
                        if self.sessions[session][&#39;wg_drift&#39;]:
                                out[-1] += [f&#34;{self.sessions[session][&#39;c2&#39;]:.1e} ± {self.sessions[session][&#39;SE_c2&#39;]:.1e}&#34;]
                        else:
                                out[-1] += [&#39;&#39;]

        print(pretty_table(out))
        if not os.path.exists(dir):
                os.makedirs(dir)
        with open(f&#39;{dir}/{filename}&#39;, &#39;w&#39;) as fid:
                fid.write(make_csv(out))</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.unsplit_samples"><code class="name flex">
<span>def <span class="ident">unsplit_samples</span></span>(<span>self, tables=True)</span>
</code></dt>
<dd>
<section class="desc"><pre><code>&gt;&gt;&gt; Missing docstring
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">        def unsplit_samples(self, tables = True):
                &#39;&#39;&#39;
                &gt;&gt;&gt; Missing docstring
                &#39;&#39;&#39;
                unknowns_old = sorted({s for s in self.unknowns})
                CM_old = self.normalization.covar[:,:]
                VD_old = self.normalization.params.valuesdict().copy()
                vars_old = self.normalization.var_names

                unknowns_new = sorted({r[&#39;Sample_original&#39;] for r in self if &#39;Sample_original&#39; in r})
                
                Ns = len(vars_old) - len(unknowns_old)
                vars_new = vars_old[:Ns] + [f&#39;D47_{pf(u)}&#39; for u in unknowns_new]
                VD_new = {k: VD_old[k] for k in vars_old[:Ns]}

                W = np.zeros((len(vars_new), len(vars_old)))
                W[:Ns,:Ns] = np.eye(Ns)
                for u in unknowns_new:
                        splits = sorted({r[&#39;Sample&#39;] for r in self if &#39;Sample_original&#39; in r and r[&#39;Sample_original&#39;] == u})
                        if self.grouping == &#39;by_session&#39;:
                                weights = [self.samples[s][&#39;SE_D47&#39;]**-2 for s in splits]
                        elif self.grouping == &#39;by_uid&#39;:
                                weights = [1 for s in splits]
                        sw = sum(weights)
                        weights = [w/sw for w in weights]
                        W[vars_new.index(f&#39;D47_{pf(u)}&#39;),[vars_old.index(f&#39;D47_{pf(s)}&#39;) for s in splits]] = weights[:]
#               print(&#39;\nUnsplitting weights matrix:&#39;)
#               print(&#39;\n&#39;.join([&#39; &#39;.join([f&#39;{x:.1f}&#39; if x else &#39; - &#39; for x in l]) for l in W]))
#               print(&#39;---&#39;)

                CM_new = W @ CM_old @ W.T
                V = W @ np.array([[VD_old[k]] for k in vars_old])
                VD_new = {k:v[0] for k,v in zip(vars_new, V)}
                
                self.normalization.covar = CM_new
                self.normalization.params.valuesdict = lambda : VD_new
                self.normalization.var_names = vars_new

                for r in self:
                        if r[&#39;Sample&#39;] in self.unknowns:
                                r[&#39;Sample_split&#39;] = r[&#39;Sample&#39;]
                                r[&#39;Sample&#39;] = r[&#39;Sample_original&#39;]
                
                self.refresh_samples()
                self.consolidate_samples()
                self.consolidate_repro()

                if tables:
                        self.table_of_analyses()
                        self.table_of_samples()</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.vprint"><code class="name flex">
<span>def <span class="ident">vprint</span></span>(<span>self, txt)</span>
</code></dt>
<dd>
<section class="desc"><p>Print log message to screen if D47data.verbose is true.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vprint(self, txt):
        &#39;&#39;&#39;
        Print log message to screen if D47data.verbose is true.
        &#39;&#39;&#39;
        if self.verbose:
                print(f&#39;{self.msgcolor}[D47data]   {txt}\033[0m&#39;)</code></pre>
</details>
</dd>
<dt id="D47crunch.D47data.wg"><code class="name flex">
<span>def <span class="ident">wg</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute bulk composition of the working gas for each session
based on the average composition, within each session,
of a given sample.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wg(self):
        &#39;&#39;&#39;
        Compute bulk composition of the working gas for each session
        based on the average composition, within each session,
        of a given sample.
        &#39;&#39;&#39;

        self.vprint(f&#34;Computing working gas composition:&#34;)

        sample = self.SAMPLE_CONSTRAINING_WG_COMPOSITION
        d13C_vpdb = self.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
        d18O_vpdb = self.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION
        a18_acid = self.ALPHA_18O_ACID_REACTION

        R13_s = self.R13_VPDB * (1 + d13C_vpdb / 1000)
        R17_s = self.R17_VPDB * ((1 + d18O_vpdb / 1000) * a18_acid) ** self.lambda_17
        R18_s = self.R18_VPDB * (1 + d18O_vpdb / 1000) * a18_acid

        C12_s = 1 / (1 + R13_s)
        C13_s = R13_s / (1 + R13_s)
        C16_s = 1 / (1 + R17_s + R18_s)
        C17_s = R17_s / (1 + R17_s + R18_s)
        C18_s = R18_s / (1 + R17_s + R18_s)

        C626_s = C12_s * C16_s ** 2
        C627_s = 2 * C12_s * C16_s * C17_s
        C628_s = 2 * C12_s * C16_s * C18_s
        C636_s = C13_s * C16_s ** 2
        C637_s = 2 * C13_s * C16_s * C17_s
        C727_s = C12_s * C17_s ** 2

        R45_s = (C627_s + C636_s) / C626_s
        R46_s = (C628_s + C637_s + C727_s) / C626_s

        for s in self.sessions:
                db = [r for r in self.sessions[s][&#39;data&#39;] if r[&#39;Sample&#39;] == sample]
                d45_s = np.mean([r[&#39;d45&#39;] for r in db])
                d46_s = np.mean([r[&#39;d46&#39;] for r in db])
                R45_wg = R45_s / (1 + d45_s / 1000)
                R46_wg = R46_s / (1 + d46_s / 1000)

                d13Cwg_VPDB, d18Owg_VSMOW = self.compute_bulk_deltas(R45_wg, R46_wg)

                self.vprint(f&#39;Session {s} WG:   δ13C_VPDB = {d13Cwg_VPDB:.3f}   δ18O_VSMOW = {d18Owg_VSMOW:.3f}&#39;)

                self.sessions[s][&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                self.sessions[s][&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW
                for r in self.sessions[s][&#39;data&#39;]:
                        r[&#39;d13Cwg_VPDB&#39;] = d13Cwg_VPDB
                        r[&#39;d18Owg_VSMOW&#39;] = d18Owg_VSMOW</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="D47crunch.correlated_sum" href="#D47crunch.correlated_sum">correlated_sum</a></code></li>
<li><code><a title="D47crunch.make_csv" href="#D47crunch.make_csv">make_csv</a></code></li>
<li><code><a title="D47crunch.pf" href="#D47crunch.pf">pf</a></code></li>
<li><code><a title="D47crunch.pretty_table" href="#D47crunch.pretty_table">pretty_table</a></code></li>
<li><code><a title="D47crunch.smart_type" href="#D47crunch.smart_type">smart_type</a></code></li>
<li><code><a title="D47crunch.transpose_table" href="#D47crunch.transpose_table">transpose_table</a></code></li>
<li><code><a title="D47crunch.w_avg" href="#D47crunch.w_avg">w_avg</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="D47crunch.D47data" href="#D47crunch.D47data">D47data</a></code></h4>
<ul class="">
<li><code><a title="D47crunch.D47data.ALPHA_18O_ACID_REACTION" href="#D47crunch.D47data.ALPHA_18O_ACID_REACTION">ALPHA_18O_ACID_REACTION</a></code></li>
<li><code><a title="D47crunch.D47data.LEVENE_REF_SAMPLE" href="#D47crunch.D47data.LEVENE_REF_SAMPLE">LEVENE_REF_SAMPLE</a></code></li>
<li><code><a title="D47crunch.D47data.Nominal_D47" href="#D47crunch.D47data.Nominal_D47">Nominal_D47</a></code></li>
<li><code><a title="D47crunch.D47data.R13_VPDB" href="#D47crunch.D47data.R13_VPDB">R13_VPDB</a></code></li>
<li><code><a title="D47crunch.D47data.R17_VPDB" href="#D47crunch.D47data.R17_VPDB">R17_VPDB</a></code></li>
<li><code><a title="D47crunch.D47data.R17_VSMOW" href="#D47crunch.D47data.R17_VSMOW">R17_VSMOW</a></code></li>
<li><code><a title="D47crunch.D47data.R18_VPDB" href="#D47crunch.D47data.R18_VPDB">R18_VPDB</a></code></li>
<li><code><a title="D47crunch.D47data.R18_VSMOW" href="#D47crunch.D47data.R18_VSMOW">R18_VSMOW</a></code></li>
<li><code><a title="D47crunch.D47data.SAMPLE_CONSTRAINING_WG_COMPOSITION" href="#D47crunch.D47data.SAMPLE_CONSTRAINING_WG_COMPOSITION">SAMPLE_CONSTRAINING_WG_COMPOSITION</a></code></li>
<li><code><a title="D47crunch.D47data.T_ACID" href="#D47crunch.D47data.T_ACID">T_ACID</a></code></li>
<li><code><a title="D47crunch.D47data.compute_bulk_and_clumping_deltas" href="#D47crunch.D47data.compute_bulk_and_clumping_deltas">compute_bulk_and_clumping_deltas</a></code></li>
<li><code><a title="D47crunch.D47data.compute_bulk_deltas" href="#D47crunch.D47data.compute_bulk_deltas">compute_bulk_deltas</a></code></li>
<li><code><a title="D47crunch.D47data.compute_isobar_ratios" href="#D47crunch.D47data.compute_isobar_ratios">compute_isobar_ratios</a></code></li>
<li><code><a title="D47crunch.D47data.compute_reproducibility" href="#D47crunch.D47data.compute_reproducibility">compute_reproducibility</a></code></li>
<li><code><a title="D47crunch.D47data.consolidate" href="#D47crunch.D47data.consolidate">consolidate</a></code></li>
<li><code><a title="D47crunch.D47data.consolidate_repro" href="#D47crunch.D47data.consolidate_repro">consolidate_repro</a></code></li>
<li><code><a title="D47crunch.D47data.consolidate_samples" href="#D47crunch.D47data.consolidate_samples">consolidate_samples</a></code></li>
<li><code><a title="D47crunch.D47data.consolidate_sessions" href="#D47crunch.D47data.consolidate_sessions">consolidate_sessions</a></code></li>
<li><code><a title="D47crunch.D47data.crunch" href="#D47crunch.D47data.crunch">crunch</a></code></li>
<li><code><a title="D47crunch.D47data.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION" href="#D47crunch.D47data.d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION">d13C_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION</a></code></li>
<li><code><a title="D47crunch.D47data.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION" href="#D47crunch.D47data.d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION">d18O_VPDB_OF_SAMPLE_CONSTRAINING_WG_COMPOSITION</a></code></li>
<li><code><a title="D47crunch.D47data.input" href="#D47crunch.D47data.input">input</a></code></li>
<li><code><a title="D47crunch.D47data.lambda_17" href="#D47crunch.D47data.lambda_17">lambda_17</a></code></li>
<li><code><a title="D47crunch.D47data.normalization_error" href="#D47crunch.D47data.normalization_error">normalization_error</a></code></li>
<li><code><a title="D47crunch.D47data.normalize" href="#D47crunch.D47data.normalize">normalize</a></code></li>
<li><code><a title="D47crunch.D47data.plot_sessions" href="#D47crunch.D47data.plot_sessions">plot_sessions</a></code></li>
<li><code><a title="D47crunch.D47data.read" href="#D47crunch.D47data.read">read</a></code></li>
<li><code><a title="D47crunch.D47data.refresh" href="#D47crunch.D47data.refresh">refresh</a></code></li>
<li><code><a title="D47crunch.D47data.refresh_samples" href="#D47crunch.D47data.refresh_samples">refresh_samples</a></code></li>
<li><code><a title="D47crunch.D47data.refresh_sessions" href="#D47crunch.D47data.refresh_sessions">refresh_sessions</a></code></li>
<li><code><a title="D47crunch.D47data.report" href="#D47crunch.D47data.report">report</a></code></li>
<li><code><a title="D47crunch.D47data.sample_D47_covar" href="#D47crunch.D47data.sample_D47_covar">sample_D47_covar</a></code></li>
<li><code><a title="D47crunch.D47data.sample_average" href="#D47crunch.D47data.sample_average">sample_average</a></code></li>
<li><code><a title="D47crunch.D47data.split_samples" href="#D47crunch.D47data.split_samples">split_samples</a></code></li>
<li><code><a title="D47crunch.D47data.table_of_analyses" href="#D47crunch.D47data.table_of_analyses">table_of_analyses</a></code></li>
<li><code><a title="D47crunch.D47data.table_of_samples" href="#D47crunch.D47data.table_of_samples">table_of_samples</a></code></li>
<li><code><a title="D47crunch.D47data.table_of_sessions" href="#D47crunch.D47data.table_of_sessions">table_of_sessions</a></code></li>
<li><code><a title="D47crunch.D47data.unsplit_samples" href="#D47crunch.D47data.unsplit_samples">unsplit_samples</a></code></li>
<li><code><a title="D47crunch.D47data.vprint" href="#D47crunch.D47data.vprint">vprint</a></code></li>
<li><code><a title="D47crunch.D47data.wg" href="#D47crunch.D47data.wg">wg</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>